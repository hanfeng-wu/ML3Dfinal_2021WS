{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "All needed imports included here\n",
    "\"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: 1368\n",
      "Validation Set Size: 236\n",
      "Test Set Size: 383\n",
      "Voxel Dimensions: (1, 32, 32, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4563fa08e1894059ab29fa390a8167ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create data loaders and augmentations needed here\n",
    "\"\"\"\n",
    "from Data.ShapeNetDataLoader import ShapeNetVoxelData\n",
    "from Utils.visualization import visualize_occupancy\n",
    "\n",
    "overfit = False\n",
    "\n",
    "shapenet_core_path = Path(\"D:\\ShapeNetCoreVoxel32\")\n",
    "shapenet_splits_csv_path = Path(\"Data/shapenet_splits.csv\")\n",
    "voxel_filename = \"model_3.binvox\"\n",
    "# load only models from some synsets\n",
    "synset_id_filter = [\"04379243\"]  # tables\n",
    "train_data = ShapeNetVoxelData(shapenet_core_path=shapenet_core_path, shapenet_splits_csv_path=shapenet_splits_csv_path, split=\"train\", \n",
    "    overfit=overfit, synset_id_filter=synset_id_filter, voxel_filename=voxel_filename\n",
    ")\n",
    "print(f\"Train Set Size: {len(train_data)}\")\n",
    "val_data = ShapeNetVoxelData(shapenet_core_path=shapenet_core_path, shapenet_splits_csv_path=shapenet_splits_csv_path, split=\"val\",\n",
    "    overfit=overfit, synset_id_filter=synset_id_filter, voxel_filename=voxel_filename\n",
    ")\n",
    "print(f\"Validation Set Size: {len(val_data)}\")\n",
    "test_data = ShapeNetVoxelData(shapenet_core_path=shapenet_core_path, shapenet_splits_csv_path=shapenet_splits_csv_path, split=\"test\",\n",
    "    overfit=overfit, synset_id_filter=synset_id_filter, voxel_filename=voxel_filename\n",
    ")\n",
    "print(f\"Test Set Size: {len(test_data)}\")\n",
    "\n",
    "train_sample = train_data[0]\n",
    "print(f'Voxel Dimensions: {train_sample.shape}')\n",
    "\n",
    "visualize_occupancy(train_sample.squeeze(), flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purifying predicted Meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCode to purify meshes predicted by the previous networks to be used in the retrieval step\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Code to purify meshes predicted by the previous networks to be used in the retrieval step\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mesh Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type    | Params\n",
      "-----------------------------------\n",
      "0 | _model | Network | 34.2 M\n",
      "-----------------------------------\n",
      "34.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "34.2 M    Total params\n",
      "136.637   Total estimated model params size (MB)\n",
      "C:\\Users\\svlwe\\miniconda3\\envs\\ml-3d\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:623: UserWarning: Checkpoint directory C:\\Users\\svlwe\\source\\repos\\ML_3D\\project\\Assets\\Models\\VoxelAutoencoder exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 44/44 [00:12<00:00,  3.61it/s, loss=0.0953, v_num=255]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  129.89         \t|  100 %          \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  8.0712         \t|16             \t|  129.14         \t|  99.422         \t|\n",
      "run_training_batch                 \t|  0.26061        \t|352            \t|  91.736         \t|  70.625         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.13518        \t|352            \t|  47.585         \t|  36.635         \t|\n",
      "training_step_and_backward         \t|  0.12414        \t|352            \t|  43.697         \t|  33.641         \t|\n",
      "model_forward                      \t|  0.11593        \t|352            \t|  40.806         \t|  31.416         \t|\n",
      "training_step                      \t|  0.11557        \t|352            \t|  40.68          \t|  31.319         \t|\n",
      "fetch_next_train_batch             \t|  0.03353        \t|368            \t|  12.339         \t|  9.4995         \t|\n",
      "get_train_batch                    \t|  0.03353        \t|368            \t|  12.339         \t|  9.4995         \t|\n",
      "validation_step                    \t|  0.11601        \t|90             \t|  10.441         \t|  8.0383         \t|\n",
      "evaluation_step_and_end            \t|  0.11601        \t|90             \t|  10.441         \t|  8.0383         \t|\n",
      "on_validation_end                  \t|  1.8218         \t|5              \t|  9.109          \t|  7.0128         \t|\n",
      "fetch_next_validate_batch          \t|  0.034207       \t|92             \t|  3.147          \t|  2.4228         \t|\n",
      "get_validate_batch                 \t|  0.034207       \t|92             \t|  3.147          \t|  2.4228         \t|\n",
      "backward                           \t|  0.0063949      \t|352            \t|  2.251          \t|  1.733          \t|\n",
      "on_train_batch_end                 \t|  0.0019063      \t|352            \t|  0.671          \t|  0.51659        \t|\n",
      "training_batch_to_device           \t|  0.0019063      \t|352            \t|  0.671          \t|  0.51659        \t|\n",
      "zero_grad                          \t|  0.001642       \t|352            \t|  0.578          \t|  0.44499        \t|\n",
      "on_validation_batch_end            \t|  0.0025444      \t|90             \t|  0.229          \t|  0.1763         \t|\n",
      "on_train_batch_start               \t|  0.00040625     \t|352            \t|  0.143          \t|  0.11009        \t|\n",
      "evaluation_batch_to_device         \t|  0.0012         \t|90             \t|  0.108          \t|  0.083147       \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.031          \t|3              \t|  0.093          \t|  0.071598       \t|\n",
      "get_sanity_check_batch             \t|  0.031          \t|3              \t|  0.093          \t|  0.071598       \t|\n",
      "on_train_epoch_start               \t|  0.0019375      \t|16             \t|  0.031          \t|  0.023866       \t|\n",
      "on_validation_start                \t|  0.0032         \t|5              \t|  0.016          \t|  0.012318       \t|\n",
      "on_batch_end                       \t|  4.5455e-05     \t|352            \t|  0.016          \t|  0.012318       \t|\n",
      "on_batch_start                     \t|  4.2614e-05     \t|352            \t|  0.015          \t|  0.011548       \t|\n",
      "prepare_data                       \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "configure_callbacks                \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_before_accelerator_backend_setup\t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "setup                              \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "configure_sharded_model            \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_configure_sharded_model         \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "configure_optimizers               \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_fit_start                       \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_pretrain_routine_start          \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_pretrain_routine_end            \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_sanity_check_start              \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_val_dataloader                  \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "val_dataloader                     \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_validation_model_eval           \t|  0.0            \t|5              \t|  0.0            \t|  0.0            \t|\n",
      "on_epoch_start                     \t|  0.0            \t|21             \t|  0.0            \t|  0.0            \t|\n",
      "on_validation_epoch_start          \t|  0.0            \t|5              \t|  0.0            \t|  0.0            \t|\n",
      "on_validation_batch_start          \t|  0.0            \t|90             \t|  0.0            \t|  0.0            \t|\n",
      "validation_step_end                \t|  0.0            \t|90             \t|  0.0            \t|  0.0            \t|\n",
      "on_validation_epoch_end            \t|  0.0            \t|5              \t|  0.0            \t|  0.0            \t|\n",
      "on_epoch_end                       \t|  0.0            \t|21             \t|  0.0            \t|  0.0            \t|\n",
      "on_sanity_check_end                \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_train_dataloader                \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "train_dataloader                   \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_train_start                     \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "training_step_end                  \t|  0.0            \t|352            \t|  0.0            \t|  0.0            \t|\n",
      "on_before_zero_grad                \t|  0.0            \t|352            \t|  0.0            \t|  0.0            \t|\n",
      "on_before_backward                 \t|  0.0            \t|352            \t|  0.0            \t|  0.0            \t|\n",
      "on_after_backward                  \t|  0.0            \t|352            \t|  0.0            \t|  0.0            \t|\n",
      "on_before_optimizer_step           \t|  0.0            \t|352            \t|  0.0            \t|  0.0            \t|\n",
      "on_train_epoch_end                 \t|  0.0            \t|16             \t|  0.0            \t|  0.0            \t|\n",
      "on_train_end                       \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_fit_end                         \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "teardown                           \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%env CUDA_LAUNCH_BLOCKING=1\n",
    "\"\"\"\n",
    "AutoEncoder Models and/or different techniques used to encode the mesh to a smaller dimensions\n",
    "\"\"\"\n",
    "from Networks.VoxelAutoencoder import VoxelAutoencoder\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "model = VoxelAutoencoder(train_data, val_data, test_data, device)\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=\"Assets/Models/VoxelAutoencoder/\",\n",
    "    filename=\"voxel-autoencoder-{epoch:0004d}-{val_loss:.3f}\",\n",
    "    save_top_k=3,\n",
    "    mode=\"min\",\n",
    ")\n",
    "tqdm_progess_bar = TQDMProgressBar(refresh_rate=1)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1024,\n",
    "    gpus=1 if torch.cuda.is_available() else None,\n",
    "    log_every_n_steps=1,\n",
    "    logger=logger,\n",
    "    check_val_every_n_epoch=8,\n",
    "    callbacks=[model_checkpoint, tqdm_progess_bar],\n",
    "    profiler=\"simple\"\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae29df8e83a4e84b1b35aab5a5c4e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8970e9e38fce4a7e961233607db58ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_test_sample = val_data[0]\n",
    "\n",
    "visualize_occupancy(train_test_sample.squeeze(), flip_axes=True)\n",
    "\n",
    "tensor_test = torch.from_numpy(train_test_sample[np.newaxis, :])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    decoded_test = model(tensor_test)\n",
    "\n",
    "tmp_decoded = decoded_test.clone()\n",
    "tmp_decoded[decoded_test<0.5] = 0\n",
    "tmp_decoded[decoded_test>=0.5] = 1\n",
    "\n",
    "decoded_test_np = tmp_decoded.squeeze().detach().numpy()\n",
    "\n",
    "visualize_occupancy(decoded_test_np, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mesh Retreival Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Models/Techniques to use the previous encoding steps to retreive objects from a specified database\n",
    "\"\"\"\n",
    "# TODO: store latent vector of all shapenet models\n",
    "# TODO: encode voxel and find obj that has the closest latent vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and Full Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing the entire pipeline implemented with added visualizations and discussions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations\n",
    "\n",
    "[1]....."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7c2a59d5225d3a31d26be8da3fedd8f4fff04f1963eacdf138e0c401e96b304"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('i2dl': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

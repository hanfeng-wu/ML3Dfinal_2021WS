{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "All needed imports included here\n",
    "\"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: 1368\n",
      "Validation Set Size: 236\n",
      "Test Set Size: 383\n",
      "Voxel Dimensions: (1, 32, 32, 32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b07252b6454033b8fe1af5b116875a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create data loaders and augmentations needed here\n",
    "\"\"\"\n",
    "from Data.ShapeNetDataLoader import ShapeNetVoxelData\n",
    "from Utils.visualization import visualize_occupancy\n",
    "\n",
    "overfit = False\n",
    "\n",
    "shapenet_core_path = Path(\"D:\\ShapeNetCoreVoxel32\")\n",
    "shapenet_splits_csv_path = Path(\"Data/shapenet_splits.csv\")\n",
    "voxel_filename = \"model_3.binvox\"\n",
    "# load only models from some synsets\n",
    "synset_id_filter = [\"04379243\"]  # tables\n",
    "train_data = ShapeNetVoxelData(shapenet_core_path=shapenet_core_path, shapenet_splits_csv_path=shapenet_splits_csv_path, split=\"train\", \n",
    "    overfit=overfit, synset_id_filter=synset_id_filter, voxel_filename=voxel_filename\n",
    ")\n",
    "print(f\"Train Set Size: {len(train_data)}\")\n",
    "val_data = ShapeNetVoxelData(shapenet_core_path=shapenet_core_path, shapenet_splits_csv_path=shapenet_splits_csv_path, split=\"val\",\n",
    "    overfit=overfit, synset_id_filter=synset_id_filter, voxel_filename=voxel_filename\n",
    ")\n",
    "print(f\"Validation Set Size: {len(val_data)}\")\n",
    "test_data = ShapeNetVoxelData(shapenet_core_path=shapenet_core_path, shapenet_splits_csv_path=shapenet_splits_csv_path, split=\"test\",\n",
    "    overfit=overfit, synset_id_filter=synset_id_filter, voxel_filename=voxel_filename\n",
    ")\n",
    "print(f\"Test Set Size: {len(test_data)}\")\n",
    "\n",
    "train_sample = train_data[0]\n",
    "print(f'Voxel Dimensions: {train_sample.shape}')\n",
    "\n",
    "visualize_occupancy(train_sample.squeeze(), flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purifying predicted Meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCode to purify meshes predicted by the previous networks to be used in the retrieval step\\n'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Code to purify meshes predicted by the previous networks to be used in the retrieval step\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mesh Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  81%|████████  | 21/26 [00:23<00:05,  1.10s/it, loss=0.126, v_num=257]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type    | Params\n",
      "-----------------------------------\n",
      "0 | _model | Network | 34.2 M\n",
      "-----------------------------------\n",
      "34.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "34.2 M    Total params\n",
      "136.637   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  81%|████████  | 21/26 [00:24<00:05,  1.16s/it, loss=0.126, v_num=257]\n",
      "Epoch 334: 100%|██████████| 26/26 [00:07<00:00,  3.66it/s, loss=0.0255, v_num=257]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  2514.7         \t|  100 %          \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  7.5035         \t|335            \t|  2513.7         \t|  99.959         \t|\n",
      "run_training_batch                 \t|  0.25105        \t|7370           \t|  1850.2         \t|  73.575         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.12634        \t|7370           \t|  931.16         \t|  37.029         \t|\n",
      "training_step_and_backward         \t|  0.11624        \t|7370           \t|  856.69         \t|  34.067         \t|\n",
      "model_forward                      \t|  0.10951        \t|7370           \t|  807.11         \t|  32.096         \t|\n",
      "training_step                      \t|  0.1093         \t|7370           \t|  805.54         \t|  32.033         \t|\n",
      "get_train_batch                    \t|  0.031399       \t|7705           \t|  241.93         \t|  9.6207         \t|\n",
      "fetch_next_train_batch             \t|  0.031368       \t|7705           \t|  241.69         \t|  9.6112         \t|\n",
      "on_train_epoch_end                 \t|  0.55924        \t|335            \t|  187.34         \t|  7.4499         \t|\n",
      "evaluation_step_and_end            \t|  0.10473        \t|1342           \t|  140.54         \t|  5.5888         \t|\n",
      "validation_step                    \t|  0.10469        \t|1342           \t|  140.49         \t|  5.5869         \t|\n",
      "get_validate_batch                 \t|  0.02514        \t|1675           \t|  42.109         \t|  1.6745         \t|\n",
      "fetch_next_validate_batch          \t|  0.025121       \t|1675           \t|  42.077         \t|  1.6732         \t|\n",
      "backward                           \t|  0.0056453      \t|7370           \t|  41.606         \t|  1.6545         \t|\n",
      "on_train_batch_end                 \t|  0.0018858      \t|7370           \t|  13.898         \t|  0.55267        \t|\n",
      "training_batch_to_device           \t|  0.0018068      \t|7370           \t|  13.316         \t|  0.52953        \t|\n",
      "zero_grad                          \t|  0.0010389      \t|7370           \t|  7.657          \t|  0.30449        \t|\n",
      "on_validation_batch_end            \t|  0.002108       \t|1342           \t|  2.829          \t|  0.1125         \t|\n",
      "on_train_batch_start               \t|  0.00035482     \t|7370           \t|  2.615          \t|  0.10399        \t|\n",
      "evaluation_batch_to_device         \t|  0.0016349      \t|1342           \t|  2.194          \t|  0.087247       \t|\n",
      "on_validation_start                \t|  0.0052738      \t|336            \t|  1.772          \t|  0.070466       \t|\n",
      "on_validation_end                  \t|  0.0033006      \t|336            \t|  1.109          \t|  0.044101       \t|\n",
      "on_train_epoch_start               \t|  0.002009       \t|335            \t|  0.673          \t|  0.026763       \t|\n",
      "on_before_zero_grad                \t|  2.9172e-05     \t|7370           \t|  0.215          \t|  0.0085497      \t|\n",
      "on_after_backward                  \t|  2.5645e-05     \t|7370           \t|  0.189          \t|  0.0075158      \t|\n",
      "on_batch_end                       \t|  2.5102e-05     \t|7370           \t|  0.185          \t|  0.0073567      \t|\n",
      "on_batch_start                     \t|  2.3474e-05     \t|7370           \t|  0.173          \t|  0.0068795      \t|\n",
      "on_before_optimizer_step           \t|  2.3202e-05     \t|7370           \t|  0.171          \t|  0.0068         \t|\n",
      "on_before_backward                 \t|  1.8725e-05     \t|7370           \t|  0.138          \t|  0.0054877      \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.041333       \t|3              \t|  0.124          \t|  0.004931       \t|\n",
      "get_sanity_check_batch             \t|  0.041333       \t|3              \t|  0.124          \t|  0.004931       \t|\n",
      "on_validation_model_eval           \t|  0.00019048     \t|336            \t|  0.064          \t|  0.002545       \t|\n",
      "on_epoch_start                     \t|  2.3845e-05     \t|671            \t|  0.016          \t|  0.00063626     \t|\n",
      "on_pretrain_routine_start          \t|  0.016          \t|1              \t|  0.016          \t|  0.00063626     \t|\n",
      "on_validation_batch_start          \t|  1.1923e-05     \t|1342           \t|  0.016          \t|  0.00063626     \t|\n",
      "validation_step_end                \t|  1.1923e-05     \t|1342           \t|  0.016          \t|  0.00063626     \t|\n",
      "on_validation_epoch_end            \t|  4.7619e-05     \t|336            \t|  0.016          \t|  0.00063626     \t|\n",
      "on_epoch_end                       \t|  2.3845e-05     \t|671            \t|  0.016          \t|  0.00063626     \t|\n",
      "training_step_end                  \t|  2.171e-06      \t|7370           \t|  0.016          \t|  0.00063626     \t|\n",
      "prepare_data                       \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "configure_callbacks                \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_before_accelerator_backend_setup\t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "setup                              \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "configure_sharded_model            \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_configure_sharded_model         \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "configure_optimizers               \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_fit_start                       \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_pretrain_routine_end            \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_sanity_check_start              \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_val_dataloader                  \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "val_dataloader                     \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_validation_epoch_start          \t|  0.0            \t|336            \t|  0.0            \t|  0.0            \t|\n",
      "on_sanity_check_end                \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_train_dataloader                \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "train_dataloader                   \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_train_start                     \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_train_end                       \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "on_fit_end                         \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "teardown                           \t|  0.0            \t|1              \t|  0.0            \t|  0.0            \t|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%env CUDA_LAUNCH_BLOCKING=1\n",
    "\"\"\"\n",
    "AutoEncoder Models and/or different techniques used to encode the mesh to a smaller dimensions\n",
    "\"\"\"\n",
    "from Networks.VoxelAutoencoder import VoxelAutoencoder\n",
    "from pytorch_lightning.loggers.tensorboard import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# lower kl_divergence_scale -> smoother latent space but worse reconstruction\n",
    "kl_divergence_scale=0.05\n",
    "model = VoxelAutoencoder(train_data, val_data, test_data, device, kl_divergence_scale=kl_divergence_scale)\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=\"D:/Models/VoxelAutoencoder/\",\n",
    "    filename=\"voxel-autoencoder-{epoch:0004d}-{val_loss:.4f}\",\n",
    "    save_top_k=3,\n",
    "    every_n_epochs=8,\n",
    "    mode=\"min\",\n",
    ")\n",
    "tqdm_progess_bar = TQDMProgressBar(refresh_rate=1)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=64, mode=\"min\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1024,\n",
    "    gpus=1 if torch.cuda.is_available() else None,\n",
    "    log_every_n_steps=1,\n",
    "    logger=logger,\n",
    "    callbacks=[model_checkpoint, tqdm_progess_bar, early_stopping],\n",
    "    profiler=\"simple\"\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac24d45cb3fd4c418d90950379957d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acea6659d81d41b6b15cfca9c3bc6d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize reconstruction\n",
    "train_test_sample = test_data[1]\n",
    "\n",
    "visualize_occupancy(train_test_sample.squeeze(), flip_axes=True)\n",
    "\n",
    "sample_tensor = torch.from_numpy(train_test_sample[np.newaxis, :])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    decoded_test = model(sample_tensor)\n",
    "    print(model.encode(sample_tensor)[0].shape)\n",
    "\n",
    "tmp_decoded = decoded_test.clone()\n",
    "tmp_decoded[decoded_test<0.5] = 0\n",
    "tmp_decoded[decoded_test>=0.5] = 1\n",
    "\n",
    "decoded_test_np = tmp_decoded.squeeze().detach().numpy()\n",
    "\n",
    "visualize_occupancy(decoded_test_np, flip_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-8.1335e-01, -1.5713e+00, -1.0298e+00, -1.7457e+00,  2.8676e-01,\n",
      "        -8.4046e-01, -3.9098e-02, -1.1492e-02, -1.2321e-01, -3.0048e+00,\n",
      "        -1.3972e+00,  4.9813e-01,  2.8126e-01, -1.2275e+00,  1.4138e+00,\n",
      "         1.3568e+00,  2.2159e-01, -1.3605e-01,  1.6306e+00, -6.7599e-01,\n",
      "         5.0273e-01, -6.4468e-01, -1.1023e+00, -8.7999e-01,  1.7361e+00,\n",
      "         5.8381e-01, -1.8062e-01,  1.7283e-01,  1.0237e+00, -5.4272e-01,\n",
      "        -7.5886e-03,  4.3708e-01,  1.4482e+00, -1.4428e+00,  4.6320e-01,\n",
      "         9.5385e-01, -1.5240e-01, -3.9288e-01, -1.0642e-02, -9.9375e-01,\n",
      "        -1.5230e-01,  6.6617e-01,  7.0120e-02, -1.3126e+00,  5.2079e-02,\n",
      "         1.5797e+00, -5.2441e-01, -4.1080e-01, -7.2666e-01, -2.8784e-01,\n",
      "        -1.1763e+00,  9.6107e-01,  3.9524e-01, -3.0084e-04, -9.0999e-01,\n",
      "         4.2810e-01,  3.2235e-01, -6.3933e-01, -1.4902e+00, -2.6133e-02,\n",
      "         1.8495e-01,  6.7956e-01,  7.8874e-01,  4.5258e-01,  1.5660e+00,\n",
      "        -9.5898e-01, -8.6814e-01,  1.7663e+00, -5.9031e-01,  1.5460e-01,\n",
      "         2.7246e-01, -1.2334e+00,  6.2017e-02, -1.1993e+00, -1.3185e-01,\n",
      "        -6.2955e-02,  1.7249e+00,  5.2587e-01, -4.9548e-01,  1.4061e+00,\n",
      "         2.6985e-01, -8.4323e-01, -1.6599e+00,  1.7548e-01, -1.2539e+00,\n",
      "         4.5229e-01, -1.3331e-01, -4.0750e-01, -4.1965e-02, -1.3566e+00,\n",
      "         2.3174e+00,  2.3285e+00,  1.9595e+00, -1.2083e+00,  1.2082e+00,\n",
      "        -5.2887e-01, -9.3923e-01, -1.3175e+00,  2.7431e-01,  1.7737e+00,\n",
      "        -9.9175e-01, -9.2188e-01, -1.1273e+00, -8.0947e-01,  2.8380e+00,\n",
      "        -1.4422e-01,  1.0830e+00, -2.5658e-01,  6.8561e-01, -3.0795e-01,\n",
      "         1.0191e+00, -1.1616e-01,  1.1031e+00, -4.5167e-01, -1.0510e+00,\n",
      "        -1.3991e+00, -7.4863e-01,  1.0683e+00,  1.0067e+00, -2.3268e-01,\n",
      "        -4.5261e-01,  5.1688e-01, -1.9607e+00, -1.0977e+00,  5.4012e-02,\n",
      "         1.1550e+00, -7.4424e-01, -6.8052e-02]), array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., ..., 0., 0., 0.],\n",
      "         [0., 0., 1., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 1., ..., 0., 0., 0.],\n",
      "         [0., 0., 1., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# compute latent vectors of training samples\n",
    "latent_vectors = {}\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for train_sample in train_data:\n",
    "        sample_tensor = torch.from_numpy(train_sample[np.newaxis, :])\n",
    "        latent_vectors[model.encode(sample_tensor)[0]] = train_sample\n",
    "\n",
    "for latent_vector in latent_vectors.items():\n",
    "    print(latent_vector)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sample:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66255a0b2afc4d0da3b4a7cee34c5f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.6926)\n",
      "tensor(14.8235)\n",
      "tensor(14.4839)\n",
      "tensor(14.3314)\n",
      "tensor(13.5117)\n",
      "tensor(13.1566)\n",
      "Retrieved voxel:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a656fd86d854732aa425cfa553c5012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute latent vector of test sample\n",
    "test_sample = train_data[0]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_tensor = torch.from_numpy(test_sample[np.newaxis, :])\n",
    "    test_latent_vector = model.encode(sample_tensor)[0]\n",
    "\n",
    "print(\"Test sample:\")\n",
    "visualize_occupancy(test_sample.squeeze(), flip_axes=True)  \n",
    "\n",
    "# find closest latent vector\n",
    "min_distance = float('inf')\n",
    "best_voxel_match = None\n",
    "for train_latent_vector, train_voxel in latent_vectors.items():\n",
    "    distance = torch.dist(test_latent_vector, train_latent_vector)\n",
    "    if (distance < min_distance):\n",
    "        min_distance = distance\n",
    "        best_voxel_match = train_voxel\n",
    "        print(min_distance)\n",
    "\n",
    "print(\"Retrieved voxel:\")\n",
    "visualize_occupancy(best_voxel_match.squeeze(), flip_axes=True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mesh Retreival Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Models/Techniques to use the previous encoding steps to retreive objects from a specified database\n",
    "\"\"\"\n",
    "# TODO: store latent vector of all shapenet models\n",
    "# TODO: encode voxel and find obj that has the closest latent vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and Full Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing the entire pipeline implemented with added visualizations and discussions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations\n",
    "\n",
    "[1]....."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7c2a59d5225d3a31d26be8da3fedd8f4fff04f1963eacdf138e0c401e96b304"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('i2dl': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

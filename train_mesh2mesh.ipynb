{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from Networks.mesh2mesh import *\n",
    "from Networks.rgbd2mesh import RGBD2Mesh\n",
    "import trimesh\n",
    "from Networks.obj2pointcloud import *\n",
    "from Networks.pointclouddataset import *\n",
    "from chamferdist import ChamferDistance\n",
    "from Networks.foldingnet import FoldingNetDec\n",
    "from Networks import train_mesh2mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####1 get data for stage one autoencoder training\n",
    "\n",
    "train_dataset = pcd_stage1(split='train')\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,   # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "        batch_size=1,   # The size of batches is defined here\n",
    "        shuffle=True,    # Shuffling the order of samples is useful during training to prevent that the network learns to depend on the order of the input data\n",
    "        num_workers=4,   # Data is usually loaded in parallel by num_workers\n",
    "        pin_memory=True  # This is an implementation detail to speed up data uploading to the GPU\n",
    "    )\n",
    "val_dataset = pcd_stage1(split='val')\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,     # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "        batch_size=1,   # The size of batches is defined here\n",
    "        shuffle=False,   # During validation, shuffling is not necessary anymore\n",
    "        num_workers=4,   # Data is usually loaded in parallel by num_workers\n",
    "        pin_memory=True  # This is an implementation detail to speed up data uploading to the GPU\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Be carefull removing the model\n",
    "\n",
    "\n",
    "\n",
    "config = {\n",
    "    'experiment_name': 'pcd_stage1_overfit',\n",
    "    'device': 'cuda:0',                   # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': True,                   # True since we're doing overfitting\n",
    "    'batch_size': 1,\n",
    "    'resume_ckpt_en': None,\n",
    "    'resume_ckpt_de': None,\n",
    "    'learning_rate': 0.0001,\n",
    "    'max_epochs': 300,\n",
    "    'print_every_n': 100,\n",
    "    'validate_every_n': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "[001/00019] train_loss: 0.0189191915\n",
      "[001/00019] val_loss: 0.0065100389\n",
      "[002/00039] train_loss: 0.0066918780\n",
      "[002/00039] val_loss: 0.0057656527\n",
      "[003/00059] train_loss: 0.0055907195\n",
      "[003/00059] val_loss: 0.0055175549\n",
      "[004/00079] train_loss: 0.0065607616\n",
      "[004/00079] val_loss: 0.0057122614\n",
      "[006/00019] train_loss: 0.0062096286\n",
      "[006/00019] val_loss: 0.0061137844\n",
      "[007/00039] train_loss: 0.0052823322\n",
      "[007/00039] val_loss: 0.0050643082\n",
      "[008/00059] train_loss: 0.0059039012\n",
      "[008/00059] val_loss: 0.0051013329\n",
      "[009/00079] train_loss: 0.0047843145\n",
      "[009/00079] val_loss: 0.0049696155\n",
      "[011/00019] train_loss: 0.0048867470\n",
      "[011/00019] val_loss: 0.0057279938\n",
      "[012/00039] train_loss: 0.0047318251\n",
      "[012/00039] val_loss: 0.0037244379\n",
      "[013/00059] train_loss: 0.0034602307\n",
      "[013/00059] val_loss: 0.0027869330\n",
      "[014/00079] train_loss: 0.0027653593\n",
      "[014/00079] val_loss: 0.0023355766\n",
      "[016/00019] train_loss: 0.0024237112\n",
      "[016/00019] val_loss: 0.0023658171\n",
      "[017/00039] train_loss: 0.0025202188\n",
      "[017/00039] val_loss: 0.0022449715\n",
      "[018/00059] train_loss: 0.0021611624\n",
      "[018/00059] val_loss: 0.0020279128\n",
      "[019/00079] train_loss: 0.0022869436\n",
      "[019/00079] val_loss: 0.0019550787\n",
      "[021/00019] train_loss: 0.0021510517\n",
      "[021/00019] val_loss: 0.0019397080\n",
      "[022/00039] train_loss: 0.0020739128\n",
      "[022/00039] val_loss: 0.0018906897\n",
      "[023/00059] train_loss: 0.0020029242\n",
      "[023/00059] val_loss: 0.0018697529\n",
      "[024/00079] train_loss: 0.0019827980\n",
      "[024/00079] val_loss: 0.0019156690\n",
      "[026/00019] train_loss: 0.0021573605\n",
      "[026/00019] val_loss: 0.0018577905\n",
      "[027/00039] train_loss: 0.0018812815\n",
      "[027/00039] val_loss: 0.0018328499\n",
      "[028/00059] train_loss: 0.0019648578\n",
      "[028/00059] val_loss: 0.0017867162\n",
      "[029/00079] train_loss: 0.0021738952\n",
      "[029/00079] val_loss: 0.0018393142\n",
      "[031/00019] train_loss: 0.0019802426\n",
      "[031/00019] val_loss: 0.0017685315\n",
      "[032/00039] train_loss: 0.0019400365\n",
      "[032/00039] val_loss: 0.0017445851\n",
      "[033/00059] train_loss: 0.0018377974\n",
      "[033/00059] val_loss: 0.0017552406\n",
      "[034/00079] train_loss: 0.0020492379\n",
      "[034/00079] val_loss: 0.0017894527\n",
      "[036/00019] train_loss: 0.0018512252\n",
      "[036/00019] val_loss: 0.0017199354\n",
      "[037/00039] train_loss: 0.0018158578\n",
      "[037/00039] val_loss: 0.0020089319\n",
      "[038/00059] train_loss: 0.0019662368\n",
      "[038/00059] val_loss: 0.0017262799\n",
      "[039/00079] train_loss: 0.0018127221\n",
      "[039/00079] val_loss: 0.0018389862\n",
      "[041/00019] train_loss: 0.0018184027\n",
      "[041/00019] val_loss: 0.0017314584\n",
      "[042/00039] train_loss: 0.0018208537\n",
      "[042/00039] val_loss: 0.0019000847\n",
      "[043/00059] train_loss: 0.0018351232\n",
      "[043/00059] val_loss: 0.0016874273\n",
      "[044/00079] train_loss: 0.0017891157\n",
      "[044/00079] val_loss: 0.0016067075\n",
      "[046/00019] train_loss: 0.0016882178\n",
      "[046/00019] val_loss: 0.0018381616\n",
      "[047/00039] train_loss: 0.0016750879\n",
      "[047/00039] val_loss: 0.0016243330\n",
      "[048/00059] train_loss: 0.0016779128\n",
      "[048/00059] val_loss: 0.0016580606\n",
      "[049/00079] train_loss: 0.0017012390\n",
      "[049/00079] val_loss: 0.0017060217\n",
      "[051/00019] train_loss: 0.0017856145\n",
      "[051/00019] val_loss: 0.0016150766\n",
      "[052/00039] train_loss: 0.0018394368\n",
      "[052/00039] val_loss: 0.0015523322\n",
      "[053/00059] train_loss: 0.0016279901\n",
      "[053/00059] val_loss: 0.0015861653\n",
      "[054/00079] train_loss: 0.0017782144\n",
      "[054/00079] val_loss: 0.0016976722\n",
      "[056/00019] train_loss: 0.0018095712\n",
      "[056/00019] val_loss: 0.0015482346\n",
      "[057/00039] train_loss: 0.0016504654\n",
      "[057/00039] val_loss: 0.0015687405\n",
      "[058/00059] train_loss: 0.0016136684\n",
      "[058/00059] val_loss: 0.0015489212\n",
      "[059/00079] train_loss: 0.0015848390\n",
      "[059/00079] val_loss: 0.0015059427\n",
      "[061/00019] train_loss: 0.0015644462\n",
      "[061/00019] val_loss: 0.0014529339\n",
      "[062/00039] train_loss: 0.0014998771\n",
      "[062/00039] val_loss: 0.0015258760\n",
      "[063/00059] train_loss: 0.0014812484\n",
      "[063/00059] val_loss: 0.0015646144\n",
      "[064/00079] train_loss: 0.0017439445\n",
      "[064/00079] val_loss: 0.0014302187\n",
      "[066/00019] train_loss: 0.0015548222\n",
      "[066/00019] val_loss: 0.0015361445\n",
      "[067/00039] train_loss: 0.0014841708\n",
      "[067/00039] val_loss: 0.0014353184\n",
      "[068/00059] train_loss: 0.0015617875\n",
      "[068/00059] val_loss: 0.0014167068\n",
      "[069/00079] train_loss: 0.0014672778\n",
      "[069/00079] val_loss: 0.0013792793\n",
      "[071/00019] train_loss: 0.0013921200\n",
      "[071/00019] val_loss: 0.0012632668\n",
      "[072/00039] train_loss: 0.0013523275\n",
      "[072/00039] val_loss: 0.0013498226\n",
      "[073/00059] train_loss: 0.0012595668\n",
      "[073/00059] val_loss: 0.0011817785\n",
      "[074/00079] train_loss: 0.0012664088\n",
      "[074/00079] val_loss: 0.0011256438\n",
      "[076/00019] train_loss: 0.0011616465\n",
      "[076/00019] val_loss: 0.0011493271\n",
      "[077/00039] train_loss: 0.0012410827\n",
      "[077/00039] val_loss: 0.0011113691\n",
      "[078/00059] train_loss: 0.0011585865\n",
      "[078/00059] val_loss: 0.0012532306\n",
      "[079/00079] train_loss: 0.0013103681\n",
      "[079/00079] val_loss: 0.0014082328\n",
      "[081/00019] train_loss: 0.0012403337\n",
      "[081/00019] val_loss: 0.0010830484\n",
      "[082/00039] train_loss: 0.0011244222\n",
      "[082/00039] val_loss: 0.0011614501\n",
      "[083/00059] train_loss: 0.0012444486\n",
      "[083/00059] val_loss: 0.0011584045\n",
      "[084/00079] train_loss: 0.0013545064\n",
      "[084/00079] val_loss: 0.0011702513\n",
      "[086/00019] train_loss: 0.0012055540\n",
      "[086/00019] val_loss: 0.0011411491\n",
      "[087/00039] train_loss: 0.0010277563\n",
      "[087/00039] val_loss: 0.0010278890\n",
      "[088/00059] train_loss: 0.0011139583\n",
      "[088/00059] val_loss: 0.0010454854\n",
      "[089/00079] train_loss: 0.0011076527\n",
      "[089/00079] val_loss: 0.0010266708\n",
      "[091/00019] train_loss: 0.0010596554\n",
      "[091/00019] val_loss: 0.0010010616\n",
      "[092/00039] train_loss: 0.0010645165\n",
      "[092/00039] val_loss: 0.0010198514\n",
      "[093/00059] train_loss: 0.0012077897\n",
      "[093/00059] val_loss: 0.0009995567\n",
      "[094/00079] train_loss: 0.0010514772\n",
      "[094/00079] val_loss: 0.0009853934\n",
      "[096/00019] train_loss: 0.0010146982\n",
      "[096/00019] val_loss: 0.0011130805\n",
      "[097/00039] train_loss: 0.0010563264\n",
      "[097/00039] val_loss: 0.0009488136\n",
      "[098/00059] train_loss: 0.0010528018\n",
      "[098/00059] val_loss: 0.0009264603\n",
      "[099/00079] train_loss: 0.0009898716\n",
      "[099/00079] val_loss: 0.0009203297\n",
      "[101/00019] train_loss: 0.0011937223\n",
      "[101/00019] val_loss: 0.0009919297\n",
      "[102/00039] train_loss: 0.0009586666\n",
      "[102/00039] val_loss: 0.0009124220\n",
      "[103/00059] train_loss: 0.0009730960\n",
      "[103/00059] val_loss: 0.0009555965\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9e49d931ea5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_mesh2mesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Hanfeng/TUM/ML3D/ML3Dfinal_2021WS/Networks/train_mesh2mesh.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Hanfeng/TUM/ML3D/ML3Dfinal_2021WS/Networks/train_mesh2mesh.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, trainloader, valloader, device, config)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# loss logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mtrain_loss_running\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_mesh2mesh.main(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "[000/00099] train_loss: 0.0007168060\n",
      "[000/00099] val_loss: 0.0006033471\n",
      "[000/00199] train_loss: 0.0007950362\n",
      "[000/00199] val_loss: 0.0007556513\n",
      "[000/00299] train_loss: 0.0007420536\n",
      "[000/00299] val_loss: 0.0006384985\n",
      "[000/00399] train_loss: 0.0008447172\n",
      "[000/00399] val_loss: 0.0006559506\n",
      "[000/00499] train_loss: 0.0009390969\n",
      "[000/00499] val_loss: 0.0006362721\n",
      "[000/00599] train_loss: 0.0006838169\n",
      "[000/00599] val_loss: 0.0006181712\n",
      "[000/00699] train_loss: 0.0007863503\n",
      "[000/00699] val_loss: 0.0006372426\n",
      "[000/00799] train_loss: 0.0007451214\n",
      "[000/00799] val_loss: 0.0006312531\n",
      "[000/00899] train_loss: 0.0007174762\n",
      "[000/00899] val_loss: 0.0005934975\n",
      "[000/00999] train_loss: 0.0007488182\n",
      "[000/00999] val_loss: 0.0006222363\n",
      "[000/01099] train_loss: 0.0008030093\n",
      "[000/01099] val_loss: 0.0006594332\n",
      "[000/01199] train_loss: 0.0007632369\n",
      "[000/01199] val_loss: 0.0006239315\n",
      "[000/01299] train_loss: 0.0007546756\n",
      "[000/01299] val_loss: 0.0006130763\n",
      "[000/01399] train_loss: 0.0007612381\n",
      "[000/01399] val_loss: 0.0006755941\n",
      "[000/01499] train_loss: 0.0008088919\n",
      "[000/01499] val_loss: 0.0006578846\n",
      "[000/01599] train_loss: 0.0007932274\n",
      "[000/01599] val_loss: 0.0006104952\n",
      "[000/01699] train_loss: 0.0006563968\n",
      "[000/01699] val_loss: 0.0006057061\n",
      "[000/01799] train_loss: 0.0006691936\n",
      "[000/01799] val_loss: 0.0005916645\n",
      "[000/01899] train_loss: 0.0007291862\n",
      "[000/01899] val_loss: 0.0005958244\n",
      "[001/00079] train_loss: 0.0007398615\n",
      "[001/00079] val_loss: 0.0007172613\n",
      "[001/00179] train_loss: 0.0007384667\n",
      "[001/00179] val_loss: 0.0005974364\n",
      "[001/00279] train_loss: 0.0008543242\n",
      "[001/00279] val_loss: 0.0006125671\n",
      "[001/00379] train_loss: 0.0007916997\n",
      "[001/00379] val_loss: 0.0006151648\n",
      "[001/00479] train_loss: 0.0006612892\n",
      "[001/00479] val_loss: 0.0005901512\n",
      "[001/00579] train_loss: 0.0007314031\n",
      "[001/00579] val_loss: 0.0007328629\n",
      "[001/00679] train_loss: 0.0009549119\n",
      "[001/00679] val_loss: 0.0012493273\n",
      "[001/00779] train_loss: 0.0008408248\n",
      "[001/00779] val_loss: 0.0006679642\n",
      "[001/00879] train_loss: 0.0007360271\n",
      "[001/00879] val_loss: 0.0006148734\n",
      "[001/00979] train_loss: 0.0007125811\n",
      "[001/00979] val_loss: 0.0006183774\n",
      "[001/01079] train_loss: 0.0007897209\n",
      "[001/01079] val_loss: 0.0005868643\n",
      "[001/01179] train_loss: 0.0009493556\n",
      "[001/01179] val_loss: 0.0006233485\n",
      "[001/01279] train_loss: 0.0008740394\n",
      "[001/01279] val_loss: 0.0006034006\n",
      "[001/01379] train_loss: 0.0007724179\n",
      "[001/01379] val_loss: 0.0005939679\n",
      "[001/01479] train_loss: 0.0006509301\n",
      "[001/01479] val_loss: 0.0005682014\n",
      "[001/01579] train_loss: 0.0006891560\n",
      "[001/01579] val_loss: 0.0005736138\n",
      "[001/01679] train_loss: 0.0008093456\n",
      "[001/01679] val_loss: 0.0006046291\n",
      "[001/01779] train_loss: 0.0006211419\n",
      "[001/01779] val_loss: 0.0005814321\n",
      "[001/01879] train_loss: 0.0006400463\n",
      "[001/01879] val_loss: 0.0006153501\n",
      "[002/00059] train_loss: 0.0007041869\n",
      "[002/00059] val_loss: 0.0006123791\n",
      "[002/00159] train_loss: 0.0007160511\n",
      "[002/00159] val_loss: 0.0005966807\n",
      "[002/00259] train_loss: 0.0006799371\n",
      "[002/00259] val_loss: 0.0005806703\n",
      "[002/00359] train_loss: 0.0006655445\n",
      "[002/00359] val_loss: 0.0006129175\n",
      "[002/00459] train_loss: 0.0007118141\n",
      "[002/00459] val_loss: 0.0005851547\n",
      "[002/00559] train_loss: 0.0007039683\n",
      "[002/00559] val_loss: 0.0007405233\n",
      "[002/00659] train_loss: 0.0007568915\n",
      "[002/00659] val_loss: 0.0007982690\n",
      "[002/00759] train_loss: 0.0006633118\n",
      "[002/00759] val_loss: 0.0006129638\n",
      "[002/00859] train_loss: 0.0006802760\n",
      "[002/00859] val_loss: 0.0005752480\n",
      "[002/00959] train_loss: 0.0006460785\n",
      "[002/00959] val_loss: 0.0006422087\n",
      "[002/01059] train_loss: 0.0007926374\n",
      "[002/01059] val_loss: 0.0006215477\n",
      "[002/01159] train_loss: 0.0006793285\n",
      "[002/01159] val_loss: 0.0006610131\n",
      "[002/01259] train_loss: 0.0012919899\n",
      "[002/01259] val_loss: 0.0007254357\n",
      "[002/01359] train_loss: 0.0007150953\n",
      "[002/01359] val_loss: 0.0006381452\n",
      "[002/01459] train_loss: 0.0008572856\n",
      "[002/01459] val_loss: 0.0007476676\n",
      "[002/01559] train_loss: 0.0007675869\n",
      "[002/01559] val_loss: 0.0006136989\n",
      "[002/01659] train_loss: 0.0008143946\n",
      "[002/01659] val_loss: 0.0006489336\n",
      "[002/01759] train_loss: 0.0007424718\n",
      "[002/01759] val_loss: 0.0006164593\n",
      "[002/01859] train_loss: 0.0007009163\n",
      "[002/01859] val_loss: 0.0005874549\n",
      "[003/00039] train_loss: 0.0007491789\n",
      "[003/00039] val_loss: 0.0005752494\n",
      "[003/00139] train_loss: 0.0007048747\n",
      "[003/00139] val_loss: 0.0005686217\n",
      "[003/00239] train_loss: 0.0007479698\n",
      "[003/00239] val_loss: 0.0006613485\n",
      "[003/00339] train_loss: 0.0007112753\n",
      "[003/00339] val_loss: 0.0005928121\n",
      "[003/00439] train_loss: 0.0005912214\n",
      "[003/00439] val_loss: 0.0005446687\n",
      "[003/00539] train_loss: 0.0006970319\n",
      "[003/00539] val_loss: 0.0005934631\n",
      "[003/00639] train_loss: 0.0007484892\n",
      "[003/00639] val_loss: 0.0005633438\n",
      "[003/00739] train_loss: 0.0006895864\n",
      "[003/00739] val_loss: 0.0005898398\n",
      "[003/00839] train_loss: 0.0008015580\n",
      "[003/00839] val_loss: 0.0006605584\n",
      "[003/00939] train_loss: 0.0007600232\n",
      "[003/00939] val_loss: 0.0006141844\n",
      "[003/01039] train_loss: 0.0006410882\n",
      "[003/01039] val_loss: 0.0005892442\n",
      "[003/01139] train_loss: 0.0006362162\n",
      "[003/01139] val_loss: 0.0005837060\n",
      "[003/01239] train_loss: 0.0008203041\n",
      "[003/01239] val_loss: 0.0006112527\n",
      "[003/01339] train_loss: 0.0006761775\n",
      "[003/01339] val_loss: 0.0006091645\n",
      "[003/01439] train_loss: 0.0006482720\n",
      "[003/01439] val_loss: 0.0005803767\n",
      "[003/01539] train_loss: 0.0007355456\n",
      "[003/01539] val_loss: 0.0006117875\n",
      "[003/01639] train_loss: 0.0006849092\n",
      "[003/01639] val_loss: 0.0005998616\n",
      "[003/01739] train_loss: 0.0008005802\n",
      "[003/01739] val_loss: 0.0006005356\n",
      "[003/01839] train_loss: 0.0006910416\n",
      "[003/01839] val_loss: 0.0006384806\n",
      "[004/00019] train_loss: 0.0007168954\n",
      "[004/00019] val_loss: 0.0006334147\n",
      "[004/00119] train_loss: 0.0006825515\n",
      "[004/00119] val_loss: 0.0005687919\n",
      "[004/00219] train_loss: 0.0007660811\n",
      "[004/00219] val_loss: 0.0006028870\n",
      "[004/00319] train_loss: 0.0006660598\n",
      "[004/00319] val_loss: 0.0005736318\n",
      "[004/00419] train_loss: 0.0007162287\n",
      "[004/00419] val_loss: 0.0005662990\n",
      "[004/00519] train_loss: 0.0006209428\n",
      "[004/00519] val_loss: 0.0005994306\n",
      "[004/00619] train_loss: 0.0006408426\n",
      "[004/00619] val_loss: 0.0005706045\n",
      "[004/00719] train_loss: 0.0006892045\n",
      "[004/00719] val_loss: 0.0007333296\n",
      "[004/00819] train_loss: 0.0006460446\n",
      "[004/00819] val_loss: 0.0005610057\n",
      "[004/00919] train_loss: 0.0007251690\n",
      "[004/00919] val_loss: 0.0005915388\n",
      "[004/01019] train_loss: 0.0007686240\n",
      "[004/01019] val_loss: 0.0005921419\n",
      "[004/01119] train_loss: 0.0006566842\n",
      "[004/01119] val_loss: 0.0005733140\n",
      "[004/01219] train_loss: 0.0006816399\n",
      "[004/01219] val_loss: 0.0005581873\n",
      "[004/01319] train_loss: 0.0007395593\n",
      "[004/01319] val_loss: 0.0005792991\n",
      "[004/01419] train_loss: 0.0007597650\n",
      "[004/01419] val_loss: 0.0005991943\n",
      "[004/01519] train_loss: 0.0007821142\n",
      "[004/01519] val_loss: 0.0005705859\n",
      "[004/01619] train_loss: 0.0006403481\n",
      "[004/01619] val_loss: 0.0005899229\n",
      "[004/01719] train_loss: 0.0007428530\n",
      "[004/01719] val_loss: 0.0005729386\n",
      "[004/01819] train_loss: 0.0005883985\n",
      "[004/01819] val_loss: 0.0005344378\n",
      "[004/01919] train_loss: 0.0006619945\n",
      "[004/01919] val_loss: 0.0005478822\n",
      "[005/00099] train_loss: 0.0007690715\n",
      "[005/00099] val_loss: 0.0006137971\n",
      "[005/00199] train_loss: 0.0006703847\n",
      "[005/00199] val_loss: 0.0005560455\n",
      "[005/00299] train_loss: 0.0006889688\n",
      "[005/00299] val_loss: 0.0005782942\n",
      "[005/00399] train_loss: 0.0006884470\n",
      "[005/00399] val_loss: 0.0005583731\n",
      "[005/00499] train_loss: 0.0007452952\n",
      "[005/00499] val_loss: 0.0005462985\n",
      "[005/00599] train_loss: 0.0006478719\n",
      "[005/00599] val_loss: 0.0005801084\n",
      "[005/00699] train_loss: 0.0006326122\n",
      "[005/00699] val_loss: 0.0005614582\n",
      "[005/00799] train_loss: 0.0005779454\n",
      "[005/00799] val_loss: 0.0005754574\n",
      "[005/00899] train_loss: 0.0006032514\n",
      "[005/00899] val_loss: 0.0005630188\n",
      "[005/00999] train_loss: 0.0008183563\n",
      "[005/00999] val_loss: 0.0007452819\n",
      "[005/01099] train_loss: 0.0007102075\n",
      "[005/01099] val_loss: 0.0005710628\n",
      "[005/01199] train_loss: 0.0006399007\n",
      "[005/01199] val_loss: 0.0007789993\n",
      "[005/01299] train_loss: 0.0007651636\n",
      "[005/01299] val_loss: 0.0005326713\n",
      "[005/01399] train_loss: 0.0007287943\n",
      "[005/01399] val_loss: 0.0005742821\n",
      "[005/01499] train_loss: 0.0006996699\n",
      "[005/01499] val_loss: 0.0005569392\n",
      "[005/01599] train_loss: 0.0007100654\n",
      "[005/01599] val_loss: 0.0005568785\n",
      "[005/01699] train_loss: 0.0005935496\n",
      "[005/01699] val_loss: 0.0006068785\n",
      "[005/01799] train_loss: 0.0007148379\n",
      "[005/01799] val_loss: 0.0007744227\n",
      "[005/01899] train_loss: 0.0007716193\n",
      "[005/01899] val_loss: 0.0005737765\n",
      "[006/00079] train_loss: 0.0006835090\n",
      "[006/00079] val_loss: 0.0006201264\n",
      "[006/00179] train_loss: 0.0006663759\n",
      "[006/00179] val_loss: 0.0005586784\n",
      "[006/00279] train_loss: 0.0006349381\n",
      "[006/00279] val_loss: 0.0006319033\n",
      "[006/00379] train_loss: 0.0006320510\n",
      "[006/00379] val_loss: 0.0006213230\n",
      "[006/00479] train_loss: 0.0006998202\n",
      "[006/00479] val_loss: 0.0006040432\n",
      "[006/00579] train_loss: 0.0007630228\n",
      "[006/00579] val_loss: 0.0005552654\n",
      "[006/00679] train_loss: 0.0005988675\n",
      "[006/00679] val_loss: 0.0005291596\n",
      "[006/00779] train_loss: 0.0007035925\n",
      "[006/00779] val_loss: 0.0005373628\n",
      "[006/00879] train_loss: 0.0006843610\n",
      "[006/00879] val_loss: 0.0007019026\n",
      "[006/00979] train_loss: 0.0005644970\n",
      "[006/00979] val_loss: 0.0005638531\n",
      "[006/01079] train_loss: 0.0008216703\n",
      "[006/01079] val_loss: 0.0006267998\n",
      "[006/01179] train_loss: 0.0006680369\n",
      "[006/01179] val_loss: 0.0005804912\n",
      "[006/01279] train_loss: 0.0006811268\n",
      "[006/01279] val_loss: 0.0005565180\n",
      "[006/01379] train_loss: 0.0007225171\n",
      "[006/01379] val_loss: 0.0005929439\n",
      "[006/01479] train_loss: 0.0006538559\n",
      "[006/01479] val_loss: 0.0006274103\n",
      "[006/01579] train_loss: 0.0007000899\n",
      "[006/01579] val_loss: 0.0007553619\n",
      "[006/01679] train_loss: 0.0006585787\n",
      "[006/01679] val_loss: 0.0005319738\n",
      "[006/01779] train_loss: 0.0006078318\n",
      "[006/01779] val_loss: 0.0005293412\n",
      "[006/01879] train_loss: 0.0007811989\n",
      "[006/01879] val_loss: 0.0006137801\n",
      "[007/00059] train_loss: 0.0007321361\n",
      "[007/00059] val_loss: 0.0006086507\n",
      "[007/00159] train_loss: 0.0005856043\n",
      "[007/00159] val_loss: 0.0005465334\n",
      "[007/00259] train_loss: 0.0005825660\n",
      "[007/00259] val_loss: 0.0005572514\n",
      "[007/00359] train_loss: 0.0005847421\n",
      "[007/00359] val_loss: 0.0006172671\n",
      "[007/00459] train_loss: 0.0006685630\n",
      "[007/00459] val_loss: 0.0006315815\n",
      "[007/00559] train_loss: 0.0006192179\n",
      "[007/00559] val_loss: 0.0005440052\n",
      "[007/00659] train_loss: 0.0006595603\n",
      "[007/00659] val_loss: 0.0005359917\n",
      "[007/00759] train_loss: 0.0006464378\n",
      "[007/00759] val_loss: 0.0005521923\n",
      "[007/00859] train_loss: 0.0005871591\n",
      "[007/00859] val_loss: 0.0005648454\n",
      "[007/00959] train_loss: 0.0006688309\n",
      "[007/00959] val_loss: 0.0005434302\n",
      "[007/01059] train_loss: 0.0006496972\n",
      "[007/01059] val_loss: 0.0005801618\n",
      "[007/01159] train_loss: 0.0006692239\n",
      "[007/01159] val_loss: 0.0005476183\n",
      "[007/01259] train_loss: 0.0006290966\n",
      "[007/01259] val_loss: 0.0005712722\n",
      "[007/01359] train_loss: 0.0008346746\n",
      "[007/01359] val_loss: 0.0009920361\n",
      "[007/01459] train_loss: 0.0007220508\n",
      "[007/01459] val_loss: 0.0006442887\n",
      "[007/01559] train_loss: 0.0006843797\n",
      "[007/01559] val_loss: 0.0005862992\n",
      "[007/01659] train_loss: 0.0006128068\n",
      "[007/01659] val_loss: 0.0005722241\n",
      "[007/01759] train_loss: 0.0006545167\n",
      "[007/01759] val_loss: 0.0005810967\n",
      "[007/01859] train_loss: 0.0007100579\n",
      "[007/01859] val_loss: 0.0006382997\n",
      "[008/00039] train_loss: 0.0006409165\n",
      "[008/00039] val_loss: 0.0005502172\n",
      "[008/00139] train_loss: 0.0007611827\n",
      "[008/00139] val_loss: 0.0005527964\n",
      "[008/00239] train_loss: 0.0006918255\n",
      "[008/00239] val_loss: 0.0005664431\n",
      "[008/00339] train_loss: 0.0006587948\n",
      "[008/00339] val_loss: 0.0005430179\n",
      "[008/00439] train_loss: 0.0006296769\n",
      "[008/00439] val_loss: 0.0005512687\n",
      "[008/00539] train_loss: 0.0005948780\n",
      "[008/00539] val_loss: 0.0005297438\n",
      "[008/00639] train_loss: 0.0005829657\n",
      "[008/00639] val_loss: 0.0005414879\n",
      "[008/00739] train_loss: 0.0007000678\n",
      "[008/00739] val_loss: 0.0005827725\n",
      "[008/00839] train_loss: 0.0006466779\n",
      "[008/00839] val_loss: 0.0005607843\n",
      "[008/00939] train_loss: 0.0006550380\n",
      "[008/00939] val_loss: 0.0005421091\n",
      "[008/01039] train_loss: 0.0005325177\n",
      "[008/01039] val_loss: 0.0005368742\n",
      "[008/01139] train_loss: 0.0006412734\n",
      "[008/01139] val_loss: 0.0005701131\n",
      "[008/01239] train_loss: 0.0006793923\n",
      "[008/01239] val_loss: 0.0005473544\n",
      "[008/01339] train_loss: 0.0006423798\n",
      "[008/01339] val_loss: 0.0005400906\n",
      "[008/01439] train_loss: 0.0006455844\n",
      "[008/01439] val_loss: 0.0005585742\n",
      "[008/01539] train_loss: 0.0006397976\n",
      "[008/01539] val_loss: 0.0005423538\n",
      "[008/01639] train_loss: 0.0006538929\n",
      "[008/01639] val_loss: 0.0005940015\n",
      "[008/01739] train_loss: 0.0006382096\n",
      "[008/01739] val_loss: 0.0005713668\n",
      "[008/01839] train_loss: 0.0006401569\n",
      "[008/01839] val_loss: 0.0005334878\n",
      "[009/00019] train_loss: 0.0007925132\n",
      "[009/00019] val_loss: 0.0005763386\n",
      "[009/00119] train_loss: 0.0006137270\n",
      "[009/00119] val_loss: 0.0005754799\n",
      "[009/00219] train_loss: 0.0006512714\n",
      "[009/00219] val_loss: 0.0005337018\n",
      "[009/00319] train_loss: 0.0006682785\n",
      "[009/00319] val_loss: 0.0005479077\n",
      "[009/00419] train_loss: 0.0006796609\n",
      "[009/00419] val_loss: 0.0005574662\n",
      "[009/00519] train_loss: 0.0006147593\n",
      "[009/00519] val_loss: 0.0005202446\n",
      "[009/00619] train_loss: 0.0006349064\n",
      "[009/00619] val_loss: 0.0005980618\n",
      "[009/00719] train_loss: 0.0006091762\n",
      "[009/00719] val_loss: 0.0006150466\n",
      "[009/00819] train_loss: 0.0006504563\n",
      "[009/00819] val_loss: 0.0005740146\n",
      "[009/00919] train_loss: 0.0006198796\n",
      "[009/00919] val_loss: 0.0005258771\n",
      "[009/01019] train_loss: 0.0006012162\n",
      "[009/01019] val_loss: 0.0005578267\n",
      "[009/01119] train_loss: 0.0006072256\n",
      "[009/01119] val_loss: 0.0005287086\n",
      "[009/01219] train_loss: 0.0006387146\n",
      "[009/01219] val_loss: 0.0005723728\n",
      "[009/01319] train_loss: 0.0006967067\n",
      "[009/01319] val_loss: 0.0005249892\n",
      "[009/01419] train_loss: 0.0006116546\n",
      "[009/01419] val_loss: 0.0005832305\n",
      "[009/01519] train_loss: 0.0006037296\n",
      "[009/01519] val_loss: 0.0005405161\n",
      "[009/01619] train_loss: 0.0006325754\n",
      "[009/01619] val_loss: 0.0005699249\n",
      "[009/01719] train_loss: 0.0006073201\n",
      "[009/01719] val_loss: 0.0005525923\n",
      "[009/01819] train_loss: 0.0006154994\n",
      "[009/01819] val_loss: 0.0005633621\n",
      "[009/01919] train_loss: 0.0007039056\n",
      "[009/01919] val_loss: 0.0005263383\n",
      "[010/00099] train_loss: 0.0005545487\n",
      "[010/00099] val_loss: 0.0005125077\n",
      "[010/00199] train_loss: 0.0005932803\n",
      "[010/00199] val_loss: 0.0005653444\n",
      "[010/00299] train_loss: 0.0006080356\n",
      "[010/00299] val_loss: 0.0005507484\n",
      "[010/00399] train_loss: 0.0006398216\n",
      "[010/00399] val_loss: 0.0005211447\n",
      "[010/00499] train_loss: 0.0006190377\n",
      "[010/00499] val_loss: 0.0005473079\n",
      "[010/00599] train_loss: 0.0007082184\n",
      "[010/00599] val_loss: 0.0005983884\n",
      "[010/00699] train_loss: 0.0007000600\n",
      "[010/00699] val_loss: 0.0005212122\n",
      "[010/00799] train_loss: 0.0005920438\n",
      "[010/00799] val_loss: 0.0005370266\n",
      "[010/00899] train_loss: 0.0006309445\n",
      "[010/00899] val_loss: 0.0005304277\n",
      "[010/00999] train_loss: 0.0006724593\n",
      "[010/00999] val_loss: 0.0006239996\n",
      "[010/01099] train_loss: 0.0006344949\n",
      "[010/01099] val_loss: 0.0005392006\n",
      "[010/01199] train_loss: 0.0006045384\n",
      "[010/01199] val_loss: 0.0005149771\n",
      "[010/01299] train_loss: 0.0006266264\n",
      "[010/01299] val_loss: 0.0005171687\n",
      "[010/01399] train_loss: 0.0006746520\n",
      "[010/01399] val_loss: 0.0006114360\n",
      "[010/01499] train_loss: 0.0006251008\n",
      "[010/01499] val_loss: 0.0005414452\n",
      "[010/01599] train_loss: 0.0005957098\n",
      "[010/01599] val_loss: 0.0005340438\n",
      "[010/01699] train_loss: 0.0006831611\n",
      "[010/01699] val_loss: 0.0005678441\n",
      "[010/01799] train_loss: 0.0006245302\n",
      "[010/01799] val_loss: 0.0005926819\n",
      "[010/01899] train_loss: 0.0006349540\n",
      "[010/01899] val_loss: 0.0005651714\n",
      "[011/00079] train_loss: 0.0005747637\n",
      "[011/00079] val_loss: 0.0005227033\n",
      "[011/00179] train_loss: 0.0007762799\n",
      "[011/00179] val_loss: 0.0006352189\n",
      "[011/00279] train_loss: 0.0007159442\n",
      "[011/00279] val_loss: 0.0006574981\n",
      "[011/00379] train_loss: 0.0005986201\n",
      "[011/00379] val_loss: 0.0005283839\n",
      "[011/00479] train_loss: 0.0005035598\n",
      "[011/00479] val_loss: 0.0005200544\n",
      "[011/00579] train_loss: 0.0005399311\n",
      "[011/00579] val_loss: 0.0005881329\n",
      "[011/00679] train_loss: 0.0005796236\n",
      "[011/00679] val_loss: 0.0005432147\n",
      "[011/00779] train_loss: 0.0007080493\n",
      "[011/00779] val_loss: 0.0005498119\n",
      "[011/00879] train_loss: 0.0006581593\n",
      "[011/00879] val_loss: 0.0005774648\n",
      "[011/00979] train_loss: 0.0006772834\n",
      "[011/00979] val_loss: 0.0005313887\n",
      "[011/01079] train_loss: 0.0006219741\n",
      "[011/01079] val_loss: 0.0005632184\n",
      "[011/01179] train_loss: 0.0007226356\n",
      "[011/01179] val_loss: 0.0005633422\n",
      "[011/01279] train_loss: 0.0006434065\n",
      "[011/01279] val_loss: 0.0005636515\n",
      "[011/01379] train_loss: 0.0005994472\n",
      "[011/01379] val_loss: 0.0005444786\n",
      "[011/01479] train_loss: 0.0005824004\n",
      "[011/01479] val_loss: 0.0005561451\n",
      "[011/01579] train_loss: 0.0005706725\n",
      "[011/01579] val_loss: 0.0005241408\n",
      "[011/01679] train_loss: 0.0005838111\n",
      "[011/01679] val_loss: 0.0005339243\n",
      "[011/01779] train_loss: 0.0007054694\n",
      "[011/01779] val_loss: 0.0005095799\n",
      "[011/01879] train_loss: 0.0006467752\n",
      "[011/01879] val_loss: 0.0005690737\n",
      "[012/00059] train_loss: 0.0006053473\n",
      "[012/00059] val_loss: 0.0006006957\n",
      "[012/00159] train_loss: 0.0005702752\n",
      "[012/00159] val_loss: 0.0005302762\n",
      "[012/00259] train_loss: 0.0006053878\n",
      "[012/00259] val_loss: 0.0005382011\n",
      "[012/00359] train_loss: 0.0005909176\n",
      "[012/00359] val_loss: 0.0005738316\n",
      "[012/00459] train_loss: 0.0005567984\n",
      "[012/00459] val_loss: 0.0005197880\n",
      "[012/00559] train_loss: 0.0005527784\n",
      "[012/00559] val_loss: 0.0005802623\n",
      "[012/00659] train_loss: 0.0006055245\n",
      "[012/00659] val_loss: 0.0005330906\n",
      "[012/00759] train_loss: 0.0006709469\n",
      "[012/00759] val_loss: 0.0005511681\n",
      "[012/00859] train_loss: 0.0006314591\n",
      "[012/00859] val_loss: 0.0005587123\n",
      "[012/00959] train_loss: 0.0005824923\n",
      "[012/00959] val_loss: 0.0005127261\n",
      "[012/01059] train_loss: 0.0005706865\n",
      "[012/01059] val_loss: 0.0005908214\n",
      "[012/01159] train_loss: 0.0006457689\n",
      "[012/01159] val_loss: 0.0005863917\n",
      "[012/01259] train_loss: 0.0006500737\n",
      "[012/01259] val_loss: 0.0005555965\n",
      "[012/01359] train_loss: 0.0005948684\n",
      "[012/01359] val_loss: 0.0005232363\n",
      "[012/01459] train_loss: 0.0006179868\n",
      "[012/01459] val_loss: 0.0005377328\n",
      "[012/01559] train_loss: 0.0005830654\n",
      "[012/01559] val_loss: 0.0005766822\n",
      "[012/01659] train_loss: 0.0006422492\n",
      "[012/01659] val_loss: 0.0005139292\n",
      "[012/01759] train_loss: 0.0006517468\n",
      "[012/01759] val_loss: 0.0005887436\n",
      "[012/01859] train_loss: 0.0005662424\n",
      "[012/01859] val_loss: 0.0005217912\n",
      "[013/00039] train_loss: 0.0007034856\n",
      "[013/00039] val_loss: 0.0005737102\n",
      "[013/00139] train_loss: 0.0005609642\n",
      "[013/00139] val_loss: 0.0005407233\n",
      "[013/00239] train_loss: 0.0006051576\n",
      "[013/00239] val_loss: 0.0005371996\n",
      "[013/00339] train_loss: 0.0005764927\n",
      "[013/00339] val_loss: 0.0005492363\n",
      "[013/00439] train_loss: 0.0004844881\n",
      "[013/00439] val_loss: 0.0005253548\n",
      "[013/00539] train_loss: 0.0005241751\n",
      "[013/00539] val_loss: 0.0005428665\n",
      "[013/00639] train_loss: 0.0006506029\n",
      "[013/00639] val_loss: 0.0005159782\n",
      "[013/00739] train_loss: 0.0005882645\n",
      "[013/00739] val_loss: 0.0005476383\n",
      "[013/00839] train_loss: 0.0006190713\n",
      "[013/00839] val_loss: 0.0005348204\n",
      "[013/00939] train_loss: 0.0005310307\n",
      "[013/00939] val_loss: 0.0005041061\n",
      "[013/01039] train_loss: 0.0006979844\n",
      "[013/01039] val_loss: 0.0005600397\n",
      "[013/01139] train_loss: 0.0006638601\n",
      "[013/01139] val_loss: 0.0005666912\n",
      "[013/01239] train_loss: 0.0007257294\n",
      "[013/01239] val_loss: 0.0005241795\n",
      "[013/01339] train_loss: 0.0006688987\n",
      "[013/01339] val_loss: 0.0005488560\n",
      "[013/01439] train_loss: 0.0006695363\n",
      "[013/01439] val_loss: 0.0005702908\n",
      "[013/01539] train_loss: 0.0006251956\n",
      "[013/01539] val_loss: 0.0005480316\n",
      "[013/01639] train_loss: 0.0005618020\n",
      "[013/01639] val_loss: 0.0005159575\n",
      "[013/01739] train_loss: 0.0006273073\n",
      "[013/01739] val_loss: 0.0004924673\n",
      "[013/01839] train_loss: 0.0006207669\n",
      "[013/01839] val_loss: 0.0005429108\n",
      "[014/00019] train_loss: 0.0006289089\n",
      "[014/00019] val_loss: 0.0005396349\n",
      "[014/00119] train_loss: 0.0005710480\n",
      "[014/00119] val_loss: 0.0005107538\n",
      "[014/00219] train_loss: 0.0005964558\n",
      "[014/00219] val_loss: 0.0004962942\n",
      "[014/00319] train_loss: 0.0005312589\n",
      "[014/00319] val_loss: 0.0005016706\n",
      "[014/00419] train_loss: 0.0005622319\n",
      "[014/00419] val_loss: 0.0005251245\n",
      "[014/00519] train_loss: 0.0005545548\n",
      "[014/00519] val_loss: 0.0005370747\n",
      "[014/00619] train_loss: 0.0006038170\n",
      "[014/00619] val_loss: 0.0005127961\n",
      "[014/00719] train_loss: 0.0005816016\n",
      "[014/00719] val_loss: 0.0005028051\n",
      "[014/00819] train_loss: 0.0005928034\n",
      "[014/00819] val_loss: 0.0005234895\n",
      "[014/00919] train_loss: 0.0005220736\n",
      "[014/00919] val_loss: 0.0005526537\n",
      "[014/01019] train_loss: 0.0006225108\n",
      "[014/01019] val_loss: 0.0006857614\n",
      "[014/01119] train_loss: 0.0010199266\n",
      "[014/01119] val_loss: 0.0006387880\n",
      "[014/01219] train_loss: 0.0006988539\n",
      "[014/01219] val_loss: 0.0005466495\n",
      "[014/01319] train_loss: 0.0006134863\n",
      "[014/01319] val_loss: 0.0005079936\n",
      "[014/01419] train_loss: 0.0005605655\n",
      "[014/01419] val_loss: 0.0004950535\n",
      "[014/01519] train_loss: 0.0005815355\n",
      "[014/01519] val_loss: 0.0004974382\n",
      "[014/01619] train_loss: 0.0005510335\n",
      "[014/01619] val_loss: 0.0005229072\n",
      "[014/01719] train_loss: 0.0007215111\n",
      "[014/01719] val_loss: 0.0005458565\n",
      "[014/01819] train_loss: 0.0005888845\n",
      "[014/01819] val_loss: 0.0005257886\n",
      "[014/01919] train_loss: 0.0006165349\n",
      "[014/01919] val_loss: 0.0005138497\n",
      "[015/00099] train_loss: 0.0005958464\n",
      "[015/00099] val_loss: 0.0005337365\n",
      "[015/00199] train_loss: 0.0005857518\n",
      "[015/00199] val_loss: 0.0004994123\n",
      "[015/00299] train_loss: 0.0005798112\n",
      "[015/00299] val_loss: 0.0005020684\n",
      "[015/00399] train_loss: 0.0005167064\n",
      "[015/00399] val_loss: 0.0005020826\n",
      "[015/00499] train_loss: 0.0005338404\n",
      "[015/00499] val_loss: 0.0005320331\n",
      "[015/00599] train_loss: 0.0006201221\n",
      "[015/00599] val_loss: 0.0005157525\n",
      "[015/00699] train_loss: 0.0005702339\n",
      "[015/00699] val_loss: 0.0005260266\n",
      "[015/00799] train_loss: 0.0005499236\n",
      "[015/00799] val_loss: 0.0005365322\n",
      "[015/00899] train_loss: 0.0005347165\n",
      "[015/00899] val_loss: 0.0005025395\n",
      "[015/00999] train_loss: 0.0005587871\n",
      "[015/00999] val_loss: 0.0005146804\n",
      "[015/01099] train_loss: 0.0006252439\n",
      "[015/01099] val_loss: 0.0005044711\n",
      "[015/01199] train_loss: 0.0006053224\n",
      "[015/01199] val_loss: 0.0005725004\n",
      "[015/01299] train_loss: 0.0006427243\n",
      "[015/01299] val_loss: 0.0005081078\n",
      "[015/01399] train_loss: 0.0005164245\n",
      "[015/01399] val_loss: 0.0004838186\n",
      "[015/01499] train_loss: 0.0005489248\n",
      "[015/01499] val_loss: 0.0005171696\n",
      "[015/01599] train_loss: 0.0005664103\n",
      "[015/01599] val_loss: 0.0004918058\n",
      "[015/01699] train_loss: 0.0006127585\n",
      "[015/01699] val_loss: 0.0005123664\n",
      "[015/01799] train_loss: 0.0006152543\n",
      "[015/01799] val_loss: 0.0008329674\n",
      "[015/01899] train_loss: 0.0007640966\n",
      "[015/01899] val_loss: 0.0005840768\n",
      "[016/00079] train_loss: 0.0005863611\n",
      "[016/00079] val_loss: 0.0005467127\n",
      "[016/00179] train_loss: 0.0005484476\n",
      "[016/00179] val_loss: 0.0005063418\n",
      "[016/00279] train_loss: 0.0005066095\n",
      "[016/00279] val_loss: 0.0005293774\n",
      "[016/00379] train_loss: 0.0008123673\n",
      "[016/00379] val_loss: 0.0005362642\n",
      "[016/00479] train_loss: 0.0006907556\n",
      "[016/00479] val_loss: 0.0005403038\n",
      "[016/00579] train_loss: 0.0005767939\n",
      "[016/00579] val_loss: 0.0005851327\n",
      "[016/00679] train_loss: 0.0006343574\n",
      "[016/00679] val_loss: 0.0005200332\n",
      "[016/00779] train_loss: 0.0007049698\n",
      "[016/00779] val_loss: 0.0006025203\n",
      "[016/00879] train_loss: 0.0005330275\n",
      "[016/00879] val_loss: 0.0004950908\n",
      "[016/00979] train_loss: 0.0005929895\n",
      "[016/00979] val_loss: 0.0005212649\n",
      "[016/01079] train_loss: 0.0005879112\n",
      "[016/01079] val_loss: 0.0005148820\n",
      "[016/01179] train_loss: 0.0005965808\n",
      "[016/01179] val_loss: 0.0005220389\n",
      "[016/01279] train_loss: 0.0005907464\n",
      "[016/01279] val_loss: 0.0004874852\n",
      "[016/01379] train_loss: 0.0005696317\n",
      "[016/01379] val_loss: 0.0005230543\n",
      "[016/01479] train_loss: 0.0005796487\n",
      "[016/01479] val_loss: 0.0005262291\n",
      "[016/01579] train_loss: 0.0005259011\n",
      "[016/01579] val_loss: 0.0005253186\n",
      "[016/01679] train_loss: 0.0005814462\n",
      "[016/01679] val_loss: 0.0004865055\n",
      "[016/01779] train_loss: 0.0004660149\n",
      "[016/01779] val_loss: 0.0004988536\n",
      "[016/01879] train_loss: 0.0005591200\n",
      "[016/01879] val_loss: 0.0004945124\n",
      "[017/00059] train_loss: 0.0005981031\n",
      "[017/00059] val_loss: 0.0005004858\n",
      "[017/00159] train_loss: 0.0004426505\n",
      "[017/00159] val_loss: 0.0005001635\n",
      "[017/00259] train_loss: 0.0005831896\n",
      "[017/00259] val_loss: 0.0005657224\n",
      "[017/00359] train_loss: 0.0005303000\n",
      "[017/00359] val_loss: 0.0005005714\n",
      "[017/00459] train_loss: 0.0005475315\n",
      "[017/00459] val_loss: 0.0005083931\n",
      "[017/00559] train_loss: 0.0005887875\n",
      "[017/00559] val_loss: 0.0005518674\n",
      "[017/00659] train_loss: 0.0005973329\n",
      "[017/00659] val_loss: 0.0004942217\n",
      "[017/00759] train_loss: 0.0005636674\n",
      "[017/00759] val_loss: 0.0004954181\n",
      "[017/00859] train_loss: 0.0005896859\n",
      "[017/00859] val_loss: 0.0004956333\n",
      "[017/00959] train_loss: 0.0005280787\n",
      "[017/00959] val_loss: 0.0004829812\n",
      "[017/01059] train_loss: 0.0005686894\n",
      "[017/01059] val_loss: 0.0005048854\n",
      "[017/01159] train_loss: 0.0005652764\n",
      "[017/01159] val_loss: 0.0005080833\n",
      "[017/01259] train_loss: 0.0005215861\n",
      "[017/01259] val_loss: 0.0004846340\n",
      "[017/01359] train_loss: 0.0005582375\n",
      "[017/01359] val_loss: 0.0005123005\n",
      "[017/01459] train_loss: 0.0005992560\n",
      "[017/01459] val_loss: 0.0005280045\n",
      "[017/01559] train_loss: 0.0006653389\n",
      "[017/01559] val_loss: 0.0005238679\n",
      "[017/01659] train_loss: 0.0005400183\n",
      "[017/01659] val_loss: 0.0005007981\n",
      "[017/01759] train_loss: 0.0005614619\n",
      "[017/01759] val_loss: 0.0005559062\n",
      "[017/01859] train_loss: 0.0005643854\n",
      "[017/01859] val_loss: 0.0005110082\n",
      "[018/00039] train_loss: 0.0005759198\n",
      "[018/00039] val_loss: 0.0005006042\n",
      "[018/00139] train_loss: 0.0005172456\n",
      "[018/00139] val_loss: 0.0004793225\n",
      "[018/00239] train_loss: 0.0005075914\n",
      "[018/00239] val_loss: 0.0004921315\n",
      "[018/00339] train_loss: 0.0005091263\n",
      "[018/00339] val_loss: 0.0004983650\n",
      "[018/00439] train_loss: 0.0006379445\n",
      "[018/00439] val_loss: 0.0005599555\n",
      "[018/00539] train_loss: 0.0006242049\n",
      "[018/00539] val_loss: 0.0006966860\n",
      "[018/00639] train_loss: 0.0007446368\n",
      "[018/00639] val_loss: 0.0005017212\n",
      "[018/00739] train_loss: 0.0005922566\n",
      "[018/00739] val_loss: 0.0005241515\n",
      "[018/00839] train_loss: 0.0004985844\n",
      "[018/00839] val_loss: 0.0004928756\n",
      "[018/00939] train_loss: 0.0005415121\n",
      "[018/00939] val_loss: 0.0005098434\n",
      "[018/01039] train_loss: 0.0005721918\n",
      "[018/01039] val_loss: 0.0005100198\n",
      "[018/01139] train_loss: 0.0005069546\n",
      "[018/01139] val_loss: 0.0005093885\n",
      "[018/01239] train_loss: 0.0005552005\n",
      "[018/01239] val_loss: 0.0005241427\n",
      "[018/01339] train_loss: 0.0005808895\n",
      "[018/01339] val_loss: 0.0004979208\n",
      "[018/01439] train_loss: 0.0005349410\n",
      "[018/01439] val_loss: 0.0005084326\n",
      "[018/01539] train_loss: 0.0005977888\n",
      "[018/01539] val_loss: 0.0005035430\n",
      "[018/01639] train_loss: 0.0005539106\n",
      "[018/01639] val_loss: 0.0005149736\n",
      "[018/01739] train_loss: 0.0006361050\n",
      "[018/01739] val_loss: 0.0005047002\n",
      "[018/01839] train_loss: 0.0006398067\n",
      "[018/01839] val_loss: 0.0005015474\n",
      "[019/00019] train_loss: 0.0005307080\n",
      "[019/00019] val_loss: 0.0004821946\n",
      "[019/00119] train_loss: 0.0005903100\n",
      "[019/00119] val_loss: 0.0004829060\n",
      "[019/00219] train_loss: 0.0005043843\n",
      "[019/00219] val_loss: 0.0004833156\n",
      "[019/00319] train_loss: 0.0005513035\n",
      "[019/00319] val_loss: 0.0004828404\n",
      "[019/00419] train_loss: 0.0005902263\n",
      "[019/00419] val_loss: 0.0004987362\n",
      "[019/00519] train_loss: 0.0005353743\n",
      "[019/00519] val_loss: 0.0004827074\n",
      "[019/00619] train_loss: 0.0004912355\n",
      "[019/00619] val_loss: 0.0004765731\n",
      "[019/00719] train_loss: 0.0005353107\n",
      "[019/00719] val_loss: 0.0006564012\n",
      "[019/00819] train_loss: 0.0005686176\n",
      "[019/00819] val_loss: 0.0004995944\n",
      "[019/00919] train_loss: 0.0005854074\n",
      "[019/00919] val_loss: 0.0005063218\n",
      "[019/01019] train_loss: 0.0005946845\n",
      "[019/01019] val_loss: 0.0004792470\n",
      "[019/01119] train_loss: 0.0005819040\n",
      "[019/01119] val_loss: 0.0005512008\n",
      "[019/01219] train_loss: 0.0005613165\n",
      "[019/01219] val_loss: 0.0005045169\n",
      "[019/01319] train_loss: 0.0005659475\n",
      "[019/01319] val_loss: 0.0005077095\n",
      "[019/01419] train_loss: 0.0006026407\n",
      "[019/01419] val_loss: 0.0005266586\n",
      "[019/01519] train_loss: 0.0005758818\n",
      "[019/01519] val_loss: 0.0004934630\n",
      "[019/01619] train_loss: 0.0005608904\n",
      "[019/01619] val_loss: 0.0004922325\n",
      "[019/01719] train_loss: 0.0005254947\n",
      "[019/01719] val_loss: 0.0005007312\n",
      "[019/01819] train_loss: 0.0005543985\n",
      "[019/01819] val_loss: 0.0004959460\n",
      "[019/01919] train_loss: 0.0005100534\n",
      "[019/01919] val_loss: 0.0004986312\n",
      "[020/00099] train_loss: 0.0005105980\n",
      "[020/00099] val_loss: 0.0006335403\n",
      "[020/00199] train_loss: 0.0005360986\n",
      "[020/00199] val_loss: 0.0004798922\n",
      "[020/00299] train_loss: 0.0006529616\n",
      "[020/00299] val_loss: 0.0005518214\n",
      "[020/00399] train_loss: 0.0005825139\n",
      "[020/00399] val_loss: 0.0005049349\n",
      "[020/00499] train_loss: 0.0005512514\n",
      "[020/00499] val_loss: 0.0004839005\n",
      "[020/00599] train_loss: 0.0005132736\n",
      "[020/00599] val_loss: 0.0004949032\n",
      "[020/00699] train_loss: 0.0005426543\n",
      "[020/00699] val_loss: 0.0004843323\n",
      "[020/00799] train_loss: 0.0005388591\n",
      "[020/00799] val_loss: 0.0004907394\n",
      "[020/00899] train_loss: 0.0005607216\n",
      "[020/00899] val_loss: 0.0005138007\n",
      "[020/00999] train_loss: 0.0005862020\n",
      "[020/00999] val_loss: 0.0005007989\n",
      "[020/01099] train_loss: 0.0005192909\n",
      "[020/01099] val_loss: 0.0004873694\n",
      "[020/01199] train_loss: 0.0005218557\n",
      "[020/01199] val_loss: 0.0004890813\n",
      "[020/01299] train_loss: 0.0005436224\n",
      "[020/01299] val_loss: 0.0005016776\n",
      "[020/01399] train_loss: 0.0005188911\n",
      "[020/01399] val_loss: 0.0004748228\n",
      "[020/01499] train_loss: 0.0005054688\n",
      "[020/01499] val_loss: 0.0004840062\n",
      "[020/01599] train_loss: 0.0005422601\n",
      "[020/01599] val_loss: 0.0004626496\n",
      "[020/01699] train_loss: 0.0005313314\n",
      "[020/01699] val_loss: 0.0004828308\n",
      "[020/01799] train_loss: 0.0005429912\n",
      "[020/01799] val_loss: 0.0005392825\n",
      "[020/01899] train_loss: 0.0005423927\n",
      "[020/01899] val_loss: 0.0005192324\n",
      "[021/00079] train_loss: 0.0005498015\n",
      "[021/00079] val_loss: 0.0005098041\n",
      "[021/00179] train_loss: 0.0005290660\n",
      "[021/00179] val_loss: 0.0004925450\n",
      "[021/00279] train_loss: 0.0005416342\n",
      "[021/00279] val_loss: 0.0005343905\n",
      "[021/00379] train_loss: 0.0005433234\n",
      "[021/00379] val_loss: 0.0004680383\n",
      "[021/00479] train_loss: 0.0004757223\n",
      "[021/00479] val_loss: 0.0004787196\n",
      "[021/00579] train_loss: 0.0005150897\n",
      "[021/00579] val_loss: 0.0004968829\n",
      "[021/00679] train_loss: 0.0005116795\n",
      "[021/00679] val_loss: 0.0005084396\n",
      "[021/00779] train_loss: 0.0005050260\n",
      "[021/00779] val_loss: 0.0004745305\n",
      "[021/00879] train_loss: 0.0005298080\n",
      "[021/00879] val_loss: 0.0004802875\n",
      "[021/00979] train_loss: 0.0005157649\n",
      "[021/00979] val_loss: 0.0005068668\n",
      "[021/01079] train_loss: 0.0006338858\n",
      "[021/01079] val_loss: 0.0005260331\n",
      "[021/01179] train_loss: 0.0005593744\n",
      "[021/01179] val_loss: 0.0004720161\n",
      "[021/01279] train_loss: 0.0005533546\n",
      "[021/01279] val_loss: 0.0005583132\n",
      "[021/01379] train_loss: 0.0005655727\n",
      "[021/01379] val_loss: 0.0004925670\n",
      "[021/01479] train_loss: 0.0005963915\n",
      "[021/01479] val_loss: 0.0004958069\n",
      "[021/01579] train_loss: 0.0005321859\n",
      "[021/01579] val_loss: 0.0004778927\n",
      "[021/01679] train_loss: 0.0005467019\n",
      "[021/01679] val_loss: 0.0005053487\n",
      "[021/01779] train_loss: 0.0005336459\n",
      "[021/01779] val_loss: 0.0005152106\n",
      "[021/01879] train_loss: 0.0005290111\n",
      "[021/01879] val_loss: 0.0004860410\n",
      "[022/00059] train_loss: 0.0005962425\n",
      "[022/00059] val_loss: 0.0004923459\n",
      "[022/00159] train_loss: 0.0005029249\n",
      "[022/00159] val_loss: 0.0004845170\n",
      "[022/00259] train_loss: 0.0005448913\n",
      "[022/00259] val_loss: 0.0005287558\n",
      "[022/00359] train_loss: 0.0005603679\n",
      "[022/00359] val_loss: 0.0004956753\n",
      "[022/00459] train_loss: 0.0005344045\n",
      "[022/00459] val_loss: 0.0004940108\n",
      "[022/00559] train_loss: 0.0006247237\n",
      "[022/00559] val_loss: 0.0005833867\n",
      "[022/00659] train_loss: 0.0005274371\n",
      "[022/00659] val_loss: 0.0004866780\n",
      "[022/00759] train_loss: 0.0004842604\n",
      "[022/00759] val_loss: 0.0004747212\n",
      "[022/00859] train_loss: 0.0005241840\n",
      "[022/00859] val_loss: 0.0004733274\n",
      "[022/00959] train_loss: 0.0005082318\n",
      "[022/00959] val_loss: 0.0004912684\n",
      "[022/01059] train_loss: 0.0005330420\n",
      "[022/01059] val_loss: 0.0004900217\n",
      "[022/01159] train_loss: 0.0005465919\n",
      "[022/01159] val_loss: 0.0005017508\n",
      "[022/01259] train_loss: 0.0005102623\n",
      "[022/01259] val_loss: 0.0004927962\n",
      "[022/01359] train_loss: 0.0004884092\n",
      "[022/01359] val_loss: 0.0004852886\n",
      "[022/01459] train_loss: 0.0005709355\n",
      "[022/01459] val_loss: 0.0004806608\n",
      "[022/01559] train_loss: 0.0005705661\n",
      "[022/01559] val_loss: 0.0004903573\n",
      "[022/01659] train_loss: 0.0005398477\n",
      "[022/01659] val_loss: 0.0004942023\n",
      "[022/01759] train_loss: 0.0005625943\n",
      "[022/01759] val_loss: 0.0004985057\n",
      "[022/01859] train_loss: 0.0004798070\n",
      "[022/01859] val_loss: 0.0005016475\n",
      "[023/00039] train_loss: 0.0004408624\n",
      "[023/00039] val_loss: 0.0004724689\n",
      "[023/00139] train_loss: 0.0005571602\n",
      "[023/00139] val_loss: 0.0007930451\n",
      "[023/00239] train_loss: 0.0005537617\n",
      "[023/00239] val_loss: 0.0005463923\n",
      "[023/00339] train_loss: 0.0005474623\n",
      "[023/00339] val_loss: 0.0005217399\n",
      "[023/00439] train_loss: 0.0005762509\n",
      "[023/00439] val_loss: 0.0005215317\n",
      "[023/00539] train_loss: 0.0005023596\n",
      "[023/00539] val_loss: 0.0006229448\n",
      "[023/00639] train_loss: 0.0008154058\n",
      "[023/00639] val_loss: 0.0005110533\n",
      "[023/00739] train_loss: 0.0005451595\n",
      "[023/00739] val_loss: 0.0004863200\n",
      "[023/00839] train_loss: 0.0005645092\n",
      "[023/00839] val_loss: 0.0005109773\n",
      "[023/00939] train_loss: 0.0005345251\n",
      "[023/00939] val_loss: 0.0004865596\n",
      "[023/01039] train_loss: 0.0004944373\n",
      "[023/01039] val_loss: 0.0004791312\n",
      "[023/01139] train_loss: 0.0005087371\n",
      "[023/01139] val_loss: 0.0005752390\n",
      "[023/01239] train_loss: 0.0005849864\n",
      "[023/01239] val_loss: 0.0004854390\n",
      "[023/01339] train_loss: 0.0005373202\n",
      "[023/01339] val_loss: 0.0005077684\n",
      "[023/01439] train_loss: 0.0005554653\n",
      "[023/01439] val_loss: 0.0004753747\n",
      "[023/01539] train_loss: 0.0005203189\n",
      "[023/01539] val_loss: 0.0004750832\n",
      "[023/01639] train_loss: 0.0005174990\n",
      "[023/01639] val_loss: 0.0005877502\n",
      "[023/01739] train_loss: 0.0005288345\n",
      "[023/01739] val_loss: 0.0004535676\n",
      "[023/01839] train_loss: 0.0005465165\n",
      "[023/01839] val_loss: 0.0004892816\n",
      "[024/00019] train_loss: 0.0004934353\n",
      "[024/00019] val_loss: 0.0004587571\n",
      "[024/00119] train_loss: 0.0004663483\n",
      "[024/00119] val_loss: 0.0004558007\n",
      "[024/00219] train_loss: 0.0004909551\n",
      "[024/00219] val_loss: 0.0004862901\n",
      "[024/00319] train_loss: 0.0004741042\n",
      "[024/00319] val_loss: 0.0004637484\n",
      "[024/00419] train_loss: 0.0004912682\n",
      "[024/00419] val_loss: 0.0004713326\n",
      "[024/00519] train_loss: 0.0006293887\n",
      "[024/00519] val_loss: 0.0006550263\n",
      "[024/00619] train_loss: 0.0005837522\n",
      "[024/00619] val_loss: 0.0005337904\n",
      "[024/00719] train_loss: 0.0005071576\n",
      "[024/00719] val_loss: 0.0004796778\n",
      "[024/00819] train_loss: 0.0005384614\n",
      "[024/00819] val_loss: 0.0004690108\n",
      "[024/00919] train_loss: 0.0005722298\n",
      "[024/00919] val_loss: 0.0005127864\n",
      "[024/01019] train_loss: 0.0005399450\n",
      "[024/01019] val_loss: 0.0004886515\n",
      "[024/01119] train_loss: 0.0005397183\n",
      "[024/01119] val_loss: 0.0004738444\n",
      "[024/01219] train_loss: 0.0005467738\n",
      "[024/01219] val_loss: 0.0004797922\n",
      "[024/01319] train_loss: 0.0005147296\n",
      "[024/01319] val_loss: 0.0004837896\n",
      "[024/01419] train_loss: 0.0004842868\n",
      "[024/01419] val_loss: 0.0004968779\n",
      "[024/01519] train_loss: 0.0005371991\n",
      "[024/01519] val_loss: 0.0004600895\n",
      "[024/01619] train_loss: 0.0005441752\n",
      "[024/01619] val_loss: 0.0005186775\n",
      "[024/01719] train_loss: 0.0005412778\n",
      "[024/01719] val_loss: 0.0004895753\n",
      "[024/01819] train_loss: 0.0004704721\n",
      "[024/01819] val_loss: 0.0004575186\n",
      "[024/01919] train_loss: 0.0004880757\n",
      "[024/01919] val_loss: 0.0006253158\n",
      "[025/00099] train_loss: 0.0005772345\n",
      "[025/00099] val_loss: 0.0004557540\n",
      "[025/00199] train_loss: 0.0005079030\n",
      "[025/00199] val_loss: 0.0004689612\n",
      "[025/00299] train_loss: 0.0004939486\n",
      "[025/00299] val_loss: 0.0004748442\n",
      "[025/00399] train_loss: 0.0004960550\n",
      "[025/00399] val_loss: 0.0004647577\n",
      "[025/00499] train_loss: 0.0004651982\n",
      "[025/00499] val_loss: 0.0004651776\n",
      "[025/00599] train_loss: 0.0005151318\n",
      "[025/00599] val_loss: 0.0004595493\n",
      "[025/00699] train_loss: 0.0005057874\n",
      "[025/00699] val_loss: 0.0004542692\n",
      "[025/00799] train_loss: 0.0004538366\n",
      "[025/00799] val_loss: 0.0004530346\n",
      "[025/00899] train_loss: 0.0004975490\n",
      "[025/00899] val_loss: 0.0004944028\n",
      "[025/00999] train_loss: 0.0005434342\n",
      "[025/00999] val_loss: 0.0004699901\n",
      "[025/01099] train_loss: 0.0005173875\n",
      "[025/01099] val_loss: 0.0004801367\n",
      "[025/01199] train_loss: 0.0004966986\n",
      "[025/01199] val_loss: 0.0005364020\n",
      "[025/01299] train_loss: 0.0005786966\n",
      "[025/01299] val_loss: 0.0005964178\n",
      "[025/01399] train_loss: 0.0005609419\n",
      "[025/01399] val_loss: 0.0005144844\n",
      "[025/01499] train_loss: 0.0004986193\n",
      "[025/01499] val_loss: 0.0004807743\n",
      "[025/01599] train_loss: 0.0005378602\n",
      "[025/01599] val_loss: 0.0004559109\n",
      "[025/01699] train_loss: 0.0004913085\n",
      "[025/01699] val_loss: 0.0004407090\n",
      "[025/01799] train_loss: 0.0005208439\n",
      "[025/01799] val_loss: 0.0004517990\n",
      "[025/01899] train_loss: 0.0005181957\n",
      "[025/01899] val_loss: 0.0004645266\n",
      "[026/00079] train_loss: 0.0005029566\n",
      "[026/00079] val_loss: 0.0005178506\n",
      "[026/00179] train_loss: 0.0005606968\n",
      "[026/00179] val_loss: 0.0004791958\n",
      "[026/00279] train_loss: 0.0004816479\n",
      "[026/00279] val_loss: 0.0004946924\n",
      "[026/00379] train_loss: 0.0005318962\n",
      "[026/00379] val_loss: 0.0004604370\n",
      "[026/00479] train_loss: 0.0004739744\n",
      "[026/00479] val_loss: 0.0004744926\n",
      "[026/00579] train_loss: 0.0005706273\n",
      "[026/00579] val_loss: 0.0004886674\n",
      "[026/00679] train_loss: 0.0005165327\n",
      "[026/00679] val_loss: 0.0005069537\n",
      "[026/00779] train_loss: 0.0005909122\n",
      "[026/00779] val_loss: 0.0004677534\n",
      "[026/00879] train_loss: 0.0005199714\n",
      "[026/00879] val_loss: 0.0004767786\n",
      "[026/00979] train_loss: 0.0005047335\n",
      "[026/00979] val_loss: 0.0004766718\n",
      "[026/01079] train_loss: 0.0005710056\n",
      "[026/01079] val_loss: 0.0004520031\n",
      "[026/01179] train_loss: 0.0005126213\n",
      "[026/01179] val_loss: 0.0004774298\n",
      "[026/01279] train_loss: 0.0005033420\n",
      "[026/01279] val_loss: 0.0004457990\n",
      "[026/01379] train_loss: 0.0005133880\n",
      "[026/01379] val_loss: 0.0004922433\n",
      "[026/01479] train_loss: 0.0004888921\n",
      "[026/01479] val_loss: 0.0005149233\n",
      "[026/01579] train_loss: 0.0004867338\n",
      "[026/01579] val_loss: 0.0004611239\n",
      "[026/01679] train_loss: 0.0005095092\n",
      "[026/01679] val_loss: 0.0004550728\n",
      "[026/01779] train_loss: 0.0004255733\n",
      "[026/01779] val_loss: 0.0004634913\n",
      "[026/01879] train_loss: 0.0004378310\n",
      "[026/01879] val_loss: 0.0004424648\n",
      "[027/00059] train_loss: 0.0005122671\n",
      "[027/00059] val_loss: 0.0004633445\n",
      "[027/00159] train_loss: 0.0004803823\n",
      "[027/00159] val_loss: 0.0004644710\n",
      "[027/00259] train_loss: 0.0006131500\n",
      "[027/00259] val_loss: 0.0008158909\n",
      "[027/00359] train_loss: 0.0005820192\n",
      "[027/00359] val_loss: 0.0005066422\n",
      "[027/00459] train_loss: 0.0005008683\n",
      "[027/00459] val_loss: 0.0005138182\n",
      "[027/00559] train_loss: 0.0004908987\n",
      "[027/00559] val_loss: 0.0005126942\n",
      "[027/00659] train_loss: 0.0004791686\n",
      "[027/00659] val_loss: 0.0004799893\n",
      "[027/00759] train_loss: 0.0004971094\n",
      "[027/00759] val_loss: 0.0004688815\n",
      "[027/00859] train_loss: 0.0004995562\n",
      "[027/00859] val_loss: 0.0004601652\n",
      "[027/00959] train_loss: 0.0004794713\n",
      "[027/00959] val_loss: 0.0004928283\n",
      "[027/01059] train_loss: 0.0004347129\n",
      "[027/01059] val_loss: 0.0005011786\n",
      "[027/01159] train_loss: 0.0005599250\n",
      "[027/01159] val_loss: 0.0004833654\n",
      "[027/01259] train_loss: 0.0004910746\n",
      "[027/01259] val_loss: 0.0004659655\n",
      "[027/01359] train_loss: 0.0005549609\n",
      "[027/01359] val_loss: 0.0004870316\n",
      "[027/01459] train_loss: 0.0005146195\n",
      "[027/01459] val_loss: 0.0004620973\n",
      "[027/01559] train_loss: 0.0004831502\n",
      "[027/01559] val_loss: 0.0004578837\n",
      "[027/01659] train_loss: 0.0004722020\n",
      "[027/01659] val_loss: 0.0004675086\n",
      "[027/01759] train_loss: 0.0004680864\n",
      "[027/01759] val_loss: 0.0004798109\n",
      "[027/01859] train_loss: 0.0004904025\n",
      "[027/01859] val_loss: 0.0005102532\n",
      "[028/00039] train_loss: 0.0005263873\n",
      "[028/00039] val_loss: 0.0004696634\n",
      "[028/00139] train_loss: 0.0004912489\n",
      "[028/00139] val_loss: 0.0004793626\n",
      "[028/00239] train_loss: 0.0004727626\n",
      "[028/00239] val_loss: 0.0004561921\n",
      "[028/00339] train_loss: 0.0004790466\n",
      "[028/00339] val_loss: 0.0004647430\n",
      "[028/00439] train_loss: 0.0005399795\n",
      "[028/00439] val_loss: 0.0004705735\n",
      "[028/00539] train_loss: 0.0005513862\n",
      "[028/00539] val_loss: 0.0004750701\n",
      "[028/00639] train_loss: 0.0005288534\n",
      "[028/00639] val_loss: 0.0004772420\n",
      "[028/00739] train_loss: 0.0005024879\n",
      "[028/00739] val_loss: 0.0004741314\n",
      "[028/00839] train_loss: 0.0004721678\n",
      "[028/00839] val_loss: 0.0004859174\n",
      "[028/00939] train_loss: 0.0004505976\n",
      "[028/00939] val_loss: 0.0004643600\n",
      "[028/01039] train_loss: 0.0004756618\n",
      "[028/01039] val_loss: 0.0004718064\n",
      "[028/01139] train_loss: 0.0004710500\n",
      "[028/01139] val_loss: 0.0004427081\n",
      "[028/01239] train_loss: 0.0004743371\n",
      "[028/01239] val_loss: 0.0004689257\n",
      "[028/01339] train_loss: 0.0005062424\n",
      "[028/01339] val_loss: 0.0004517709\n",
      "[028/01439] train_loss: 0.0004600942\n",
      "[028/01439] val_loss: 0.0004727438\n",
      "[028/01539] train_loss: 0.0005126772\n",
      "[028/01539] val_loss: 0.0004764863\n",
      "[028/01639] train_loss: 0.0004808729\n",
      "[028/01639] val_loss: 0.0004969923\n",
      "[028/01739] train_loss: 0.0005042636\n",
      "[028/01739] val_loss: 0.0004633176\n",
      "[028/01839] train_loss: 0.0004873600\n",
      "[028/01839] val_loss: 0.0004843246\n",
      "[029/00019] train_loss: 0.0005257819\n",
      "[029/00019] val_loss: 0.0004737188\n",
      "[029/00119] train_loss: 0.0004674347\n",
      "[029/00119] val_loss: 0.0004636442\n",
      "[029/00219] train_loss: 0.0004934328\n",
      "[029/00219] val_loss: 0.0004799002\n",
      "[029/00319] train_loss: 0.0004740421\n",
      "[029/00319] val_loss: 0.0004659899\n",
      "[029/00419] train_loss: 0.0005213530\n",
      "[029/00419] val_loss: 0.0005346445\n",
      "[029/00519] train_loss: 0.0005954214\n",
      "[029/00519] val_loss: 0.0006939919\n",
      "[029/00619] train_loss: 0.0007563161\n",
      "[029/00619] val_loss: 0.0004745176\n",
      "[029/00719] train_loss: 0.0004979241\n",
      "[029/00719] val_loss: 0.0004528273\n",
      "[029/00819] train_loss: 0.0004750559\n",
      "[029/00819] val_loss: 0.0004365414\n",
      "[029/00919] train_loss: 0.0004986961\n",
      "[029/00919] val_loss: 0.0004480523\n",
      "[029/01019] train_loss: 0.0004264052\n",
      "[029/01019] val_loss: 0.0004430645\n",
      "[029/01119] train_loss: 0.0004556985\n",
      "[029/01119] val_loss: 0.0004706497\n",
      "[029/01219] train_loss: 0.0005138096\n",
      "[029/01219] val_loss: 0.0004624939\n",
      "[029/01319] train_loss: 0.0004994930\n",
      "[029/01319] val_loss: 0.0004663128\n",
      "[029/01419] train_loss: 0.0005024656\n",
      "[029/01419] val_loss: 0.0004863598\n",
      "[029/01519] train_loss: 0.0004839753\n",
      "[029/01519] val_loss: 0.0004606571\n",
      "[029/01619] train_loss: 0.0005029525\n",
      "[029/01619] val_loss: 0.0004487975\n",
      "[029/01719] train_loss: 0.0005004892\n",
      "[029/01719] val_loss: 0.0004559318\n",
      "[029/01819] train_loss: 0.0004639583\n",
      "[029/01819] val_loss: 0.0004551421\n",
      "[029/01919] train_loss: 0.0004572834\n",
      "[029/01919] val_loss: 0.0004529037\n",
      "[030/00099] train_loss: 0.0004743405\n",
      "[030/00099] val_loss: 0.0004534011\n",
      "[030/00199] train_loss: 0.0004296884\n",
      "[030/00199] val_loss: 0.0004478475\n",
      "[030/00299] train_loss: 0.0004696054\n",
      "[030/00299] val_loss: 0.0004546916\n",
      "[030/00399] train_loss: 0.0004423688\n",
      "[030/00399] val_loss: 0.0004487202\n",
      "[030/00499] train_loss: 0.0004579030\n",
      "[030/00499] val_loss: 0.0004467087\n",
      "[030/00599] train_loss: 0.0004526372\n",
      "[030/00599] val_loss: 0.0005528604\n",
      "[030/00699] train_loss: 0.0005977362\n",
      "[030/00699] val_loss: 0.0005275148\n",
      "[030/00799] train_loss: 0.0005129106\n",
      "[030/00799] val_loss: 0.0004769876\n",
      "[030/00899] train_loss: 0.0005005189\n",
      "[030/00899] val_loss: 0.0005352888\n",
      "[030/00999] train_loss: 0.0005125184\n",
      "[030/00999] val_loss: 0.0004573056\n",
      "[030/01099] train_loss: 0.0004921917\n",
      "[030/01099] val_loss: 0.0004587770\n",
      "[030/01199] train_loss: 0.0004825232\n",
      "[030/01199] val_loss: 0.0004661558\n",
      "[030/01299] train_loss: 0.0004909568\n",
      "[030/01299] val_loss: 0.0005248580\n",
      "[030/01399] train_loss: 0.0005152250\n",
      "[030/01399] val_loss: 0.0004760717\n",
      "[030/01499] train_loss: 0.0004643626\n",
      "[030/01499] val_loss: 0.0005120274\n",
      "[030/01599] train_loss: 0.0005002502\n",
      "[030/01599] val_loss: 0.0004881162\n",
      "[030/01699] train_loss: 0.0004544038\n",
      "[030/01699] val_loss: 0.0004850486\n",
      "[030/01799] train_loss: 0.0004590431\n",
      "[030/01799] val_loss: 0.0004358247\n",
      "[030/01899] train_loss: 0.0004548829\n",
      "[030/01899] val_loss: 0.0004453389\n",
      "[031/00079] train_loss: 0.0004604925\n",
      "[031/00079] val_loss: 0.0004646373\n",
      "[031/00179] train_loss: 0.0004600201\n",
      "[031/00179] val_loss: 0.0004504383\n",
      "[031/00279] train_loss: 0.0005098160\n",
      "[031/00279] val_loss: 0.0004726695\n",
      "[031/00379] train_loss: 0.0004871370\n",
      "[031/00379] val_loss: 0.0004582123\n",
      "[031/00479] train_loss: 0.0004947639\n",
      "[031/00479] val_loss: 0.0004311949\n",
      "[031/00579] train_loss: 0.0004734138\n",
      "[031/00579] val_loss: 0.0005228592\n",
      "[031/00679] train_loss: 0.0004733964\n",
      "[031/00679] val_loss: 0.0004389521\n",
      "[031/00779] train_loss: 0.0004866044\n",
      "[031/00779] val_loss: 0.0004765371\n",
      "[031/00879] train_loss: 0.0004720382\n",
      "[031/00879] val_loss: 0.0004706070\n",
      "[031/00979] train_loss: 0.0004845577\n",
      "[031/00979] val_loss: 0.0004560899\n",
      "[031/01079] train_loss: 0.0004970352\n",
      "[031/01079] val_loss: 0.0004626459\n",
      "[031/01179] train_loss: 0.0004819488\n",
      "[031/01179] val_loss: 0.0004524182\n",
      "[031/01279] train_loss: 0.0004800831\n",
      "[031/01279] val_loss: 0.0004479098\n",
      "[031/01379] train_loss: 0.0004535477\n",
      "[031/01379] val_loss: 0.0004712268\n",
      "[031/01479] train_loss: 0.0004825335\n",
      "[031/01479] val_loss: 0.0004553775\n",
      "[031/01579] train_loss: 0.0004718425\n",
      "[031/01579] val_loss: 0.0004442554\n",
      "[031/01679] train_loss: 0.0004477008\n",
      "[031/01679] val_loss: 0.0004515546\n",
      "[031/01779] train_loss: 0.0004343531\n",
      "[031/01779] val_loss: 0.0004714915\n",
      "[031/01879] train_loss: 0.0004807654\n",
      "[031/01879] val_loss: 0.0004670788\n",
      "[032/00059] train_loss: 0.0005475964\n",
      "[032/00059] val_loss: 0.0004788583\n",
      "[032/00159] train_loss: 0.0005513820\n",
      "[032/00159] val_loss: 0.0004583272\n",
      "[032/00259] train_loss: 0.0004817636\n",
      "[032/00259] val_loss: 0.0004738946\n",
      "[032/00359] train_loss: 0.0005092498\n",
      "[032/00359] val_loss: 0.0004831996\n",
      "[032/00459] train_loss: 0.0004543657\n",
      "[032/00459] val_loss: 0.0004543887\n",
      "[032/00559] train_loss: 0.0004348984\n",
      "[032/00559] val_loss: 0.0004481499\n",
      "[032/00659] train_loss: 0.0004615065\n",
      "[032/00659] val_loss: 0.0004732690\n",
      "[032/00759] train_loss: 0.0004972705\n",
      "[032/00759] val_loss: 0.0004536877\n",
      "[032/00859] train_loss: 0.0004486484\n",
      "[032/00859] val_loss: 0.0004367744\n",
      "[032/00959] train_loss: 0.0004626775\n",
      "[032/00959] val_loss: 0.0004530395\n",
      "[032/01059] train_loss: 0.0004074240\n",
      "[032/01059] val_loss: 0.0004704509\n",
      "[032/01159] train_loss: 0.0005194127\n",
      "[032/01159] val_loss: 0.0004616938\n",
      "[032/01259] train_loss: 0.0004864857\n",
      "[032/01259] val_loss: 0.0004793699\n",
      "[032/01359] train_loss: 0.0005234852\n",
      "[032/01359] val_loss: 0.0004873489\n",
      "[032/01459] train_loss: 0.0005135445\n",
      "[032/01459] val_loss: 0.0004617978\n",
      "[032/01559] train_loss: 0.0005028653\n",
      "[032/01559] val_loss: 0.0005040934\n",
      "[032/01659] train_loss: 0.0004669390\n",
      "[032/01659] val_loss: 0.0004766038\n",
      "[032/01759] train_loss: 0.0004685173\n",
      "[032/01759] val_loss: 0.0004320529\n",
      "[032/01859] train_loss: 0.0004686177\n",
      "[032/01859] val_loss: 0.0004497336\n",
      "[033/00039] train_loss: 0.0004517124\n",
      "[033/00039] val_loss: 0.0004555896\n",
      "[033/00139] train_loss: 0.0004739522\n",
      "[033/00139] val_loss: 0.0004541207\n",
      "[033/00239] train_loss: 0.0004634572\n",
      "[033/00239] val_loss: 0.0004487036\n",
      "[033/00339] train_loss: 0.0004522614\n",
      "[033/00339] val_loss: 0.0004490514\n",
      "[033/00439] train_loss: 0.0004784509\n",
      "[033/00439] val_loss: 0.0004466283\n",
      "[033/00539] train_loss: 0.0004646760\n",
      "[033/00539] val_loss: 0.0004804753\n",
      "[033/00639] train_loss: 0.0004833666\n",
      "[033/00639] val_loss: 0.0005065926\n",
      "[033/00739] train_loss: 0.0004733349\n",
      "[033/00739] val_loss: 0.0004696346\n",
      "[033/00839] train_loss: 0.0005300441\n",
      "[033/00839] val_loss: 0.0005123040\n",
      "[033/00939] train_loss: 0.0004729056\n",
      "[033/00939] val_loss: 0.0004380173\n",
      "[033/01039] train_loss: 0.0004648112\n",
      "[033/01039] val_loss: 0.0004370445\n",
      "[033/01139] train_loss: 0.0004803215\n",
      "[033/01139] val_loss: 0.0004876945\n",
      "[033/01239] train_loss: 0.0005201202\n",
      "[033/01239] val_loss: 0.0004655060\n",
      "[033/01339] train_loss: 0.0004454210\n",
      "[033/01339] val_loss: 0.0004530165\n",
      "[033/01439] train_loss: 0.0004049412\n",
      "[033/01439] val_loss: 0.0004610675\n",
      "[033/01539] train_loss: 0.0004624451\n",
      "[033/01539] val_loss: 0.0004444089\n",
      "[033/01639] train_loss: 0.0005208340\n",
      "[033/01639] val_loss: 0.0004688760\n",
      "[033/01739] train_loss: 0.0004505232\n",
      "[033/01739] val_loss: 0.0004614090\n",
      "[033/01839] train_loss: 0.0004239124\n",
      "[033/01839] val_loss: 0.0004452975\n",
      "[034/00019] train_loss: 0.0004825868\n",
      "[034/00019] val_loss: 0.0004391734\n",
      "[034/00119] train_loss: 0.0006873816\n",
      "[034/00119] val_loss: 0.0004920747\n",
      "[034/00219] train_loss: 0.0004745432\n",
      "[034/00219] val_loss: 0.0004585495\n",
      "[034/00319] train_loss: 0.0004301503\n",
      "[034/00319] val_loss: 0.0004449132\n",
      "[034/00419] train_loss: 0.0004663302\n",
      "[034/00419] val_loss: 0.0005055635\n",
      "[034/00519] train_loss: 0.0004862964\n",
      "[034/00519] val_loss: 0.0004587768\n",
      "[034/00619] train_loss: 0.0004419803\n",
      "[034/00619] val_loss: 0.0004311779\n",
      "[034/00719] train_loss: 0.0004448944\n",
      "[034/00719] val_loss: 0.0004279439\n",
      "[034/00819] train_loss: 0.0004162058\n",
      "[034/00819] val_loss: 0.0004558188\n",
      "[034/00919] train_loss: 0.0004736203\n",
      "[034/00919] val_loss: 0.0004424267\n",
      "[034/01019] train_loss: 0.0006692127\n",
      "[034/01019] val_loss: 0.0004641671\n",
      "[034/01119] train_loss: 0.0004462503\n",
      "[034/01119] val_loss: 0.0004436423\n",
      "[034/01219] train_loss: 0.0004520563\n",
      "[034/01219] val_loss: 0.0004706409\n",
      "[034/01319] train_loss: 0.0004643224\n",
      "[034/01319] val_loss: 0.0004956829\n",
      "[034/01419] train_loss: 0.0004287286\n",
      "[034/01419] val_loss: 0.0004471087\n",
      "[034/01519] train_loss: 0.0005136546\n",
      "[034/01519] val_loss: 0.0004602684\n",
      "[034/01619] train_loss: 0.0004166653\n",
      "[034/01619] val_loss: 0.0004709833\n",
      "[034/01719] train_loss: 0.0004617547\n",
      "[034/01719] val_loss: 0.0004357751\n",
      "[034/01819] train_loss: 0.0004755338\n",
      "[034/01819] val_loss: 0.0004370758\n",
      "[034/01919] train_loss: 0.0004657956\n",
      "[034/01919] val_loss: 0.0004340036\n",
      "[035/00099] train_loss: 0.0004501865\n",
      "[035/00099] val_loss: 0.0004482388\n",
      "[035/00199] train_loss: 0.0004293642\n",
      "[035/00199] val_loss: 0.0004421867\n",
      "[035/00299] train_loss: 0.0003963391\n",
      "[035/00299] val_loss: 0.0004460608\n",
      "[035/00399] train_loss: 0.0004695040\n",
      "[035/00399] val_loss: 0.0004452558\n",
      "[035/00499] train_loss: 0.0004458454\n",
      "[035/00499] val_loss: 0.0004672760\n",
      "[035/00599] train_loss: 0.0004123102\n",
      "[035/00599] val_loss: 0.0004491886\n",
      "[035/00699] train_loss: 0.0004535573\n",
      "[035/00699] val_loss: 0.0004333857\n",
      "[035/00799] train_loss: 0.0004854630\n",
      "[035/00799] val_loss: 0.0004455624\n",
      "[035/00899] train_loss: 0.0004558708\n",
      "[035/00899] val_loss: 0.0004498980\n",
      "[035/00999] train_loss: 0.0004703219\n",
      "[035/00999] val_loss: 0.0004274498\n",
      "[035/01099] train_loss: 0.0004711041\n",
      "[035/01099] val_loss: 0.0004347531\n",
      "[035/01199] train_loss: 0.0004570678\n",
      "[035/01199] val_loss: 0.0005009936\n",
      "[035/01299] train_loss: 0.0004922622\n",
      "[035/01299] val_loss: 0.0004366252\n",
      "[035/01399] train_loss: 0.0004705771\n",
      "[035/01399] val_loss: 0.0004773737\n",
      "[035/01499] train_loss: 0.0004359976\n",
      "[035/01499] val_loss: 0.0004408259\n",
      "[035/01599] train_loss: 0.0005209479\n",
      "[035/01599] val_loss: 0.0004565635\n",
      "[035/01699] train_loss: 0.0004368106\n",
      "[035/01699] val_loss: 0.0004366542\n",
      "[035/01799] train_loss: 0.0004014691\n",
      "[035/01799] val_loss: 0.0004463700\n",
      "[035/01899] train_loss: 0.0004744111\n",
      "[035/01899] val_loss: 0.0004468580\n",
      "[036/00079] train_loss: 0.0004808374\n",
      "[036/00079] val_loss: 0.0004443200\n",
      "[036/00179] train_loss: 0.0004379156\n",
      "[036/00179] val_loss: 0.0004399381\n",
      "[036/00279] train_loss: 0.0004007007\n",
      "[036/00279] val_loss: 0.0004305803\n",
      "[036/00379] train_loss: 0.0004308684\n",
      "[036/00379] val_loss: 0.0004367643\n",
      "[036/00479] train_loss: 0.0004570140\n",
      "[036/00479] val_loss: 0.0004372028\n",
      "[036/00579] train_loss: 0.0004416541\n",
      "[036/00579] val_loss: 0.0004660393\n",
      "[036/00679] train_loss: 0.0004932276\n",
      "[036/00679] val_loss: 0.0004510007\n",
      "[036/00779] train_loss: 0.0006738982\n",
      "[036/00779] val_loss: 0.0005074366\n",
      "[036/00879] train_loss: 0.0006292139\n",
      "[036/00879] val_loss: 0.0005180486\n",
      "[036/00979] train_loss: 0.0004945407\n",
      "[036/00979] val_loss: 0.0004585840\n",
      "[036/01079] train_loss: 0.0004541937\n",
      "[036/01079] val_loss: 0.0004287652\n",
      "[036/01179] train_loss: 0.0004303662\n",
      "[036/01179] val_loss: 0.0004332219\n",
      "[036/01279] train_loss: 0.0004621901\n",
      "[036/01279] val_loss: 0.0004667450\n",
      "[036/01379] train_loss: 0.0004455306\n",
      "[036/01379] val_loss: 0.0004330322\n",
      "[036/01479] train_loss: 0.0004293848\n",
      "[036/01479] val_loss: 0.0004571560\n",
      "[036/01579] train_loss: 0.0004425946\n",
      "[036/01579] val_loss: 0.0004503259\n",
      "[036/01679] train_loss: 0.0004306055\n",
      "[036/01679] val_loss: 0.0004436546\n",
      "[036/01779] train_loss: 0.0004322455\n",
      "[036/01779] val_loss: 0.0004243765\n",
      "[036/01879] train_loss: 0.0004753905\n",
      "[036/01879] val_loss: 0.0005262007\n",
      "[037/00059] train_loss: 0.0004820017\n",
      "[037/00059] val_loss: 0.0004379334\n",
      "[037/00159] train_loss: 0.0004700832\n",
      "[037/00159] val_loss: 0.0004767369\n",
      "[037/00259] train_loss: 0.0004775290\n",
      "[037/00259] val_loss: 0.0004550122\n",
      "[037/00359] train_loss: 0.0004225921\n",
      "[037/00359] val_loss: 0.0004409232\n",
      "[037/00459] train_loss: 0.0004516488\n",
      "[037/00459] val_loss: 0.0004415354\n",
      "[037/00559] train_loss: 0.0004463220\n",
      "[037/00559] val_loss: 0.0004434166\n",
      "[037/00659] train_loss: 0.0004239526\n",
      "[037/00659] val_loss: 0.0004273158\n",
      "[037/00759] train_loss: 0.0004435248\n",
      "[037/00759] val_loss: 0.0004636935\n",
      "[037/00859] train_loss: 0.0004700595\n",
      "[037/00859] val_loss: 0.0004470585\n",
      "[037/00959] train_loss: 0.0004788162\n",
      "[037/00959] val_loss: 0.0004478677\n",
      "[037/01059] train_loss: 0.0004946200\n",
      "[037/01059] val_loss: 0.0004652462\n",
      "[037/01159] train_loss: 0.0004818263\n",
      "[037/01159] val_loss: 0.0004144454\n",
      "[037/01259] train_loss: 0.0004600090\n",
      "[037/01259] val_loss: 0.0005027463\n",
      "[037/01359] train_loss: 0.0004650103\n",
      "[037/01359] val_loss: 0.0004605841\n",
      "[037/01459] train_loss: 0.0004259488\n",
      "[037/01459] val_loss: 0.0004294088\n",
      "[037/01559] train_loss: 0.0004274348\n",
      "[037/01559] val_loss: 0.0004343005\n",
      "[037/01659] train_loss: 0.0004364652\n",
      "[037/01659] val_loss: 0.0004201637\n",
      "[037/01759] train_loss: 0.0004686480\n",
      "[037/01759] val_loss: 0.0004178472\n",
      "[037/01859] train_loss: 0.0004307948\n",
      "[037/01859] val_loss: 0.0004239052\n",
      "[038/00039] train_loss: 0.0004033465\n",
      "[038/00039] val_loss: 0.0004286409\n",
      "[038/00139] train_loss: 0.0004068080\n",
      "[038/00139] val_loss: 0.0004516963\n",
      "[038/00239] train_loss: 0.0004115841\n",
      "[038/00239] val_loss: 0.0004316758\n",
      "[038/00339] train_loss: 0.0004451763\n",
      "[038/00339] val_loss: 0.0004226766\n",
      "[038/00439] train_loss: 0.0004428791\n",
      "[038/00439] val_loss: 0.0004087999\n",
      "[038/00539] train_loss: 0.0004436754\n",
      "[038/00539] val_loss: 0.0004157207\n",
      "[038/00639] train_loss: 0.0004192216\n",
      "[038/00639] val_loss: 0.0004110154\n",
      "[038/00739] train_loss: 0.0004086599\n",
      "[038/00739] val_loss: 0.0004083412\n",
      "[038/00839] train_loss: 0.0004511497\n",
      "[038/00839] val_loss: 0.0004431802\n",
      "[038/00939] train_loss: 0.0004939308\n",
      "[038/00939] val_loss: 0.0004382004\n",
      "[038/01039] train_loss: 0.0004451723\n",
      "[038/01039] val_loss: 0.0004240127\n",
      "[038/01139] train_loss: 0.0004432494\n",
      "[038/01139] val_loss: 0.0004445006\n",
      "[038/01239] train_loss: 0.0004754037\n",
      "[038/01239] val_loss: 0.0004488156\n",
      "[038/01339] train_loss: 0.0004685653\n",
      "[038/01339] val_loss: 0.0004435656\n",
      "[038/01439] train_loss: 0.0004568452\n",
      "[038/01439] val_loss: 0.0004205215\n",
      "[038/01539] train_loss: 0.0004342820\n",
      "[038/01539] val_loss: 0.0004395595\n",
      "[038/01639] train_loss: 0.0004249709\n",
      "[038/01639] val_loss: 0.0004143463\n",
      "[038/01739] train_loss: 0.0004741886\n",
      "[038/01739] val_loss: 0.0005743944\n",
      "[038/01839] train_loss: 0.0004884729\n",
      "[038/01839] val_loss: 0.0004389217\n",
      "[039/00019] train_loss: 0.0004626577\n",
      "[039/00019] val_loss: 0.0004298516\n",
      "[039/00119] train_loss: 0.0004273567\n",
      "[039/00119] val_loss: 0.0004630959\n",
      "[039/00219] train_loss: 0.0004373323\n",
      "[039/00219] val_loss: 0.0004271103\n",
      "[039/00319] train_loss: 0.0004024846\n",
      "[039/00319] val_loss: 0.0004306408\n",
      "[039/00419] train_loss: 0.0004110065\n",
      "[039/00419] val_loss: 0.0004259933\n",
      "[039/00519] train_loss: 0.0004244701\n",
      "[039/00519] val_loss: 0.0004401022\n",
      "[039/00619] train_loss: 0.0004614241\n",
      "[039/00619] val_loss: 0.0004505904\n",
      "[039/00719] train_loss: 0.0004603113\n",
      "[039/00719] val_loss: 0.0005974566\n",
      "[039/00819] train_loss: 0.0004809518\n",
      "[039/00819] val_loss: 0.0004662914\n",
      "[039/00919] train_loss: 0.0004452686\n",
      "[039/00919] val_loss: 0.0004144947\n",
      "[039/01019] train_loss: 0.0004429839\n",
      "[039/01019] val_loss: 0.0004524976\n",
      "[039/01119] train_loss: 0.0004275132\n",
      "[039/01119] val_loss: 0.0004292248\n",
      "[039/01219] train_loss: 0.0004287645\n",
      "[039/01219] val_loss: 0.0004196906\n",
      "[039/01319] train_loss: 0.0004113495\n",
      "[039/01319] val_loss: 0.0004214373\n",
      "[039/01419] train_loss: 0.0004290439\n",
      "[039/01419] val_loss: 0.0004192126\n",
      "[039/01519] train_loss: 0.0004215952\n",
      "[039/01519] val_loss: 0.0004188656\n",
      "[039/01619] train_loss: 0.0004488932\n",
      "[039/01619] val_loss: 0.0004411195\n",
      "[039/01719] train_loss: 0.0004031534\n",
      "[039/01719] val_loss: 0.0004334044\n",
      "[039/01819] train_loss: 0.0005327377\n",
      "[039/01819] val_loss: 0.0004594035\n",
      "[039/01919] train_loss: 0.0004968891\n",
      "[039/01919] val_loss: 0.0004426298\n",
      "[040/00099] train_loss: 0.0004229575\n",
      "[040/00099] val_loss: 0.0004276676\n",
      "[040/00199] train_loss: 0.0003959005\n",
      "[040/00199] val_loss: 0.0004418676\n",
      "[040/00299] train_loss: 0.0004162470\n",
      "[040/00299] val_loss: 0.0004617487\n",
      "[040/00399] train_loss: 0.0003914104\n",
      "[040/00399] val_loss: 0.0004347268\n",
      "[040/00499] train_loss: 0.0004370178\n",
      "[040/00499] val_loss: 0.0004574534\n",
      "[040/00599] train_loss: 0.0005294151\n",
      "[040/00599] val_loss: 0.0006281618\n",
      "[040/00699] train_loss: 0.0005853334\n",
      "[040/00699] val_loss: 0.0004712870\n",
      "[040/00799] train_loss: 0.0004688667\n",
      "[040/00799] val_loss: 0.0004425285\n",
      "[040/00899] train_loss: 0.0004374097\n",
      "[040/00899] val_loss: 0.0004343820\n",
      "[040/00999] train_loss: 0.0004249094\n",
      "[040/00999] val_loss: 0.0004494113\n",
      "[040/01099] train_loss: 0.0004624753\n",
      "[040/01099] val_loss: 0.0004407007\n",
      "[040/01199] train_loss: 0.0004601685\n",
      "[040/01199] val_loss: 0.0004188113\n",
      "[040/01299] train_loss: 0.0004793573\n",
      "[040/01299] val_loss: 0.0004364099\n",
      "[040/01399] train_loss: 0.0004660432\n",
      "[040/01399] val_loss: 0.0005075338\n",
      "[040/01499] train_loss: 0.0004257659\n",
      "[040/01499] val_loss: 0.0004364516\n",
      "[040/01599] train_loss: 0.0004622548\n",
      "[040/01599] val_loss: 0.0004443126\n",
      "[040/01699] train_loss: 0.0003878502\n",
      "[040/01699] val_loss: 0.0004391962\n",
      "[040/01799] train_loss: 0.0003916949\n",
      "[040/01799] val_loss: 0.0004153983\n",
      "[040/01899] train_loss: 0.0004193428\n",
      "[040/01899] val_loss: 0.0004322807\n",
      "[041/00079] train_loss: 0.0004382564\n",
      "[041/00079] val_loss: 0.0004422447\n",
      "[041/00179] train_loss: 0.0004200318\n",
      "[041/00179] val_loss: 0.0004158362\n",
      "[041/00279] train_loss: 0.0003796620\n",
      "[041/00279] val_loss: 0.0004248963\n",
      "[041/00379] train_loss: 0.0004491534\n",
      "[041/00379] val_loss: 0.0004197847\n",
      "[041/00479] train_loss: 0.0004468668\n",
      "[041/00479] val_loss: 0.0004473020\n",
      "[041/00579] train_loss: 0.0004348256\n",
      "[041/00579] val_loss: 0.0005519754\n",
      "[041/00679] train_loss: 0.0004091069\n",
      "[041/00679] val_loss: 0.0004388359\n",
      "[041/00779] train_loss: 0.0003964812\n",
      "[041/00779] val_loss: 0.0004113101\n",
      "[041/00879] train_loss: 0.0004196331\n",
      "[041/00879] val_loss: 0.0004192006\n",
      "[041/00979] train_loss: 0.0004389147\n",
      "[041/00979] val_loss: 0.0004357172\n",
      "[041/01079] train_loss: 0.0004638488\n",
      "[041/01079] val_loss: 0.0004404422\n",
      "[041/01179] train_loss: 0.0004020296\n",
      "[041/01179] val_loss: 0.0004205962\n",
      "[041/01279] train_loss: 0.0004417672\n",
      "[041/01279] val_loss: 0.0004525646\n",
      "[041/01379] train_loss: 0.0004262854\n",
      "[041/01379] val_loss: 0.0004303666\n",
      "[041/01479] train_loss: 0.0004323401\n",
      "[041/01479] val_loss: 0.0004393553\n",
      "[041/01579] train_loss: 0.0004825291\n",
      "[041/01579] val_loss: 0.0004506540\n",
      "[041/01679] train_loss: 0.0004378884\n",
      "[041/01679] val_loss: 0.0004267221\n",
      "[041/01779] train_loss: 0.0004228102\n",
      "[041/01779] val_loss: 0.0004117401\n",
      "[041/01879] train_loss: 0.0004208425\n",
      "[041/01879] val_loss: 0.0004350509\n",
      "[042/00059] train_loss: 0.0004085547\n",
      "[042/00059] val_loss: 0.0004308604\n",
      "[042/00159] train_loss: 0.0004089067\n",
      "[042/00159] val_loss: 0.0004496721\n",
      "[042/00259] train_loss: 0.0004608005\n",
      "[042/00259] val_loss: 0.0004424593\n",
      "[042/00359] train_loss: 0.0004496531\n",
      "[042/00359] val_loss: 0.0004340704\n",
      "[042/00459] train_loss: 0.0004416925\n",
      "[042/00459] val_loss: 0.0004251319\n",
      "[042/00559] train_loss: 0.0004141691\n",
      "[042/00559] val_loss: 0.0004463248\n",
      "[042/00659] train_loss: 0.0004064599\n",
      "[042/00659] val_loss: 0.0004143098\n",
      "[042/00759] train_loss: 0.0004280101\n",
      "[042/00759] val_loss: 0.0004359556\n",
      "[042/00859] train_loss: 0.0004139965\n",
      "[042/00859] val_loss: 0.0004877095\n",
      "[042/00959] train_loss: 0.0004611320\n",
      "[042/00959] val_loss: 0.0004248631\n",
      "[042/01059] train_loss: 0.0004163422\n",
      "[042/01059] val_loss: 0.0004120435\n",
      "[042/01159] train_loss: 0.0004009327\n",
      "[042/01159] val_loss: 0.0004257824\n",
      "[042/01259] train_loss: 0.0003978028\n",
      "[042/01259] val_loss: 0.0004282962\n",
      "[042/01359] train_loss: 0.0004118566\n",
      "[042/01359] val_loss: 0.0004797818\n",
      "[042/01459] train_loss: 0.0004397440\n",
      "[042/01459] val_loss: 0.0005180743\n",
      "[042/01559] train_loss: 0.0005358245\n",
      "[042/01559] val_loss: 0.0004428028\n",
      "[042/01659] train_loss: 0.0004561533\n",
      "[042/01659] val_loss: 0.0004350267\n",
      "[042/01759] train_loss: 0.0004755001\n",
      "[042/01759] val_loss: 0.0004308899\n",
      "[042/01859] train_loss: 0.0004477215\n",
      "[042/01859] val_loss: 0.0005164481\n",
      "[043/00039] train_loss: 0.0004343486\n",
      "[043/00039] val_loss: 0.0004272867\n",
      "[043/00139] train_loss: 0.0004078743\n",
      "[043/00139] val_loss: 0.0004301628\n",
      "[043/00239] train_loss: 0.0004293265\n",
      "[043/00239] val_loss: 0.0004306013\n",
      "[043/00339] train_loss: 0.0004164505\n",
      "[043/00339] val_loss: 0.0004246606\n",
      "[043/00439] train_loss: 0.0004393025\n",
      "[043/00439] val_loss: 0.0004349498\n",
      "[043/00539] train_loss: 0.0004528088\n",
      "[043/00539] val_loss: 0.0004301141\n",
      "[043/00639] train_loss: 0.0004200133\n",
      "[043/00639] val_loss: 0.0004480137\n",
      "[043/00739] train_loss: 0.0004374301\n",
      "[043/00739] val_loss: 0.0004239609\n",
      "[043/00839] train_loss: 0.0004044183\n",
      "[043/00839] val_loss: 0.0004317962\n",
      "[043/00939] train_loss: 0.0004196651\n",
      "[043/00939] val_loss: 0.0004389433\n",
      "[043/01039] train_loss: 0.0004145648\n",
      "[043/01039] val_loss: 0.0004304362\n",
      "[043/01139] train_loss: 0.0004058028\n",
      "[043/01139] val_loss: 0.0004254711\n",
      "[043/01239] train_loss: 0.0004323621\n",
      "[043/01239] val_loss: 0.0004141666\n",
      "[043/01339] train_loss: 0.0004472271\n",
      "[043/01339] val_loss: 0.0004279357\n",
      "[043/01439] train_loss: 0.0004107481\n",
      "[043/01439] val_loss: 0.0004177107\n",
      "[043/01539] train_loss: 0.0003998790\n",
      "[043/01539] val_loss: 0.0004031124\n",
      "[043/01639] train_loss: 0.0003818802\n",
      "[043/01639] val_loss: 0.0004338766\n",
      "[043/01739] train_loss: 0.0004191240\n",
      "[043/01739] val_loss: 0.0004313091\n",
      "[043/01839] train_loss: 0.0004477263\n",
      "[043/01839] val_loss: 0.0004302850\n",
      "[044/00019] train_loss: 0.0004019135\n",
      "[044/00019] val_loss: 0.0004091197\n",
      "[044/00119] train_loss: 0.0003848230\n",
      "[044/00119] val_loss: 0.0004678018\n",
      "[044/00219] train_loss: 0.0004254383\n",
      "[044/00219] val_loss: 0.0004564175\n",
      "[044/00319] train_loss: 0.0003945658\n",
      "[044/00319] val_loss: 0.0004292369\n",
      "[044/00419] train_loss: 0.0004399568\n",
      "[044/00419] val_loss: 0.0004207402\n",
      "[044/00519] train_loss: 0.0004473394\n",
      "[044/00519] val_loss: 0.0004172853\n",
      "[044/00619] train_loss: 0.0004220953\n",
      "[044/00619] val_loss: 0.0004299590\n",
      "[044/00719] train_loss: 0.0004379917\n",
      "[044/00719] val_loss: 0.0004205239\n",
      "[044/00819] train_loss: 0.0004076520\n",
      "[044/00819] val_loss: 0.0004481927\n",
      "[044/00919] train_loss: 0.0004447344\n",
      "[044/00919] val_loss: 0.0004080801\n",
      "[044/01019] train_loss: 0.0004094917\n",
      "[044/01019] val_loss: 0.0004014932\n",
      "[044/01119] train_loss: 0.0004181994\n",
      "[044/01119] val_loss: 0.0004267155\n",
      "[044/01219] train_loss: 0.0003951363\n",
      "[044/01219] val_loss: 0.0004193509\n",
      "[044/01319] train_loss: 0.0004556644\n",
      "[044/01319] val_loss: 0.0004160700\n",
      "[044/01419] train_loss: 0.0004269573\n",
      "[044/01419] val_loss: 0.0004590512\n",
      "[044/01519] train_loss: 0.0004371491\n",
      "[044/01519] val_loss: 0.0004225073\n",
      "[044/01619] train_loss: 0.0005869780\n",
      "[044/01619] val_loss: 0.0004901285\n",
      "[044/01719] train_loss: 0.0004622010\n",
      "[044/01719] val_loss: 0.0004262929\n",
      "[044/01819] train_loss: 0.0004014464\n",
      "[044/01819] val_loss: 0.0004184179\n",
      "[044/01919] train_loss: 0.0004340613\n",
      "[044/01919] val_loss: 0.0004093994\n",
      "[045/00099] train_loss: 0.0004152892\n",
      "[045/00099] val_loss: 0.0004114355\n",
      "[045/00199] train_loss: 0.0003732520\n",
      "[045/00199] val_loss: 0.0004035519\n",
      "[045/00299] train_loss: 0.0003864916\n",
      "[045/00299] val_loss: 0.0004022509\n",
      "[045/00399] train_loss: 0.0003695367\n",
      "[045/00399] val_loss: 0.0004072631\n",
      "[045/00499] train_loss: 0.0004266761\n",
      "[045/00499] val_loss: 0.0004096348\n",
      "[045/00599] train_loss: 0.0004128784\n",
      "[045/00599] val_loss: 0.0004041377\n",
      "[045/00699] train_loss: 0.0004193554\n",
      "[045/00699] val_loss: 0.0004403555\n",
      "[045/00799] train_loss: 0.0004466651\n",
      "[045/00799] val_loss: 0.0004159676\n",
      "[045/00899] train_loss: 0.0004034197\n",
      "[045/00899] val_loss: 0.0004129837\n",
      "[045/00999] train_loss: 0.0004220183\n",
      "[045/00999] val_loss: 0.0004123625\n",
      "[045/01099] train_loss: 0.0004248296\n",
      "[045/01099] val_loss: 0.0004209555\n",
      "[045/01199] train_loss: 0.0004219066\n",
      "[045/01199] val_loss: 0.0004039093\n",
      "[045/01299] train_loss: 0.0004291827\n",
      "[045/01299] val_loss: 0.0003989660\n",
      "[045/01399] train_loss: 0.0004573484\n",
      "[045/01399] val_loss: 0.0004603857\n",
      "[045/01499] train_loss: 0.0004474766\n",
      "[045/01499] val_loss: 0.0004025669\n",
      "[045/01599] train_loss: 0.0004087938\n",
      "[045/01599] val_loss: 0.0004217745\n",
      "[045/01699] train_loss: 0.0004377169\n",
      "[045/01699] val_loss: 0.0004312850\n",
      "[045/01799] train_loss: 0.0004088153\n",
      "[045/01799] val_loss: 0.0004182969\n",
      "[045/01899] train_loss: 0.0003841897\n",
      "[045/01899] val_loss: 0.0004088713\n",
      "[046/00079] train_loss: 0.0003759388\n",
      "[046/00079] val_loss: 0.0004247439\n",
      "[046/00179] train_loss: 0.0004393653\n",
      "[046/00179] val_loss: 0.0004203745\n",
      "[046/00279] train_loss: 0.0004285235\n",
      "[046/00279] val_loss: 0.0004628584\n",
      "[046/00379] train_loss: 0.0003983860\n",
      "[046/00379] val_loss: 0.0004363797\n",
      "[046/00479] train_loss: 0.0003799973\n",
      "[046/00479] val_loss: 0.0004161401\n",
      "[046/00579] train_loss: 0.0004071342\n",
      "[046/00579] val_loss: 0.0004135509\n",
      "[046/00679] train_loss: 0.0004169174\n",
      "[046/00679] val_loss: 0.0004305655\n",
      "[046/00779] train_loss: 0.0003807832\n",
      "[046/00779] val_loss: 0.0004052548\n",
      "[046/00879] train_loss: 0.0003746297\n",
      "[046/00879] val_loss: 0.0004108052\n",
      "[046/00979] train_loss: 0.0003888099\n",
      "[046/00979] val_loss: 0.0004160635\n",
      "[046/01079] train_loss: 0.0004730196\n",
      "[046/01079] val_loss: 0.0004254349\n",
      "[046/01179] train_loss: 0.0004935675\n",
      "[046/01179] val_loss: 0.0004941397\n",
      "[046/01279] train_loss: 0.0004486794\n",
      "[046/01279] val_loss: 0.0004246802\n",
      "[046/01379] train_loss: 0.0004426349\n",
      "[046/01379] val_loss: 0.0004264889\n",
      "[046/01479] train_loss: 0.0003844998\n",
      "[046/01479] val_loss: 0.0004023891\n",
      "[046/01579] train_loss: 0.0004027505\n",
      "[046/01579] val_loss: 0.0004077577\n",
      "[046/01679] train_loss: 0.0004195588\n",
      "[046/01679] val_loss: 0.0004109803\n",
      "[046/01779] train_loss: 0.0004006672\n",
      "[046/01779] val_loss: 0.0004625026\n",
      "[046/01879] train_loss: 0.0004335378\n",
      "[046/01879] val_loss: 0.0004245817\n",
      "[047/00059] train_loss: 0.0004197206\n",
      "[047/00059] val_loss: 0.0004149867\n",
      "[047/00159] train_loss: 0.0003940807\n",
      "[047/00159] val_loss: 0.0004235737\n",
      "[047/00259] train_loss: 0.0003791347\n",
      "[047/00259] val_loss: 0.0004114037\n",
      "[047/00359] train_loss: 0.0004177878\n",
      "[047/00359] val_loss: 0.0004150020\n",
      "[047/00459] train_loss: 0.0004427352\n",
      "[047/00459] val_loss: 0.0004258585\n",
      "[047/00559] train_loss: 0.0004133218\n",
      "[047/00559] val_loss: 0.0004141712\n",
      "[047/00659] train_loss: 0.0003868167\n",
      "[047/00659] val_loss: 0.0004056382\n",
      "[047/00759] train_loss: 0.0004148403\n",
      "[047/00759] val_loss: 0.0004036312\n",
      "[047/00859] train_loss: 0.0004554360\n",
      "[047/00859] val_loss: 0.0004212252\n",
      "[047/00959] train_loss: 0.0004136562\n",
      "[047/00959] val_loss: 0.0004075266\n",
      "[047/01059] train_loss: 0.0003967634\n",
      "[047/01059] val_loss: 0.0004186462\n",
      "[047/01159] train_loss: 0.0004203167\n",
      "[047/01159] val_loss: 0.0004446315\n",
      "[047/01259] train_loss: 0.0004470540\n",
      "[047/01259] val_loss: 0.0004205149\n",
      "[047/01359] train_loss: 0.0004101614\n",
      "[047/01359] val_loss: 0.0004046700\n",
      "[047/01459] train_loss: 0.0004066056\n",
      "[047/01459] val_loss: 0.0003999967\n",
      "[047/01559] train_loss: 0.0004224839\n",
      "[047/01559] val_loss: 0.0004155631\n",
      "[047/01659] train_loss: 0.0004852776\n",
      "[047/01659] val_loss: 0.0004372220\n",
      "[047/01759] train_loss: 0.0004253533\n",
      "[047/01759] val_loss: 0.0004215221\n",
      "[047/01859] train_loss: 0.0004027781\n",
      "[047/01859] val_loss: 0.0004123416\n",
      "[048/00039] train_loss: 0.0004033094\n",
      "[048/00039] val_loss: 0.0004138641\n",
      "[048/00139] train_loss: 0.0004273391\n",
      "[048/00139] val_loss: 0.0004175183\n",
      "[048/00239] train_loss: 0.0004003428\n",
      "[048/00239] val_loss: 0.0004114835\n",
      "[048/00339] train_loss: 0.0004413559\n",
      "[048/00339] val_loss: 0.0004016012\n",
      "[048/00439] train_loss: 0.0003650153\n",
      "[048/00439] val_loss: 0.0004204606\n",
      "[048/00539] train_loss: 0.0004372254\n",
      "[048/00539] val_loss: 0.0004132323\n",
      "[048/00639] train_loss: 0.0003967251\n",
      "[048/00639] val_loss: 0.0004189004\n",
      "[048/00739] train_loss: 0.0004091307\n",
      "[048/00739] val_loss: 0.0004329404\n",
      "[048/00839] train_loss: 0.0003572849\n",
      "[048/00839] val_loss: 0.0004208518\n",
      "[048/00939] train_loss: 0.0003661530\n",
      "[048/00939] val_loss: 0.0004094404\n",
      "[048/01039] train_loss: 0.0003779370\n",
      "[048/01039] val_loss: 0.0004183763\n",
      "[048/01139] train_loss: 0.0004149892\n",
      "[048/01139] val_loss: 0.0004102852\n",
      "[048/01239] train_loss: 0.0004205290\n",
      "[048/01239] val_loss: 0.0004231190\n",
      "[048/01339] train_loss: 0.0004353399\n",
      "[048/01339] val_loss: 0.0005408002\n",
      "[048/01439] train_loss: 0.0005421101\n",
      "[048/01439] val_loss: 0.0004311512\n",
      "[048/01539] train_loss: 0.0004100360\n",
      "[048/01539] val_loss: 0.0004144043\n",
      "[048/01639] train_loss: 0.0004183491\n",
      "[048/01639] val_loss: 0.0004166173\n",
      "[048/01739] train_loss: 0.0003960362\n",
      "[048/01739] val_loss: 0.0004231334\n",
      "[048/01839] train_loss: 0.0003911276\n",
      "[048/01839] val_loss: 0.0004039629\n",
      "[049/00019] train_loss: 0.0003747853\n",
      "[049/00019] val_loss: 0.0004178320\n",
      "[049/00119] train_loss: 0.0003638833\n",
      "[049/00119] val_loss: 0.0004250988\n",
      "[049/00219] train_loss: 0.0004224750\n",
      "[049/00219] val_loss: 0.0004175137\n",
      "[049/00319] train_loss: 0.0003931315\n",
      "[049/00319] val_loss: 0.0004200863\n",
      "[049/00419] train_loss: 0.0003598836\n",
      "[049/00419] val_loss: 0.0004061187\n",
      "[049/00519] train_loss: 0.0003703011\n",
      "[049/00519] val_loss: 0.0003977031\n",
      "[049/00619] train_loss: 0.0003957233\n",
      "[049/00619] val_loss: 0.0004161152\n",
      "[049/00719] train_loss: 0.0004044761\n",
      "[049/00719] val_loss: 0.0004013960\n",
      "[049/00819] train_loss: 0.0004234025\n",
      "[049/00819] val_loss: 0.0004614393\n",
      "[049/00919] train_loss: 0.0004174412\n",
      "[049/00919] val_loss: 0.0004089624\n",
      "[049/01019] train_loss: 0.0004009360\n",
      "[049/01019] val_loss: 0.0003949583\n",
      "[049/01119] train_loss: 0.0003997719\n",
      "[049/01119] val_loss: 0.0004029106\n",
      "[049/01219] train_loss: 0.0003787401\n",
      "[049/01219] val_loss: 0.0004058736\n",
      "[049/01319] train_loss: 0.0004490639\n",
      "[049/01319] val_loss: 0.0004255196\n",
      "[049/01419] train_loss: 0.0004617493\n",
      "[049/01419] val_loss: 0.0004431196\n",
      "[049/01519] train_loss: 0.0003913569\n",
      "[049/01519] val_loss: 0.0004014859\n",
      "[049/01619] train_loss: 0.0003672102\n",
      "[049/01619] val_loss: 0.0004232099\n",
      "[049/01719] train_loss: 0.0004444186\n",
      "[049/01719] val_loss: 0.0005237521\n",
      "[049/01819] train_loss: 0.0004626144\n",
      "[049/01819] val_loss: 0.0004424661\n",
      "[049/01919] train_loss: 0.0003961709\n",
      "[049/01919] val_loss: 0.0004028872\n",
      "[050/00099] train_loss: 0.0003975352\n",
      "[050/00099] val_loss: 0.0004223604\n",
      "[050/00199] train_loss: 0.0003813522\n",
      "[050/00199] val_loss: 0.0004044001\n",
      "[050/00299] train_loss: 0.0003482703\n",
      "[050/00299] val_loss: 0.0004351466\n",
      "[050/00399] train_loss: 0.0003888476\n",
      "[050/00399] val_loss: 0.0004195913\n",
      "[050/00499] train_loss: 0.0004134808\n",
      "[050/00499] val_loss: 0.0003996247\n",
      "[050/00599] train_loss: 0.0003849124\n",
      "[050/00599] val_loss: 0.0004168028\n",
      "[050/00699] train_loss: 0.0003823244\n",
      "[050/00699] val_loss: 0.0004136457\n",
      "[050/00799] train_loss: 0.0004393237\n",
      "[050/00799] val_loss: 0.0004134069\n",
      "[050/00899] train_loss: 0.0003924200\n",
      "[050/00899] val_loss: 0.0004415508\n",
      "[050/00999] train_loss: 0.0003947323\n",
      "[050/00999] val_loss: 0.0004153826\n",
      "[050/01099] train_loss: 0.0003931924\n",
      "[050/01099] val_loss: 0.0004367925\n",
      "[050/01199] train_loss: 0.0003925846\n",
      "[050/01199] val_loss: 0.0004092309\n",
      "[050/01299] train_loss: 0.0005593038\n",
      "[050/01299] val_loss: 0.0004960226\n",
      "[050/01399] train_loss: 0.0004007861\n",
      "[050/01399] val_loss: 0.0004072718\n",
      "[050/01499] train_loss: 0.0004145123\n",
      "[050/01499] val_loss: 0.0004064804\n",
      "[050/01599] train_loss: 0.0004031292\n",
      "[050/01599] val_loss: 0.0004049779\n",
      "[050/01699] train_loss: 0.0003730141\n",
      "[050/01699] val_loss: 0.0004030433\n",
      "[050/01799] train_loss: 0.0004026545\n",
      "[050/01799] val_loss: 0.0004012925\n",
      "[050/01899] train_loss: 0.0003573715\n",
      "[050/01899] val_loss: 0.0003984188\n",
      "[051/00079] train_loss: 0.0004474376\n",
      "[051/00079] val_loss: 0.0006119082\n",
      "[051/00179] train_loss: 0.0005576405\n",
      "[051/00179] val_loss: 0.0004437495\n",
      "[051/00279] train_loss: 0.0004342505\n",
      "[051/00279] val_loss: 0.0004108740\n",
      "[051/00379] train_loss: 0.0003711327\n",
      "[051/00379] val_loss: 0.0003951862\n",
      "[051/00479] train_loss: 0.0004024012\n",
      "[051/00479] val_loss: 0.0003904519\n",
      "[051/00579] train_loss: 0.0003507632\n",
      "[051/00579] val_loss: 0.0003933237\n",
      "[051/00679] train_loss: 0.0004346647\n",
      "[051/00679] val_loss: 0.0004129989\n",
      "[051/00779] train_loss: 0.0003892490\n",
      "[051/00779] val_loss: 0.0004384779\n",
      "[051/00879] train_loss: 0.0003889198\n",
      "[051/00879] val_loss: 0.0004483297\n",
      "[051/00979] train_loss: 0.0003862669\n",
      "[051/00979] val_loss: 0.0004122878\n",
      "[051/01079] train_loss: 0.0003759726\n",
      "[051/01079] val_loss: 0.0004082892\n",
      "[051/01179] train_loss: 0.0003759474\n",
      "[051/01179] val_loss: 0.0003993091\n",
      "[051/01279] train_loss: 0.0003678031\n",
      "[051/01279] val_loss: 0.0004478000\n",
      "[051/01379] train_loss: 0.0004079654\n",
      "[051/01379] val_loss: 0.0004149618\n",
      "[051/01479] train_loss: 0.0003815100\n",
      "[051/01479] val_loss: 0.0004083955\n",
      "[051/01579] train_loss: 0.0003950201\n",
      "[051/01579] val_loss: 0.0004128063\n",
      "[051/01679] train_loss: 0.0003747476\n",
      "[051/01679] val_loss: 0.0004135184\n",
      "[051/01779] train_loss: 0.0003858452\n",
      "[051/01779] val_loss: 0.0003951001\n",
      "[051/01879] train_loss: 0.0004181271\n",
      "[051/01879] val_loss: 0.0004109011\n",
      "[052/00059] train_loss: 0.0003986173\n",
      "[052/00059] val_loss: 0.0004152167\n",
      "[052/00159] train_loss: 0.0003651747\n",
      "[052/00159] val_loss: 0.0004115610\n",
      "[052/00259] train_loss: 0.0003962847\n",
      "[052/00259] val_loss: 0.0004217214\n",
      "[052/00359] train_loss: 0.0003332836\n",
      "[052/00359] val_loss: 0.0004007589\n",
      "[052/00459] train_loss: 0.0004164675\n",
      "[052/00459] val_loss: 0.0004328036\n",
      "[052/00559] train_loss: 0.0004024571\n",
      "[052/00559] val_loss: 0.0004204796\n",
      "[052/00659] train_loss: 0.0005442516\n",
      "[052/00659] val_loss: 0.0004306391\n",
      "[052/00759] train_loss: 0.0004312421\n",
      "[052/00759] val_loss: 0.0004336913\n",
      "[052/00859] train_loss: 0.0003992308\n",
      "[052/00859] val_loss: 0.0004005568\n",
      "[052/00959] train_loss: 0.0004058578\n",
      "[052/00959] val_loss: 0.0004156276\n",
      "[052/01059] train_loss: 0.0003966247\n",
      "[052/01059] val_loss: 0.0004361679\n",
      "[052/01159] train_loss: 0.0003875354\n",
      "[052/01159] val_loss: 0.0004370701\n",
      "[052/01259] train_loss: 0.0003827150\n",
      "[052/01259] val_loss: 0.0003969070\n",
      "[052/01359] train_loss: 0.0003960641\n",
      "[052/01359] val_loss: 0.0004064355\n",
      "[052/01459] train_loss: 0.0004213560\n",
      "[052/01459] val_loss: 0.0004140550\n",
      "[052/01559] train_loss: 0.0003907880\n",
      "[052/01559] val_loss: 0.0004093126\n",
      "[052/01659] train_loss: 0.0003736066\n",
      "[052/01659] val_loss: 0.0004164731\n",
      "[052/01759] train_loss: 0.0004044623\n",
      "[052/01759] val_loss: 0.0003939630\n",
      "[052/01859] train_loss: 0.0004120401\n",
      "[052/01859] val_loss: 0.0004148786\n",
      "[053/00039] train_loss: 0.0003813143\n",
      "[053/00039] val_loss: 0.0004293275\n",
      "[053/00139] train_loss: 0.0003902287\n",
      "[053/00139] val_loss: 0.0004198983\n",
      "[053/00239] train_loss: 0.0003745183\n",
      "[053/00239] val_loss: 0.0004178516\n",
      "[053/00339] train_loss: 0.0003844563\n",
      "[053/00339] val_loss: 0.0004516928\n",
      "[053/00439] train_loss: 0.0003887725\n",
      "[053/00439] val_loss: 0.0004179439\n",
      "[053/00539] train_loss: 0.0004051157\n",
      "[053/00539] val_loss: 0.0004037353\n",
      "[053/00639] train_loss: 0.0003949440\n",
      "[053/00639] val_loss: 0.0003972837\n",
      "[053/00739] train_loss: 0.0003879302\n",
      "[053/00739] val_loss: 0.0003987841\n",
      "[053/00839] train_loss: 0.0003625170\n",
      "[053/00839] val_loss: 0.0004021333\n",
      "[053/00939] train_loss: 0.0004428237\n",
      "[053/00939] val_loss: 0.0004211388\n",
      "[053/01039] train_loss: 0.0003696731\n",
      "[053/01039] val_loss: 0.0004097785\n",
      "[053/01139] train_loss: 0.0003800776\n",
      "[053/01139] val_loss: 0.0003938920\n",
      "[053/01239] train_loss: 0.0004059426\n",
      "[053/01239] val_loss: 0.0004010450\n",
      "[053/01339] train_loss: 0.0003714873\n",
      "[053/01339] val_loss: 0.0004305770\n",
      "[053/01439] train_loss: 0.0003739907\n",
      "[053/01439] val_loss: 0.0004059690\n",
      "[053/01539] train_loss: 0.0003998965\n",
      "[053/01539] val_loss: 0.0003931410\n",
      "[053/01639] train_loss: 0.0004031037\n",
      "[053/01639] val_loss: 0.0004447615\n",
      "[053/01739] train_loss: 0.0004204093\n",
      "[053/01739] val_loss: 0.0004201682\n",
      "[053/01839] train_loss: 0.0003717989\n",
      "[053/01839] val_loss: 0.0003906251\n",
      "[054/00019] train_loss: 0.0003611337\n",
      "[054/00019] val_loss: 0.0004047158\n",
      "[054/00119] train_loss: 0.0003896689\n",
      "[054/00119] val_loss: 0.0003981467\n",
      "[054/00219] train_loss: 0.0004000486\n",
      "[054/00219] val_loss: 0.0004169639\n",
      "[054/00319] train_loss: 0.0003851588\n",
      "[054/00319] val_loss: 0.0003980152\n",
      "[054/00419] train_loss: 0.0003596997\n",
      "[054/00419] val_loss: 0.0003964685\n",
      "[054/00519] train_loss: 0.0003979571\n",
      "[054/00519] val_loss: 0.0004397866\n",
      "[054/00619] train_loss: 0.0004144901\n",
      "[054/00619] val_loss: 0.0003975552\n",
      "[054/00719] train_loss: 0.0003945909\n",
      "[054/00719] val_loss: 0.0004167691\n",
      "[054/00819] train_loss: 0.0003701325\n",
      "[054/00819] val_loss: 0.0003924089\n",
      "[054/00919] train_loss: 0.0003883239\n",
      "[054/00919] val_loss: 0.0004128513\n",
      "[054/01019] train_loss: 0.0004090602\n",
      "[054/01019] val_loss: 0.0003954044\n",
      "[054/01119] train_loss: 0.0004138287\n",
      "[054/01119] val_loss: 0.0004324789\n",
      "[054/01219] train_loss: 0.0004332651\n",
      "[054/01219] val_loss: 0.0003982109\n",
      "[054/01319] train_loss: 0.0003685600\n",
      "[054/01319] val_loss: 0.0004499359\n",
      "[054/01419] train_loss: 0.0003723258\n",
      "[054/01419] val_loss: 0.0003896235\n",
      "[054/01519] train_loss: 0.0004011264\n",
      "[054/01519] val_loss: 0.0004165669\n",
      "[054/01619] train_loss: 0.0003817586\n",
      "[054/01619] val_loss: 0.0004121090\n",
      "[054/01719] train_loss: 0.0003586310\n",
      "[054/01719] val_loss: 0.0003972580\n",
      "[054/01819] train_loss: 0.0004078696\n",
      "[054/01819] val_loss: 0.0004098597\n",
      "[054/01919] train_loss: 0.0003586868\n",
      "[054/01919] val_loss: 0.0003897652\n",
      "[055/00099] train_loss: 0.0003759808\n",
      "[055/00099] val_loss: 0.0003938014\n",
      "[055/00199] train_loss: 0.0003676483\n",
      "[055/00199] val_loss: 0.0003917957\n",
      "[055/00299] train_loss: 0.0003490930\n",
      "[055/00299] val_loss: 0.0003880002\n",
      "[055/00399] train_loss: 0.0003571463\n",
      "[055/00399] val_loss: 0.0004091891\n",
      "[055/00499] train_loss: 0.0003576354\n",
      "[055/00499] val_loss: 0.0004158464\n",
      "[055/00599] train_loss: 0.0003974315\n",
      "[055/00599] val_loss: 0.0004321368\n",
      "[055/00699] train_loss: 0.0003645092\n",
      "[055/00699] val_loss: 0.0003918212\n",
      "[055/00799] train_loss: 0.0004277521\n",
      "[055/00799] val_loss: 0.0004099350\n",
      "[055/00899] train_loss: 0.0004020781\n",
      "[055/00899] val_loss: 0.0004026538\n",
      "[055/00999] train_loss: 0.0003897230\n",
      "[055/00999] val_loss: 0.0004013369\n",
      "[055/01099] train_loss: 0.0003761602\n",
      "[055/01099] val_loss: 0.0004033111\n",
      "[055/01199] train_loss: 0.0003644533\n",
      "[055/01199] val_loss: 0.0004015569\n",
      "[055/01299] train_loss: 0.0003655941\n",
      "[055/01299] val_loss: 0.0003835523\n",
      "[055/01399] train_loss: 0.0003747452\n",
      "[055/01399] val_loss: 0.0004261739\n",
      "[055/01499] train_loss: 0.0003678589\n",
      "[055/01499] val_loss: 0.0003971229\n",
      "[055/01599] train_loss: 0.0003840263\n",
      "[055/01599] val_loss: 0.0004052240\n",
      "[055/01699] train_loss: 0.0003891448\n",
      "[055/01699] val_loss: 0.0004069701\n",
      "[055/01799] train_loss: 0.0004011744\n",
      "[055/01799] val_loss: 0.0003992641\n",
      "[055/01899] train_loss: 0.0004163228\n",
      "[055/01899] val_loss: 0.0004054829\n",
      "[056/00079] train_loss: 0.0003909492\n",
      "[056/00079] val_loss: 0.0004158606\n",
      "[056/00179] train_loss: 0.0003719596\n",
      "[056/00179] val_loss: 0.0004628221\n",
      "[056/00279] train_loss: 0.0003610611\n",
      "[056/00279] val_loss: 0.0003896830\n",
      "[056/00379] train_loss: 0.0003704077\n",
      "[056/00379] val_loss: 0.0004049289\n",
      "[056/00479] train_loss: 0.0003524307\n",
      "[056/00479] val_loss: 0.0004046541\n",
      "[056/00579] train_loss: 0.0003903820\n",
      "[056/00579] val_loss: 0.0003980852\n",
      "[056/00679] train_loss: 0.0003714992\n",
      "[056/00679] val_loss: 0.0003965001\n",
      "[056/00779] train_loss: 0.0003475686\n",
      "[056/00779] val_loss: 0.0003974012\n",
      "[056/00879] train_loss: 0.0003784287\n",
      "[056/00879] val_loss: 0.0004012623\n",
      "[056/00979] train_loss: 0.0003790981\n",
      "[056/00979] val_loss: 0.0004025123\n",
      "[056/01079] train_loss: 0.0003702003\n",
      "[056/01079] val_loss: 0.0003969981\n",
      "[056/01179] train_loss: 0.0003277907\n",
      "[056/01179] val_loss: 0.0003923985\n",
      "[056/01279] train_loss: 0.0003984475\n",
      "[056/01279] val_loss: 0.0004287869\n",
      "[056/01379] train_loss: 0.0003628510\n",
      "[056/01379] val_loss: 0.0003962158\n",
      "[056/01479] train_loss: 0.0004414750\n",
      "[056/01479] val_loss: 0.0004660611\n",
      "[056/01579] train_loss: 0.0003972580\n",
      "[056/01579] val_loss: 0.0004352725\n",
      "[056/01679] train_loss: 0.0005023075\n",
      "[056/01679] val_loss: 0.0004437959\n",
      "[056/01779] train_loss: 0.0004273898\n",
      "[056/01779] val_loss: 0.0004628981\n",
      "[056/01879] train_loss: 0.0004265778\n",
      "[056/01879] val_loss: 0.0004503734\n",
      "[057/00059] train_loss: 0.0003638027\n",
      "[057/00059] val_loss: 0.0004016367\n",
      "[057/00159] train_loss: 0.0003770310\n",
      "[057/00159] val_loss: 0.0004373326\n",
      "[057/00259] train_loss: 0.0003373900\n",
      "[057/00259] val_loss: 0.0004019192\n",
      "[057/00359] train_loss: 0.0003416340\n",
      "[057/00359] val_loss: 0.0003965817\n",
      "[057/00459] train_loss: 0.0003673223\n",
      "[057/00459] val_loss: 0.0004000694\n",
      "[057/00559] train_loss: 0.0003863042\n",
      "[057/00559] val_loss: 0.0004190831\n",
      "[057/00659] train_loss: 0.0003937255\n",
      "[057/00659] val_loss: 0.0004048433\n",
      "[057/00759] train_loss: 0.0004490971\n",
      "[057/00759] val_loss: 0.0004048888\n",
      "[057/00859] train_loss: 0.0003890216\n",
      "[057/00859] val_loss: 0.0003918089\n",
      "[057/00959] train_loss: 0.0003557717\n",
      "[057/00959] val_loss: 0.0003904858\n",
      "[057/01059] train_loss: 0.0003790068\n",
      "[057/01059] val_loss: 0.0003900631\n",
      "[057/01159] train_loss: 0.0004087707\n",
      "[057/01159] val_loss: 0.0003789398\n",
      "[057/01259] train_loss: 0.0003742979\n",
      "[057/01259] val_loss: 0.0004037061\n",
      "[057/01359] train_loss: 0.0003904818\n",
      "[057/01359] val_loss: 0.0004352351\n",
      "[057/01459] train_loss: 0.0003887825\n",
      "[057/01459] val_loss: 0.0003906494\n",
      "[057/01559] train_loss: 0.0003855142\n",
      "[057/01559] val_loss: 0.0004664979\n",
      "[057/01659] train_loss: 0.0003899762\n",
      "[057/01659] val_loss: 0.0003980597\n",
      "[057/01759] train_loss: 0.0003710149\n",
      "[057/01759] val_loss: 0.0003905709\n",
      "[057/01859] train_loss: 0.0003410692\n",
      "[057/01859] val_loss: 0.0003916288\n",
      "[058/00039] train_loss: 0.0003683272\n",
      "[058/00039] val_loss: 0.0004008857\n",
      "[058/00139] train_loss: 0.0003687800\n",
      "[058/00139] val_loss: 0.0003994328\n",
      "[058/00239] train_loss: 0.0003784290\n",
      "[058/00239] val_loss: 0.0004226308\n",
      "[058/00339] train_loss: 0.0003632700\n",
      "[058/00339] val_loss: 0.0004250739\n",
      "[058/00439] train_loss: 0.0003946715\n",
      "[058/00439] val_loss: 0.0003973976\n",
      "[058/00539] train_loss: 0.0003330569\n",
      "[058/00539] val_loss: 0.0003848748\n",
      "[058/00639] train_loss: 0.0004125431\n",
      "[058/00639] val_loss: 0.0004369366\n",
      "[058/00739] train_loss: 0.0003438694\n",
      "[058/00739] val_loss: 0.0004156007\n",
      "[058/00839] train_loss: 0.0003797427\n",
      "[058/00839] val_loss: 0.0004094806\n",
      "[058/00939] train_loss: 0.0003493110\n",
      "[058/00939] val_loss: 0.0004081612\n",
      "[058/01039] train_loss: 0.0003509704\n",
      "[058/01039] val_loss: 0.0004031221\n",
      "[058/01139] train_loss: 0.0004024264\n",
      "[058/01139] val_loss: 0.0003991206\n",
      "[058/01239] train_loss: 0.0003975280\n",
      "[058/01239] val_loss: 0.0003962223\n",
      "[058/01339] train_loss: 0.0003710648\n",
      "[058/01339] val_loss: 0.0004351464\n",
      "[058/01439] train_loss: 0.0004561964\n",
      "[058/01439] val_loss: 0.0004090182\n",
      "[058/01539] train_loss: 0.0004068478\n",
      "[058/01539] val_loss: 0.0004345670\n",
      "[058/01639] train_loss: 0.0003862920\n",
      "[058/01639] val_loss: 0.0003936198\n",
      "[058/01739] train_loss: 0.0003853697\n",
      "[058/01739] val_loss: 0.0003867674\n",
      "[058/01839] train_loss: 0.0003800106\n",
      "[058/01839] val_loss: 0.0003910654\n",
      "[059/00019] train_loss: 0.0003616806\n",
      "[059/00019] val_loss: 0.0003979041\n",
      "[059/00119] train_loss: 0.0003873852\n",
      "[059/00119] val_loss: 0.0004385732\n",
      "[059/00219] train_loss: 0.0003974834\n",
      "[059/00219] val_loss: 0.0003861631\n",
      "[059/00319] train_loss: 0.0003779803\n",
      "[059/00319] val_loss: 0.0003881418\n",
      "[059/00419] train_loss: 0.0003591634\n",
      "[059/00419] val_loss: 0.0003821492\n",
      "[059/00519] train_loss: 0.0003472432\n",
      "[059/00519] val_loss: 0.0004094660\n",
      "[059/00619] train_loss: 0.0003688968\n",
      "[059/00619] val_loss: 0.0003953846\n",
      "[059/00719] train_loss: 0.0003817465\n",
      "[059/00719] val_loss: 0.0004054729\n",
      "[059/00819] train_loss: 0.0003844056\n",
      "[059/00819] val_loss: 0.0003906904\n",
      "[059/00919] train_loss: 0.0003527302\n",
      "[059/00919] val_loss: 0.0003937385\n",
      "[059/01019] train_loss: 0.0003630889\n",
      "[059/01019] val_loss: 0.0003959479\n",
      "[059/01119] train_loss: 0.0003249086\n",
      "[059/01119] val_loss: 0.0003911373\n",
      "[059/01219] train_loss: 0.0003357997\n",
      "[059/01219] val_loss: 0.0004166659\n",
      "[059/01319] train_loss: 0.0003866280\n",
      "[059/01319] val_loss: 0.0004194668\n",
      "[059/01419] train_loss: 0.0003939927\n",
      "[059/01419] val_loss: 0.0004599638\n",
      "[059/01519] train_loss: 0.0004495687\n",
      "[059/01519] val_loss: 0.0004264239\n",
      "[059/01619] train_loss: 0.0003836822\n",
      "[059/01619] val_loss: 0.0004019686\n",
      "[059/01719] train_loss: 0.0004119236\n",
      "[059/01719] val_loss: 0.0003923885\n",
      "[059/01819] train_loss: 0.0003918577\n",
      "[059/01819] val_loss: 0.0003860476\n",
      "[059/01919] train_loss: 0.0003324946\n",
      "[059/01919] val_loss: 0.0003892604\n",
      "[060/00099] train_loss: 0.0003498663\n",
      "[060/00099] val_loss: 0.0003858836\n",
      "[060/00199] train_loss: 0.0003543715\n",
      "[060/00199] val_loss: 0.0004002044\n",
      "[060/00299] train_loss: 0.0003754303\n",
      "[060/00299] val_loss: 0.0004210922\n",
      "[060/00399] train_loss: 0.0003720364\n",
      "[060/00399] val_loss: 0.0003859022\n",
      "[060/00499] train_loss: 0.0003730124\n",
      "[060/00499] val_loss: 0.0004462381\n",
      "[060/00599] train_loss: 0.0004052033\n",
      "[060/00599] val_loss: 0.0004328804\n",
      "[060/00699] train_loss: 0.0003547174\n",
      "[060/00699] val_loss: 0.0004157622\n",
      "[060/00799] train_loss: 0.0003830571\n",
      "[060/00799] val_loss: 0.0004111854\n",
      "[060/00899] train_loss: 0.0003626105\n",
      "[060/00899] val_loss: 0.0003823201\n",
      "[060/00999] train_loss: 0.0003388979\n",
      "[060/00999] val_loss: 0.0003869934\n",
      "[060/01099] train_loss: 0.0003948970\n",
      "[060/01099] val_loss: 0.0004018795\n",
      "[060/01199] train_loss: 0.0003956785\n",
      "[060/01199] val_loss: 0.0004197714\n",
      "[060/01299] train_loss: 0.0003968734\n",
      "[060/01299] val_loss: 0.0004036305\n",
      "[060/01399] train_loss: 0.0003459504\n",
      "[060/01399] val_loss: 0.0003914967\n",
      "[060/01499] train_loss: 0.0003501844\n",
      "[060/01499] val_loss: 0.0003956931\n",
      "[060/01599] train_loss: 0.0004035547\n",
      "[060/01599] val_loss: 0.0004039756\n",
      "[060/01699] train_loss: 0.0003546644\n",
      "[060/01699] val_loss: 0.0003957614\n",
      "[060/01799] train_loss: 0.0003748621\n",
      "[060/01799] val_loss: 0.0003995493\n",
      "[060/01899] train_loss: 0.0003604506\n",
      "[060/01899] val_loss: 0.0003962253\n",
      "[061/00079] train_loss: 0.0003699560\n",
      "[061/00079] val_loss: 0.0004013891\n",
      "[061/00179] train_loss: 0.0003567694\n",
      "[061/00179] val_loss: 0.0003821919\n",
      "[061/00279] train_loss: 0.0003580962\n",
      "[061/00279] val_loss: 0.0004067187\n",
      "[061/00379] train_loss: 0.0003618585\n",
      "[061/00379] val_loss: 0.0003850915\n",
      "[061/00479] train_loss: 0.0003612572\n",
      "[061/00479] val_loss: 0.0003864835\n",
      "[061/00579] train_loss: 0.0003227992\n",
      "[061/00579] val_loss: 0.0004034030\n",
      "[061/00679] train_loss: 0.0003140254\n",
      "[061/00679] val_loss: 0.0004007300\n",
      "[061/00779] train_loss: 0.0003649961\n",
      "[061/00779] val_loss: 0.0003800476\n",
      "[061/00879] train_loss: 0.0003541717\n",
      "[061/00879] val_loss: 0.0003989613\n",
      "[061/00979] train_loss: 0.0003408603\n",
      "[061/00979] val_loss: 0.0004055049\n",
      "[061/01079] train_loss: 0.0003553014\n",
      "[061/01079] val_loss: 0.0004069970\n",
      "[061/01179] train_loss: 0.0004051023\n",
      "[061/01179] val_loss: 0.0003940671\n",
      "[061/01279] train_loss: 0.0003595615\n",
      "[061/01279] val_loss: 0.0003829895\n",
      "[061/01379] train_loss: 0.0003852850\n",
      "[061/01379] val_loss: 0.0004031426\n",
      "[061/01479] train_loss: 0.0003703445\n",
      "[061/01479] val_loss: 0.0004055549\n",
      "[061/01579] train_loss: 0.0003476166\n",
      "[061/01579] val_loss: 0.0003857524\n",
      "[061/01679] train_loss: 0.0003490921\n",
      "[061/01679] val_loss: 0.0003951739\n",
      "[061/01779] train_loss: 0.0003896378\n",
      "[061/01779] val_loss: 0.0003835498\n",
      "[061/01879] train_loss: 0.0004061377\n",
      "[061/01879] val_loss: 0.0009851197\n",
      "[062/00059] train_loss: 0.0004591248\n",
      "[062/00059] val_loss: 0.0003813220\n",
      "[062/00159] train_loss: 0.0003478034\n",
      "[062/00159] val_loss: 0.0003759108\n",
      "[062/00259] train_loss: 0.0003721755\n",
      "[062/00259] val_loss: 0.0004008136\n",
      "[062/00359] train_loss: 0.0003744896\n",
      "[062/00359] val_loss: 0.0003755813\n",
      "[062/00459] train_loss: 0.0003448499\n",
      "[062/00459] val_loss: 0.0003819880\n",
      "[062/00559] train_loss: 0.0003757514\n",
      "[062/00559] val_loss: 0.0003976985\n",
      "[062/00659] train_loss: 0.0003736159\n",
      "[062/00659] val_loss: 0.0003889460\n",
      "[062/00759] train_loss: 0.0003632324\n",
      "[062/00759] val_loss: 0.0004312758\n",
      "[062/00859] train_loss: 0.0003841564\n",
      "[062/00859] val_loss: 0.0003788307\n",
      "[062/00959] train_loss: 0.0003504008\n",
      "[062/00959] val_loss: 0.0003842186\n",
      "[062/01059] train_loss: 0.0003361751\n",
      "[062/01059] val_loss: 0.0003879201\n",
      "[062/01159] train_loss: 0.0003396227\n",
      "[062/01159] val_loss: 0.0003825265\n",
      "[062/01259] train_loss: 0.0003726408\n",
      "[062/01259] val_loss: 0.0003921767\n",
      "[062/01359] train_loss: 0.0003458288\n",
      "[062/01359] val_loss: 0.0003745026\n",
      "[062/01459] train_loss: 0.0003421349\n",
      "[062/01459] val_loss: 0.0003814945\n",
      "[062/01559] train_loss: 0.0003813359\n",
      "[062/01559] val_loss: 0.0003831961\n",
      "[062/01659] train_loss: 0.0003709906\n",
      "[062/01659] val_loss: 0.0004275562\n",
      "[062/01759] train_loss: 0.0003544780\n",
      "[062/01759] val_loss: 0.0003974951\n",
      "[062/01859] train_loss: 0.0003722283\n",
      "[062/01859] val_loss: 0.0003846946\n",
      "[063/00039] train_loss: 0.0003802582\n",
      "[063/00039] val_loss: 0.0004006774\n",
      "[063/00139] train_loss: 0.0003185047\n",
      "[063/00139] val_loss: 0.0003860157\n",
      "[063/00239] train_loss: 0.0003553436\n",
      "[063/00239] val_loss: 0.0004009506\n",
      "[063/00339] train_loss: 0.0003314080\n",
      "[063/00339] val_loss: 0.0003875179\n",
      "[063/00439] train_loss: 0.0003513358\n",
      "[063/00439] val_loss: 0.0003928856\n",
      "[063/00539] train_loss: 0.0003376262\n",
      "[063/00539] val_loss: 0.0003934045\n",
      "[063/00639] train_loss: 0.0003508834\n",
      "[063/00639] val_loss: 0.0003771205\n",
      "[063/00739] train_loss: 0.0003628526\n",
      "[063/00739] val_loss: 0.0003925074\n",
      "[063/00839] train_loss: 0.0003405230\n",
      "[063/00839] val_loss: 0.0003858336\n",
      "[063/00939] train_loss: 0.0003481239\n",
      "[063/00939] val_loss: 0.0003989576\n",
      "[063/01039] train_loss: 0.0003581588\n",
      "[063/01039] val_loss: 0.0003876266\n",
      "[063/01139] train_loss: 0.0003755381\n",
      "[063/01139] val_loss: 0.0003811561\n",
      "[063/01239] train_loss: 0.0003617459\n",
      "[063/01239] val_loss: 0.0003981007\n",
      "[063/01339] train_loss: 0.0003365823\n",
      "[063/01339] val_loss: 0.0003884356\n",
      "[063/01439] train_loss: 0.0003765691\n",
      "[063/01439] val_loss: 0.0003958642\n",
      "[063/01539] train_loss: 0.0003810346\n",
      "[063/01539] val_loss: 0.0003791948\n",
      "[063/01639] train_loss: 0.0003777062\n",
      "[063/01639] val_loss: 0.0003939938\n",
      "[063/01739] train_loss: 0.0004103635\n",
      "[063/01739] val_loss: 0.0006053124\n",
      "[063/01839] train_loss: 0.0004284164\n",
      "[063/01839] val_loss: 0.0004310044\n",
      "[064/00019] train_loss: 0.0003696501\n",
      "[064/00019] val_loss: 0.0004289151\n",
      "[064/00119] train_loss: 0.0003484031\n",
      "[064/00119] val_loss: 0.0004224022\n",
      "[064/00219] train_loss: 0.0003313644\n",
      "[064/00219] val_loss: 0.0004078948\n",
      "[064/00319] train_loss: 0.0003705095\n",
      "[064/00319] val_loss: 0.0004009505\n",
      "[064/00419] train_loss: 0.0003595632\n",
      "[064/00419] val_loss: 0.0003890829\n",
      "[064/00519] train_loss: 0.0003731370\n",
      "[064/00519] val_loss: 0.0003966494\n",
      "[064/00619] train_loss: 0.0003579659\n",
      "[064/00619] val_loss: 0.0004046281\n",
      "[064/00719] train_loss: 0.0003446312\n",
      "[064/00719] val_loss: 0.0003787595\n",
      "[064/00819] train_loss: 0.0005481642\n",
      "[064/00819] val_loss: 0.0004372544\n",
      "[064/00919] train_loss: 0.0003536459\n",
      "[064/00919] val_loss: 0.0004035890\n",
      "[064/01019] train_loss: 0.0003691474\n",
      "[064/01019] val_loss: 0.0003930155\n",
      "[064/01119] train_loss: 0.0003529204\n",
      "[064/01119] val_loss: 0.0003778870\n",
      "[064/01219] train_loss: 0.0003225313\n",
      "[064/01219] val_loss: 0.0003960093\n",
      "[064/01319] train_loss: 0.0003467162\n",
      "[064/01319] val_loss: 0.0003863747\n",
      "[064/01419] train_loss: 0.0003201385\n",
      "[064/01419] val_loss: 0.0003721622\n",
      "[064/01519] train_loss: 0.0003501077\n",
      "[064/01519] val_loss: 0.0003888229\n",
      "[064/01619] train_loss: 0.0003801405\n",
      "[064/01619] val_loss: 0.0003839671\n",
      "[064/01719] train_loss: 0.0003522290\n",
      "[064/01719] val_loss: 0.0003829219\n",
      "[064/01819] train_loss: 0.0003793361\n",
      "[064/01819] val_loss: 0.0003875926\n",
      "[064/01919] train_loss: 0.0003894201\n",
      "[064/01919] val_loss: 0.0003854750\n",
      "[065/00099] train_loss: 0.0003458092\n",
      "[065/00099] val_loss: 0.0004135437\n",
      "[065/00199] train_loss: 0.0003347960\n",
      "[065/00199] val_loss: 0.0004126031\n",
      "[065/00299] train_loss: 0.0003760184\n",
      "[065/00299] val_loss: 0.0004014851\n",
      "[065/00399] train_loss: 0.0003873912\n",
      "[065/00399] val_loss: 0.0004024860\n",
      "[065/00499] train_loss: 0.0003406740\n",
      "[065/00499] val_loss: 0.0003975024\n",
      "[065/00599] train_loss: 0.0003511097\n",
      "[065/00599] val_loss: 0.0003909358\n",
      "[065/00699] train_loss: 0.0003409145\n",
      "[065/00699] val_loss: 0.0003789189\n",
      "[065/00799] train_loss: 0.0003409894\n",
      "[065/00799] val_loss: 0.0003828956\n",
      "[065/00899] train_loss: 0.0003533280\n",
      "[065/00899] val_loss: 0.0003841109\n",
      "[065/00999] train_loss: 0.0003516989\n",
      "[065/00999] val_loss: 0.0003925833\n",
      "[065/01099] train_loss: 0.0003586718\n",
      "[065/01099] val_loss: 0.0003752632\n",
      "[065/01199] train_loss: 0.0003934462\n",
      "[065/01199] val_loss: 0.0003971035\n",
      "[065/01299] train_loss: 0.0003546014\n",
      "[065/01299] val_loss: 0.0003808257\n",
      "[065/01399] train_loss: 0.0003520001\n",
      "[065/01399] val_loss: 0.0003723330\n",
      "[065/01499] train_loss: 0.0003585050\n",
      "[065/01499] val_loss: 0.0003850993\n",
      "[065/01599] train_loss: 0.0003140493\n",
      "[065/01599] val_loss: 0.0003770274\n",
      "[065/01699] train_loss: 0.0003328578\n",
      "[065/01699] val_loss: 0.0003723589\n",
      "[065/01799] train_loss: 0.0003757568\n",
      "[065/01799] val_loss: 0.0003689514\n",
      "[065/01899] train_loss: 0.0003816180\n",
      "[065/01899] val_loss: 0.0003824931\n",
      "[066/00079] train_loss: 0.0003659217\n",
      "[066/00079] val_loss: 0.0003810416\n",
      "[066/00179] train_loss: 0.0004036385\n",
      "[066/00179] val_loss: 0.0003922612\n",
      "[066/00279] train_loss: 0.0003490309\n",
      "[066/00279] val_loss: 0.0004471919\n",
      "[066/00379] train_loss: 0.0003346284\n",
      "[066/00379] val_loss: 0.0003785817\n",
      "[066/00479] train_loss: 0.0003416405\n",
      "[066/00479] val_loss: 0.0003907195\n",
      "[066/00579] train_loss: 0.0003503601\n",
      "[066/00579] val_loss: 0.0003700875\n",
      "[066/00679] train_loss: 0.0003486611\n",
      "[066/00679] val_loss: 0.0003778009\n",
      "[066/00779] train_loss: 0.0003436270\n",
      "[066/00779] val_loss: 0.0003979886\n",
      "[066/00879] train_loss: 0.0003689304\n",
      "[066/00879] val_loss: 0.0003830846\n",
      "[066/00979] train_loss: 0.0003564325\n",
      "[066/00979] val_loss: 0.0003806301\n",
      "[066/01079] train_loss: 0.0003812726\n",
      "[066/01079] val_loss: 0.0003830483\n",
      "[066/01179] train_loss: 0.0003190924\n",
      "[066/01179] val_loss: 0.0003900897\n",
      "[066/01279] train_loss: 0.0003559053\n",
      "[066/01279] val_loss: 0.0004011290\n",
      "[066/01379] train_loss: 0.0003726049\n",
      "[066/01379] val_loss: 0.0003895973\n",
      "[066/01479] train_loss: 0.0003461314\n",
      "[066/01479] val_loss: 0.0003880175\n",
      "[066/01579] train_loss: 0.0003701182\n",
      "[066/01579] val_loss: 0.0003901166\n",
      "[066/01679] train_loss: 0.0003227575\n",
      "[066/01679] val_loss: 0.0003944606\n",
      "[066/01779] train_loss: 0.0003400342\n",
      "[066/01779] val_loss: 0.0003714794\n",
      "[066/01879] train_loss: 0.0003384990\n",
      "[066/01879] val_loss: 0.0004001624\n",
      "[067/00059] train_loss: 0.0003623664\n",
      "[067/00059] val_loss: 0.0003854428\n",
      "[067/00159] train_loss: 0.0003449865\n",
      "[067/00159] val_loss: 0.0004019036\n",
      "[067/00259] train_loss: 0.0003294183\n",
      "[067/00259] val_loss: 0.0003823725\n",
      "[067/00359] train_loss: 0.0003536718\n",
      "[067/00359] val_loss: 0.0003946134\n",
      "[067/00459] train_loss: 0.0003437318\n",
      "[067/00459] val_loss: 0.0003828493\n",
      "[067/00559] train_loss: 0.0003380564\n",
      "[067/00559] val_loss: 0.0003745678\n",
      "[067/00659] train_loss: 0.0003438029\n",
      "[067/00659] val_loss: 0.0003832768\n",
      "[067/00759] train_loss: 0.0003269562\n",
      "[067/00759] val_loss: 0.0003795494\n",
      "[067/00859] train_loss: 0.0003294227\n",
      "[067/00859] val_loss: 0.0003919437\n",
      "[067/00959] train_loss: 0.0003497571\n",
      "[067/00959] val_loss: 0.0003878564\n",
      "[067/01059] train_loss: 0.0003421255\n",
      "[067/01059] val_loss: 0.0003808349\n",
      "[067/01159] train_loss: 0.0003488065\n",
      "[067/01159] val_loss: 0.0003996803\n",
      "[067/01259] train_loss: 0.0003807319\n",
      "[067/01259] val_loss: 0.0003733135\n",
      "[067/01359] train_loss: 0.0003339165\n",
      "[067/01359] val_loss: 0.0003669198\n",
      "[067/01459] train_loss: 0.0003484333\n",
      "[067/01459] val_loss: 0.0003830494\n",
      "[067/01559] train_loss: 0.0003475322\n",
      "[067/01559] val_loss: 0.0003838975\n",
      "[067/01659] train_loss: 0.0003709946\n",
      "[067/01659] val_loss: 0.0003841238\n",
      "[067/01759] train_loss: 0.0003428783\n",
      "[067/01759] val_loss: 0.0003764328\n",
      "[067/01859] train_loss: 0.0003535933\n",
      "[067/01859] val_loss: 0.0003836921\n",
      "[068/00039] train_loss: 0.0003488000\n",
      "[068/00039] val_loss: 0.0003970131\n",
      "[068/00139] train_loss: 0.0003691231\n",
      "[068/00139] val_loss: 0.0003893573\n",
      "[068/00239] train_loss: 0.0003194421\n",
      "[068/00239] val_loss: 0.0003835948\n",
      "[068/00339] train_loss: 0.0003413468\n",
      "[068/00339] val_loss: 0.0003829848\n",
      "[068/00439] train_loss: 0.0003788199\n",
      "[068/00439] val_loss: 0.0004446335\n",
      "[068/00539] train_loss: 0.0003729582\n",
      "[068/00539] val_loss: 0.0003905727\n",
      "[068/00639] train_loss: 0.0003648117\n",
      "[068/00639] val_loss: 0.0003863508\n",
      "[068/00739] train_loss: 0.0003623190\n",
      "[068/00739] val_loss: 0.0003762548\n",
      "[068/00839] train_loss: 0.0003566260\n",
      "[068/00839] val_loss: 0.0003907775\n",
      "[068/00939] train_loss: 0.0003268044\n",
      "[068/00939] val_loss: 0.0003938838\n",
      "[068/01039] train_loss: 0.0003477482\n",
      "[068/01039] val_loss: 0.0003967280\n",
      "[068/01139] train_loss: 0.0003354230\n",
      "[068/01139] val_loss: 0.0003702638\n",
      "[068/01239] train_loss: 0.0003320914\n",
      "[068/01239] val_loss: 0.0003813423\n",
      "[068/01339] train_loss: 0.0003480580\n",
      "[068/01339] val_loss: 0.0004062579\n",
      "[068/01439] train_loss: 0.0003363076\n",
      "[068/01439] val_loss: 0.0003872800\n",
      "[068/01539] train_loss: 0.0003352990\n",
      "[068/01539] val_loss: 0.0004095205\n",
      "[068/01639] train_loss: 0.0004010479\n",
      "[068/01639] val_loss: 0.0004038256\n",
      "[068/01739] train_loss: 0.0003665083\n",
      "[068/01739] val_loss: 0.0004594206\n",
      "[068/01839] train_loss: 0.0003536420\n",
      "[068/01839] val_loss: 0.0004307583\n",
      "[069/00019] train_loss: 0.0003593602\n",
      "[069/00019] val_loss: 0.0004215224\n",
      "[069/00119] train_loss: 0.0003857280\n",
      "[069/00119] val_loss: 0.0004373374\n",
      "[069/00219] train_loss: 0.0004052789\n",
      "[069/00219] val_loss: 0.0004010881\n",
      "[069/00319] train_loss: 0.0003713799\n",
      "[069/00319] val_loss: 0.0003984856\n",
      "[069/00419] train_loss: 0.0003382403\n",
      "[069/00419] val_loss: 0.0003960945\n",
      "[069/00519] train_loss: 0.0003137854\n",
      "[069/00519] val_loss: 0.0003820084\n",
      "[069/00619] train_loss: 0.0003537002\n",
      "[069/00619] val_loss: 0.0003912179\n",
      "[069/00719] train_loss: 0.0003475749\n",
      "[069/00719] val_loss: 0.0003774755\n",
      "[069/00819] train_loss: 0.0003502528\n",
      "[069/00819] val_loss: 0.0003688818\n",
      "[069/00919] train_loss: 0.0003244093\n",
      "[069/00919] val_loss: 0.0003694624\n",
      "[069/01019] train_loss: 0.0003567555\n",
      "[069/01019] val_loss: 0.0003740967\n",
      "[069/01119] train_loss: 0.0003270393\n",
      "[069/01119] val_loss: 0.0004176245\n",
      "[069/01219] train_loss: 0.0003565019\n",
      "[069/01219] val_loss: 0.0003969729\n",
      "[069/01319] train_loss: 0.0003633580\n",
      "[069/01319] val_loss: 0.0003809258\n",
      "[069/01419] train_loss: 0.0003468867\n",
      "[069/01419] val_loss: 0.0003882150\n",
      "[069/01519] train_loss: 0.0003150966\n",
      "[069/01519] val_loss: 0.0004118432\n",
      "[069/01619] train_loss: 0.0003413853\n",
      "[069/01619] val_loss: 0.0003781244\n",
      "[069/01719] train_loss: 0.0003238312\n",
      "[069/01719] val_loss: 0.0003747933\n",
      "[069/01819] train_loss: 0.0003556338\n",
      "[069/01819] val_loss: 0.0003805359\n",
      "[069/01919] train_loss: 0.0003325309\n",
      "[069/01919] val_loss: 0.0003972775\n",
      "[070/00099] train_loss: 0.0003249082\n",
      "[070/00099] val_loss: 0.0003777741\n",
      "[070/00199] train_loss: 0.0003080154\n",
      "[070/00199] val_loss: 0.0003793074\n",
      "[070/00299] train_loss: 0.0003214616\n",
      "[070/00299] val_loss: 0.0003864303\n",
      "[070/00399] train_loss: 0.0003401588\n",
      "[070/00399] val_loss: 0.0003854771\n",
      "[070/00499] train_loss: 0.0003470702\n",
      "[070/00499] val_loss: 0.0003808496\n",
      "[070/00599] train_loss: 0.0003443738\n",
      "[070/00599] val_loss: 0.0003797144\n",
      "[070/00699] train_loss: 0.0003395314\n",
      "[070/00699] val_loss: 0.0003774775\n",
      "[070/00799] train_loss: 0.0003302078\n",
      "[070/00799] val_loss: 0.0003700911\n",
      "[070/00899] train_loss: 0.0003165569\n",
      "[070/00899] val_loss: 0.0003782505\n",
      "[070/00999] train_loss: 0.0003257014\n",
      "[070/00999] val_loss: 0.0003802482\n",
      "[070/01099] train_loss: 0.0003483318\n",
      "[070/01099] val_loss: 0.0003853949\n",
      "[070/01199] train_loss: 0.0003265392\n",
      "[070/01199] val_loss: 0.0003779781\n",
      "[070/01299] train_loss: 0.0003746226\n",
      "[070/01299] val_loss: 0.0003895028\n",
      "[070/01399] train_loss: 0.0003233936\n",
      "[070/01399] val_loss: 0.0003764491\n",
      "[070/01499] train_loss: 0.0003886396\n",
      "[070/01499] val_loss: 0.0004059744\n",
      "[070/01599] train_loss: 0.0003819240\n",
      "[070/01599] val_loss: 0.0004119896\n",
      "[070/01699] train_loss: 0.0003879118\n",
      "[070/01699] val_loss: 0.0004134330\n",
      "[070/01799] train_loss: 0.0003564104\n",
      "[070/01799] val_loss: 0.0003992320\n",
      "[070/01899] train_loss: 0.0003381997\n",
      "[070/01899] val_loss: 0.0003890171\n",
      "[071/00079] train_loss: 0.0003174092\n",
      "[071/00079] val_loss: 0.0003777668\n",
      "[071/00179] train_loss: 0.0003417653\n",
      "[071/00179] val_loss: 0.0004077445\n",
      "[071/00279] train_loss: 0.0003434219\n",
      "[071/00279] val_loss: 0.0003751247\n",
      "[071/00379] train_loss: 0.0003530358\n",
      "[071/00379] val_loss: 0.0003817643\n",
      "[071/00479] train_loss: 0.0003155497\n",
      "[071/00479] val_loss: 0.0003758504\n",
      "[071/00579] train_loss: 0.0003210141\n",
      "[071/00579] val_loss: 0.0003857024\n",
      "[071/00679] train_loss: 0.0003267022\n",
      "[071/00679] val_loss: 0.0003758933\n",
      "[071/00779] train_loss: 0.0003277583\n",
      "[071/00779] val_loss: 0.0003850304\n",
      "[071/00879] train_loss: 0.0003554097\n",
      "[071/00879] val_loss: 0.0003868246\n",
      "[071/00979] train_loss: 0.0003327292\n",
      "[071/00979] val_loss: 0.0004073859\n",
      "[071/01079] train_loss: 0.0003443629\n",
      "[071/01079] val_loss: 0.0003840230\n",
      "[071/01179] train_loss: 0.0003670333\n",
      "[071/01179] val_loss: 0.0004000737\n",
      "[071/01279] train_loss: 0.0003244831\n",
      "[071/01279] val_loss: 0.0003751289\n",
      "[071/01379] train_loss: 0.0003442257\n",
      "[071/01379] val_loss: 0.0004046028\n",
      "[071/01479] train_loss: 0.0003580866\n",
      "[071/01479] val_loss: 0.0003822222\n",
      "[071/01579] train_loss: 0.0003421860\n",
      "[071/01579] val_loss: 0.0003987862\n",
      "[071/01679] train_loss: 0.0003449399\n",
      "[071/01679] val_loss: 0.0003747065\n",
      "[071/01779] train_loss: 0.0003232812\n",
      "[071/01779] val_loss: 0.0003902808\n",
      "[071/01879] train_loss: 0.0004114534\n",
      "[071/01879] val_loss: 0.0004172311\n",
      "[072/00059] train_loss: 0.0003784375\n",
      "[072/00059] val_loss: 0.0004048735\n",
      "[072/00159] train_loss: 0.0003330049\n",
      "[072/00159] val_loss: 0.0003825385\n",
      "[072/00259] train_loss: 0.0003254768\n",
      "[072/00259] val_loss: 0.0003839082\n",
      "[072/00359] train_loss: 0.0003153109\n",
      "[072/00359] val_loss: 0.0003699361\n",
      "[072/00459] train_loss: 0.0003663404\n",
      "[072/00459] val_loss: 0.0004617355\n",
      "[072/00559] train_loss: 0.0003641910\n",
      "[072/00559] val_loss: 0.0003874610\n",
      "[072/00659] train_loss: 0.0003369680\n",
      "[072/00659] val_loss: 0.0003856729\n",
      "[072/00759] train_loss: 0.0003237794\n",
      "[072/00759] val_loss: 0.0004058807\n",
      "[072/00859] train_loss: 0.0003214933\n",
      "[072/00859] val_loss: 0.0003880663\n",
      "[072/00959] train_loss: 0.0003804396\n",
      "[072/00959] val_loss: 0.0003825563\n",
      "[072/01059] train_loss: 0.0003120626\n",
      "[072/01059] val_loss: 0.0003773801\n",
      "[072/01159] train_loss: 0.0003196342\n",
      "[072/01159] val_loss: 0.0003879390\n",
      "[072/01259] train_loss: 0.0003362430\n",
      "[072/01259] val_loss: 0.0003805503\n",
      "[072/01359] train_loss: 0.0003314120\n",
      "[072/01359] val_loss: 0.0003610282\n",
      "[072/01459] train_loss: 0.0003516922\n",
      "[072/01459] val_loss: 0.0003734731\n",
      "[072/01559] train_loss: 0.0002918042\n",
      "[072/01559] val_loss: 0.0003899001\n",
      "[072/01659] train_loss: 0.0003385142\n",
      "[072/01659] val_loss: 0.0003707363\n",
      "[072/01759] train_loss: 0.0003649404\n",
      "[072/01759] val_loss: 0.0004920785\n",
      "[072/01859] train_loss: 0.0003165667\n",
      "[072/01859] val_loss: 0.0003727050\n",
      "[073/00039] train_loss: 0.0003346638\n",
      "[073/00039] val_loss: 0.0003828116\n",
      "[073/00139] train_loss: 0.0003286765\n",
      "[073/00139] val_loss: 0.0003957307\n",
      "[073/00239] train_loss: 0.0003480944\n",
      "[073/00239] val_loss: 0.0003999883\n",
      "[073/00339] train_loss: 0.0003166241\n",
      "[073/00339] val_loss: 0.0003975465\n",
      "[073/00439] train_loss: 0.0003475386\n",
      "[073/00439] val_loss: 0.0003822633\n",
      "[073/00539] train_loss: 0.0003218294\n",
      "[073/00539] val_loss: 0.0003743840\n",
      "[073/00639] train_loss: 0.0003347089\n",
      "[073/00639] val_loss: 0.0003815955\n",
      "[073/00739] train_loss: 0.0003158696\n",
      "[073/00739] val_loss: 0.0003908882\n",
      "[073/00839] train_loss: 0.0003448505\n",
      "[073/00839] val_loss: 0.0003771832\n",
      "[073/00939] train_loss: 0.0003561681\n",
      "[073/00939] val_loss: 0.0003855755\n",
      "[073/01039] train_loss: 0.0003365954\n",
      "[073/01039] val_loss: 0.0003937822\n",
      "[073/01139] train_loss: 0.0003272593\n",
      "[073/01139] val_loss: 0.0003972846\n",
      "[073/01239] train_loss: 0.0003313679\n",
      "[073/01239] val_loss: 0.0003987830\n",
      "[073/01339] train_loss: 0.0003400298\n",
      "[073/01339] val_loss: 0.0003811051\n",
      "[073/01439] train_loss: 0.0003211528\n",
      "[073/01439] val_loss: 0.0003715130\n",
      "[073/01539] train_loss: 0.0003341943\n",
      "[073/01539] val_loss: 0.0003762364\n",
      "[073/01639] train_loss: 0.0003467833\n",
      "[073/01639] val_loss: 0.0003667693\n",
      "[073/01739] train_loss: 0.0003602815\n",
      "[073/01739] val_loss: 0.0003841677\n",
      "[073/01839] train_loss: 0.0003365897\n",
      "[073/01839] val_loss: 0.0003777542\n",
      "[074/00019] train_loss: 0.0003231531\n",
      "[074/00019] val_loss: 0.0003700650\n",
      "[074/00119] train_loss: 0.0003177590\n",
      "[074/00119] val_loss: 0.0003907202\n",
      "[074/00219] train_loss: 0.0003404623\n",
      "[074/00219] val_loss: 0.0003782102\n",
      "[074/00319] train_loss: 0.0003574514\n",
      "[074/00319] val_loss: 0.0003916488\n",
      "[074/00419] train_loss: 0.0003370862\n",
      "[074/00419] val_loss: 0.0003702726\n",
      "[074/00519] train_loss: 0.0003133889\n",
      "[074/00519] val_loss: 0.0003834722\n",
      "[074/00619] train_loss: 0.0003143168\n",
      "[074/00619] val_loss: 0.0004123572\n",
      "[074/00719] train_loss: 0.0003242662\n",
      "[074/00719] val_loss: 0.0003875367\n",
      "[074/00819] train_loss: 0.0003217516\n",
      "[074/00819] val_loss: 0.0003826970\n",
      "[074/00919] train_loss: 0.0003463080\n",
      "[074/00919] val_loss: 0.0003785167\n",
      "[074/01019] train_loss: 0.0003318624\n",
      "[074/01019] val_loss: 0.0003820185\n",
      "[074/01119] train_loss: 0.0003264023\n",
      "[074/01119] val_loss: 0.0003756626\n",
      "[074/01219] train_loss: 0.0003228895\n",
      "[074/01219] val_loss: 0.0003683041\n",
      "[074/01319] train_loss: 0.0003231818\n",
      "[074/01319] val_loss: 0.0003827410\n",
      "[074/01419] train_loss: 0.0003236900\n",
      "[074/01419] val_loss: 0.0003866880\n",
      "[074/01519] train_loss: 0.0003308881\n",
      "[074/01519] val_loss: 0.0003724979\n",
      "[074/01619] train_loss: 0.0003249612\n",
      "[074/01619] val_loss: 0.0004182799\n",
      "[074/01719] train_loss: 0.0004044638\n",
      "[074/01719] val_loss: 0.0003781678\n",
      "[074/01819] train_loss: 0.0003396853\n",
      "[074/01819] val_loss: 0.0003745958\n",
      "[074/01919] train_loss: 0.0003359074\n",
      "[074/01919] val_loss: 0.0003879262\n",
      "[075/00099] train_loss: 0.0003239771\n",
      "[075/00099] val_loss: 0.0004114632\n",
      "[075/00199] train_loss: 0.0003171660\n",
      "[075/00199] val_loss: 0.0003755799\n",
      "[075/00299] train_loss: 0.0002919534\n",
      "[075/00299] val_loss: 0.0003821019\n",
      "[075/00399] train_loss: 0.0003189638\n",
      "[075/00399] val_loss: 0.0003700525\n",
      "[075/00499] train_loss: 0.0003049001\n",
      "[075/00499] val_loss: 0.0003657045\n",
      "[075/00599] train_loss: 0.0003375305\n",
      "[075/00599] val_loss: 0.0004009786\n",
      "[075/00699] train_loss: 0.0003324284\n",
      "[075/00699] val_loss: 0.0003859882\n",
      "[075/00799] train_loss: 0.0003340859\n",
      "[075/00799] val_loss: 0.0003742933\n",
      "[075/00899] train_loss: 0.0003320021\n",
      "[075/00899] val_loss: 0.0004151491\n",
      "[075/00999] train_loss: 0.0003661387\n",
      "[075/00999] val_loss: 0.0003975689\n",
      "[075/01099] train_loss: 0.0003219803\n",
      "[075/01099] val_loss: 0.0003817123\n",
      "[075/01199] train_loss: 0.0003168074\n",
      "[075/01199] val_loss: 0.0003898296\n",
      "[075/01299] train_loss: 0.0003458195\n",
      "[075/01299] val_loss: 0.0003917288\n",
      "[075/01399] train_loss: 0.0002973924\n",
      "[075/01399] val_loss: 0.0003798423\n",
      "[075/01499] train_loss: 0.0003449645\n",
      "[075/01499] val_loss: 0.0004181190\n",
      "[075/01599] train_loss: 0.0003465488\n",
      "[075/01599] val_loss: 0.0003864026\n",
      "[075/01699] train_loss: 0.0003560055\n",
      "[075/01699] val_loss: 0.0004221857\n",
      "[075/01799] train_loss: 0.0003418586\n",
      "[075/01799] val_loss: 0.0004003659\n",
      "[075/01899] train_loss: 0.0003698211\n",
      "[075/01899] val_loss: 0.0003814609\n",
      "[076/00079] train_loss: 0.0003524873\n",
      "[076/00079] val_loss: 0.0004224862\n",
      "[076/00179] train_loss: 0.0003960586\n",
      "[076/00179] val_loss: 0.0003986218\n",
      "[076/00279] train_loss: 0.0003367316\n",
      "[076/00279] val_loss: 0.0003823112\n",
      "[076/00379] train_loss: 0.0003537110\n",
      "[076/00379] val_loss: 0.0003894365\n",
      "[076/00479] train_loss: 0.0003500658\n",
      "[076/00479] val_loss: 0.0003763636\n",
      "[076/00579] train_loss: 0.0003072315\n",
      "[076/00579] val_loss: 0.0003822607\n",
      "[076/00679] train_loss: 0.0002983441\n",
      "[076/00679] val_loss: 0.0003874389\n",
      "[076/00779] train_loss: 0.0003264650\n",
      "[076/00779] val_loss: 0.0003829395\n",
      "[076/00879] train_loss: 0.0003352199\n",
      "[076/00879] val_loss: 0.0003710333\n",
      "[076/00979] train_loss: 0.0002849841\n",
      "[076/00979] val_loss: 0.0003872639\n",
      "[076/01079] train_loss: 0.0003208830\n",
      "[076/01079] val_loss: 0.0004021076\n",
      "[076/01179] train_loss: 0.0003401902\n",
      "[076/01179] val_loss: 0.0003755618\n",
      "[076/01279] train_loss: 0.0003181949\n",
      "[076/01279] val_loss: 0.0003763380\n",
      "[076/01379] train_loss: 0.0003136827\n",
      "[076/01379] val_loss: 0.0003683080\n",
      "[076/01479] train_loss: 0.0003044079\n",
      "[076/01479] val_loss: 0.0003690844\n",
      "[076/01579] train_loss: 0.0003653628\n",
      "[076/01579] val_loss: 0.0003743359\n",
      "[076/01679] train_loss: 0.0003192211\n",
      "[076/01679] val_loss: 0.0003834532\n",
      "[076/01779] train_loss: 0.0003258714\n",
      "[076/01779] val_loss: 0.0003767856\n",
      "[076/01879] train_loss: 0.0003374645\n",
      "[076/01879] val_loss: 0.0003839806\n",
      "[077/00059] train_loss: 0.0003460607\n",
      "[077/00059] val_loss: 0.0003800001\n",
      "[077/00159] train_loss: 0.0003313121\n",
      "[077/00159] val_loss: 0.0003721974\n",
      "[077/00259] train_loss: 0.0003203265\n",
      "[077/00259] val_loss: 0.0003906158\n",
      "[077/00359] train_loss: 0.0003416548\n",
      "[077/00359] val_loss: 0.0003674471\n",
      "[077/00459] train_loss: 0.0003126576\n",
      "[077/00459] val_loss: 0.0003882095\n",
      "[077/00559] train_loss: 0.0003197467\n",
      "[077/00559] val_loss: 0.0004120594\n",
      "[077/00659] train_loss: 0.0003118555\n",
      "[077/00659] val_loss: 0.0003970575\n",
      "[077/00759] train_loss: 0.0003544869\n",
      "[077/00759] val_loss: 0.0003923702\n",
      "[077/00859] train_loss: 0.0002999866\n",
      "[077/00859] val_loss: 0.0003864504\n",
      "[077/00959] train_loss: 0.0003048382\n",
      "[077/00959] val_loss: 0.0004011836\n",
      "[077/01059] train_loss: 0.0003194036\n",
      "[077/01059] val_loss: 0.0003875797\n",
      "[077/01159] train_loss: 0.0003151343\n",
      "[077/01159] val_loss: 0.0003762094\n",
      "[077/01259] train_loss: 0.0003716897\n",
      "[077/01259] val_loss: 0.0003982756\n",
      "[077/01359] train_loss: 0.0003583183\n",
      "[077/01359] val_loss: 0.0003763664\n",
      "[077/01459] train_loss: 0.0003318929\n",
      "[077/01459] val_loss: 0.0003767865\n",
      "[077/01559] train_loss: 0.0003187754\n",
      "[077/01559] val_loss: 0.0003863737\n",
      "[077/01659] train_loss: 0.0003092016\n",
      "[077/01659] val_loss: 0.0003757450\n",
      "[077/01759] train_loss: 0.0003460021\n",
      "[077/01759] val_loss: 0.0003979322\n",
      "[077/01859] train_loss: 0.0003308582\n",
      "[077/01859] val_loss: 0.0003735060\n",
      "[078/00039] train_loss: 0.0003255603\n",
      "[078/00039] val_loss: 0.0003753779\n",
      "[078/00139] train_loss: 0.0003047117\n",
      "[078/00139] val_loss: 0.0003698506\n",
      "[078/00239] train_loss: 0.0002882834\n",
      "[078/00239] val_loss: 0.0003721685\n",
      "[078/00339] train_loss: 0.0003125850\n",
      "[078/00339] val_loss: 0.0003767625\n",
      "[078/00439] train_loss: 0.0003548461\n",
      "[078/00439] val_loss: 0.0003862760\n",
      "[078/00539] train_loss: 0.0003145988\n",
      "[078/00539] val_loss: 0.0003716687\n",
      "[078/00639] train_loss: 0.0003203848\n",
      "[078/00639] val_loss: 0.0003784936\n",
      "[078/00739] train_loss: 0.0003008577\n",
      "[078/00739] val_loss: 0.0003676627\n",
      "[078/00839] train_loss: 0.0002904926\n",
      "[078/00839] val_loss: 0.0003875449\n",
      "[078/00939] train_loss: 0.0003196690\n",
      "[078/00939] val_loss: 0.0003799018\n",
      "[078/01039] train_loss: 0.0003363697\n",
      "[078/01039] val_loss: 0.0003761520\n",
      "[078/01139] train_loss: 0.0003235385\n",
      "[078/01139] val_loss: 0.0003833117\n",
      "[078/01239] train_loss: 0.0003247147\n",
      "[078/01239] val_loss: 0.0003727160\n",
      "[078/01339] train_loss: 0.0003435371\n",
      "[078/01339] val_loss: 0.0003851825\n",
      "[078/01439] train_loss: 0.0002947291\n",
      "[078/01439] val_loss: 0.0003748804\n",
      "[078/01539] train_loss: 0.0004078700\n",
      "[078/01539] val_loss: 0.0003971207\n",
      "[078/01639] train_loss: 0.0003649206\n",
      "[078/01639] val_loss: 0.0004014891\n",
      "[078/01739] train_loss: 0.0002999568\n",
      "[078/01739] val_loss: 0.0003857445\n",
      "[078/01839] train_loss: 0.0003419499\n",
      "[078/01839] val_loss: 0.0003681614\n",
      "[079/00019] train_loss: 0.0003122272\n",
      "[079/00019] val_loss: 0.0003844422\n",
      "[079/00119] train_loss: 0.0003034489\n",
      "[079/00119] val_loss: 0.0003763921\n",
      "[079/00219] train_loss: 0.0003320153\n",
      "[079/00219] val_loss: 0.0003738449\n",
      "[079/00319] train_loss: 0.0003067406\n",
      "[079/00319] val_loss: 0.0004105927\n",
      "[079/00419] train_loss: 0.0003614347\n",
      "[079/00419] val_loss: 0.0003932731\n",
      "[079/00519] train_loss: 0.0003220490\n",
      "[079/00519] val_loss: 0.0003848588\n",
      "[079/00619] train_loss: 0.0002992811\n",
      "[079/00619] val_loss: 0.0003993441\n",
      "[079/00719] train_loss: 0.0003439872\n",
      "[079/00719] val_loss: 0.0003784935\n",
      "[079/00819] train_loss: 0.0003034920\n",
      "[079/00819] val_loss: 0.0003964714\n",
      "[079/00919] train_loss: 0.0003092597\n",
      "[079/00919] val_loss: 0.0003703137\n",
      "[079/01019] train_loss: 0.0003122072\n",
      "[079/01019] val_loss: 0.0003684969\n",
      "[079/01119] train_loss: 0.0003285123\n",
      "[079/01119] val_loss: 0.0003921286\n",
      "[079/01219] train_loss: 0.0003481917\n",
      "[079/01219] val_loss: 0.0003752113\n",
      "[079/01319] train_loss: 0.0003613510\n",
      "[079/01319] val_loss: 0.0003847660\n",
      "[079/01419] train_loss: 0.0003343606\n",
      "[079/01419] val_loss: 0.0003800878\n",
      "[079/01519] train_loss: 0.0003195860\n",
      "[079/01519] val_loss: 0.0003809993\n",
      "[079/01619] train_loss: 0.0003405579\n",
      "[079/01619] val_loss: 0.0003890402\n",
      "[079/01719] train_loss: 0.0003342003\n",
      "[079/01719] val_loss: 0.0003904479\n",
      "[079/01819] train_loss: 0.0002941603\n",
      "[079/01819] val_loss: 0.0003863459\n",
      "[079/01919] train_loss: 0.0003243236\n",
      "[079/01919] val_loss: 0.0003947108\n",
      "[080/00099] train_loss: 0.0003355514\n",
      "[080/00099] val_loss: 0.0003940894\n",
      "[080/00199] train_loss: 0.0002877668\n",
      "[080/00199] val_loss: 0.0003705405\n",
      "[080/00299] train_loss: 0.0003254879\n",
      "[080/00299] val_loss: 0.0004018147\n",
      "[080/00399] train_loss: 0.0003255230\n",
      "[080/00399] val_loss: 0.0003707721\n",
      "[080/00499] train_loss: 0.0003058042\n",
      "[080/00499] val_loss: 0.0003648865\n",
      "[080/00599] train_loss: 0.0002753357\n",
      "[080/00599] val_loss: 0.0003730450\n",
      "[080/00699] train_loss: 0.0003067825\n",
      "[080/00699] val_loss: 0.0003664192\n",
      "[080/00799] train_loss: 0.0002989779\n",
      "[080/00799] val_loss: 0.0003775601\n",
      "[080/00899] train_loss: 0.0003272771\n",
      "[080/00899] val_loss: 0.0003960894\n",
      "[080/00999] train_loss: 0.0003646554\n",
      "[080/00999] val_loss: 0.0003935117\n",
      "[080/01099] train_loss: 0.0003330740\n",
      "[080/01099] val_loss: 0.0005129807\n",
      "[080/01199] train_loss: 0.0003759318\n",
      "[080/01199] val_loss: 0.0003859597\n",
      "[080/01299] train_loss: 0.0003282849\n",
      "[080/01299] val_loss: 0.0003846489\n",
      "[080/01399] train_loss: 0.0003242946\n",
      "[080/01399] val_loss: 0.0003936912\n",
      "[080/01499] train_loss: 0.0003221099\n",
      "[080/01499] val_loss: 0.0003679533\n",
      "[080/01599] train_loss: 0.0003116205\n",
      "[080/01599] val_loss: 0.0003617342\n",
      "[080/01699] train_loss: 0.0003289448\n",
      "[080/01699] val_loss: 0.0003688994\n",
      "[080/01799] train_loss: 0.0003297596\n",
      "[080/01799] val_loss: 0.0003692649\n",
      "[080/01899] train_loss: 0.0003180650\n",
      "[080/01899] val_loss: 0.0003627984\n",
      "[081/00079] train_loss: 0.0003259759\n",
      "[081/00079] val_loss: 0.0003683788\n",
      "[081/00179] train_loss: 0.0003086342\n",
      "[081/00179] val_loss: 0.0003601919\n",
      "[081/00279] train_loss: 0.0003289037\n",
      "[081/00279] val_loss: 0.0003567208\n",
      "[081/00379] train_loss: 0.0003181090\n",
      "[081/00379] val_loss: 0.0003796316\n",
      "[081/00479] train_loss: 0.0003025690\n",
      "[081/00479] val_loss: 0.0003872494\n",
      "[081/00579] train_loss: 0.0003554115\n",
      "[081/00579] val_loss: 0.0003763550\n",
      "[081/00679] train_loss: 0.0003252127\n",
      "[081/00679] val_loss: 0.0003684696\n",
      "[081/00779] train_loss: 0.0003283021\n",
      "[081/00779] val_loss: 0.0003923241\n",
      "[081/00879] train_loss: 0.0003175345\n",
      "[081/00879] val_loss: 0.0003874539\n",
      "[081/00979] train_loss: 0.0003338667\n",
      "[081/00979] val_loss: 0.0003651495\n",
      "[081/01079] train_loss: 0.0003222556\n",
      "[081/01079] val_loss: 0.0003692477\n",
      "[081/01179] train_loss: 0.0003016882\n",
      "[081/01179] val_loss: 0.0003657538\n",
      "[081/01279] train_loss: 0.0002902663\n",
      "[081/01279] val_loss: 0.0003628898\n",
      "[081/01379] train_loss: 0.0003121742\n",
      "[081/01379] val_loss: 0.0003817457\n",
      "[081/01479] train_loss: 0.0003242347\n",
      "[081/01479] val_loss: 0.0003964322\n",
      "[081/01579] train_loss: 0.0003178289\n",
      "[081/01579] val_loss: 0.0004044609\n",
      "[081/01679] train_loss: 0.0003336993\n",
      "[081/01679] val_loss: 0.0003756658\n",
      "[081/01779] train_loss: 0.0003160320\n",
      "[081/01779] val_loss: 0.0003954569\n",
      "[081/01879] train_loss: 0.0003201465\n",
      "[081/01879] val_loss: 0.0003780319\n",
      "[082/00059] train_loss: 0.0003071338\n",
      "[082/00059] val_loss: 0.0003763996\n",
      "[082/00159] train_loss: 0.0002959996\n",
      "[082/00159] val_loss: 0.0003880922\n",
      "[082/00259] train_loss: 0.0002971700\n",
      "[082/00259] val_loss: 0.0003752045\n",
      "[082/00359] train_loss: 0.0003435514\n",
      "[082/00359] val_loss: 0.0003893480\n",
      "[082/00459] train_loss: 0.0002900731\n",
      "[082/00459] val_loss: 0.0003779655\n",
      "[082/00559] train_loss: 0.0003755079\n",
      "[082/00559] val_loss: 0.0003793941\n",
      "[082/00659] train_loss: 0.0003312944\n",
      "[082/00659] val_loss: 0.0003693280\n",
      "[082/00759] train_loss: 0.0002887566\n",
      "[082/00759] val_loss: 0.0003708070\n",
      "[082/00859] train_loss: 0.0003300623\n",
      "[082/00859] val_loss: 0.0003995804\n",
      "[082/00959] train_loss: 0.0003460504\n",
      "[082/00959] val_loss: 0.0003930059\n",
      "[082/01059] train_loss: 0.0003083918\n",
      "[082/01059] val_loss: 0.0003713105\n",
      "[082/01159] train_loss: 0.0002809113\n",
      "[082/01159] val_loss: 0.0003763199\n",
      "[082/01259] train_loss: 0.0003131212\n",
      "[082/01259] val_loss: 0.0003668272\n",
      "[082/01359] train_loss: 0.0002975231\n",
      "[082/01359] val_loss: 0.0003785146\n",
      "[082/01459] train_loss: 0.0003220710\n",
      "[082/01459] val_loss: 0.0003813573\n",
      "[082/01559] train_loss: 0.0003085303\n",
      "[082/01559] val_loss: 0.0003830536\n",
      "[082/01659] train_loss: 0.0003200072\n",
      "[082/01659] val_loss: 0.0003736103\n",
      "[082/01759] train_loss: 0.0003140747\n",
      "[082/01759] val_loss: 0.0003614055\n",
      "[082/01859] train_loss: 0.0003266165\n",
      "[082/01859] val_loss: 0.0003791676\n",
      "[083/00039] train_loss: 0.0003082470\n",
      "[083/00039] val_loss: 0.0003870988\n",
      "[083/00139] train_loss: 0.0002981217\n",
      "[083/00139] val_loss: 0.0003751111\n",
      "[083/00239] train_loss: 0.0003155439\n",
      "[083/00239] val_loss: 0.0003943667\n",
      "[083/00339] train_loss: 0.0003380932\n",
      "[083/00339] val_loss: 0.0003850448\n",
      "[083/00439] train_loss: 0.0003060424\n",
      "[083/00439] val_loss: 0.0003681334\n",
      "[083/00539] train_loss: 0.0002940306\n",
      "[083/00539] val_loss: 0.0003880246\n",
      "[083/00639] train_loss: 0.0002848460\n",
      "[083/00639] val_loss: 0.0003813691\n",
      "[083/00739] train_loss: 0.0002924519\n",
      "[083/00739] val_loss: 0.0003859771\n",
      "[083/00839] train_loss: 0.0003081616\n",
      "[083/00839] val_loss: 0.0003723927\n",
      "[083/00939] train_loss: 0.0003155167\n",
      "[083/00939] val_loss: 0.0003711263\n",
      "[083/01039] train_loss: 0.0003389591\n",
      "[083/01039] val_loss: 0.0003874203\n",
      "[083/01139] train_loss: 0.0003320730\n",
      "[083/01139] val_loss: 0.0003916277\n",
      "[083/01239] train_loss: 0.0003438134\n",
      "[083/01239] val_loss: 0.0003905356\n",
      "[083/01339] train_loss: 0.0003427632\n",
      "[083/01339] val_loss: 0.0003669534\n",
      "[083/01439] train_loss: 0.0003505944\n",
      "[083/01439] val_loss: 0.0003952391\n",
      "[083/01539] train_loss: 0.0003233252\n",
      "[083/01539] val_loss: 0.0003898628\n",
      "[083/01639] train_loss: 0.0003125881\n",
      "[083/01639] val_loss: 0.0003948582\n",
      "[083/01739] train_loss: 0.0003289636\n",
      "[083/01739] val_loss: 0.0003654092\n",
      "[083/01839] train_loss: 0.0002931996\n",
      "[083/01839] val_loss: 0.0003716336\n",
      "[084/00019] train_loss: 0.0003064548\n",
      "[084/00019] val_loss: 0.0003684734\n",
      "[084/00119] train_loss: 0.0003188335\n",
      "[084/00119] val_loss: 0.0003699987\n",
      "[084/00219] train_loss: 0.0002943552\n",
      "[084/00219] val_loss: 0.0003686421\n",
      "[084/00319] train_loss: 0.0002989980\n",
      "[084/00319] val_loss: 0.0003722041\n",
      "[084/00419] train_loss: 0.0003185225\n",
      "[084/00419] val_loss: 0.0003905352\n",
      "[084/00519] train_loss: 0.0003090411\n",
      "[084/00519] val_loss: 0.0003711710\n",
      "[084/00619] train_loss: 0.0003152046\n",
      "[084/00619] val_loss: 0.0003637993\n",
      "[084/00719] train_loss: 0.0003195472\n",
      "[084/00719] val_loss: 0.0003747975\n",
      "[084/00819] train_loss: 0.0002882741\n",
      "[084/00819] val_loss: 0.0003720059\n",
      "[084/00919] train_loss: 0.0003272449\n",
      "[084/00919] val_loss: 0.0003711831\n",
      "[084/01019] train_loss: 0.0003400962\n",
      "[084/01019] val_loss: 0.0003873680\n",
      "[084/01119] train_loss: 0.0003197092\n",
      "[084/01119] val_loss: 0.0003887176\n",
      "[084/01219] train_loss: 0.0003706100\n",
      "[084/01219] val_loss: 0.0003990672\n",
      "[084/01319] train_loss: 0.0003452113\n",
      "[084/01319] val_loss: 0.0004134233\n",
      "[084/01419] train_loss: 0.0003368604\n",
      "[084/01419] val_loss: 0.0003661859\n",
      "[084/01519] train_loss: 0.0003251370\n",
      "[084/01519] val_loss: 0.0003819366\n",
      "[084/01619] train_loss: 0.0003167159\n",
      "[084/01619] val_loss: 0.0003621544\n",
      "[084/01719] train_loss: 0.0002954265\n",
      "[084/01719] val_loss: 0.0003606041\n",
      "[084/01819] train_loss: 0.0003065092\n",
      "[084/01819] val_loss: 0.0003659196\n",
      "[084/01919] train_loss: 0.0003106269\n",
      "[084/01919] val_loss: 0.0003609138\n",
      "[085/00099] train_loss: 0.0002926288\n",
      "[085/00099] val_loss: 0.0003618176\n",
      "[085/00199] train_loss: 0.0002844960\n",
      "[085/00199] val_loss: 0.0003630186\n",
      "[085/00299] train_loss: 0.0003050308\n",
      "[085/00299] val_loss: 0.0004030305\n",
      "[085/00399] train_loss: 0.0003249393\n",
      "[085/00399] val_loss: 0.0003662153\n",
      "[085/00499] train_loss: 0.0003116788\n",
      "[085/00499] val_loss: 0.0003621423\n",
      "[085/00599] train_loss: 0.0003056796\n",
      "[085/00599] val_loss: 0.0003665096\n",
      "[085/00699] train_loss: 0.0002924116\n",
      "[085/00699] val_loss: 0.0003583342\n",
      "[085/00799] train_loss: 0.0002932386\n",
      "[085/00799] val_loss: 0.0003740252\n",
      "[085/00899] train_loss: 0.0003116437\n",
      "[085/00899] val_loss: 0.0003733694\n",
      "[085/00999] train_loss: 0.0002991550\n",
      "[085/00999] val_loss: 0.0003601527\n",
      "[085/01099] train_loss: 0.0003104313\n",
      "[085/01099] val_loss: 0.0003876413\n",
      "[085/01199] train_loss: 0.0003091414\n",
      "[085/01199] val_loss: 0.0003700620\n",
      "[085/01299] train_loss: 0.0003202675\n",
      "[085/01299] val_loss: 0.0003780884\n",
      "[085/01399] train_loss: 0.0003026409\n",
      "[085/01399] val_loss: 0.0003667071\n",
      "[085/01499] train_loss: 0.0003100299\n",
      "[085/01499] val_loss: 0.0003597975\n",
      "[085/01599] train_loss: 0.0002940494\n",
      "[085/01599] val_loss: 0.0003701053\n",
      "[085/01699] train_loss: 0.0003150756\n",
      "[085/01699] val_loss: 0.0003709014\n",
      "[085/01799] train_loss: 0.0003189327\n",
      "[085/01799] val_loss: 0.0004066676\n",
      "[085/01899] train_loss: 0.0003149946\n",
      "[085/01899] val_loss: 0.0004026478\n",
      "[086/00079] train_loss: 0.0003064196\n",
      "[086/00079] val_loss: 0.0003672535\n",
      "[086/00179] train_loss: 0.0002762334\n",
      "[086/00179] val_loss: 0.0003647364\n",
      "[086/00279] train_loss: 0.0003109218\n",
      "[086/00279] val_loss: 0.0004229708\n",
      "[086/00379] train_loss: 0.0003234739\n",
      "[086/00379] val_loss: 0.0003831002\n",
      "[086/00479] train_loss: 0.0003239008\n",
      "[086/00479] val_loss: 0.0003848056\n",
      "[086/00579] train_loss: 0.0003368818\n",
      "[086/00579] val_loss: 0.0003821484\n",
      "[086/00679] train_loss: 0.0003381528\n",
      "[086/00679] val_loss: 0.0003798111\n",
      "[086/00779] train_loss: 0.0003156693\n",
      "[086/00779] val_loss: 0.0003766817\n",
      "[086/00879] train_loss: 0.0003058721\n",
      "[086/00879] val_loss: 0.0003747554\n",
      "[086/00979] train_loss: 0.0003038861\n",
      "[086/00979] val_loss: 0.0003685695\n",
      "[086/01079] train_loss: 0.0002897098\n",
      "[086/01079] val_loss: 0.0003620533\n",
      "[086/01179] train_loss: 0.0003109085\n",
      "[086/01179] val_loss: 0.0003643702\n",
      "[086/01279] train_loss: 0.0003190050\n",
      "[086/01279] val_loss: 0.0003628616\n",
      "[086/01379] train_loss: 0.0003025654\n",
      "[086/01379] val_loss: 0.0003741719\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-76c4e017ca93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m'validate_every_n'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m }\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain_mesh2mesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Hanfeng/TUM/ML3D/ML3Dfinal_2021WS/Networks/train_mesh2mesh.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Hanfeng/TUM/ML3D/ML3Dfinal_2021WS/Networks/train_mesh2mesh.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, trainloader, valloader, device, config)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# TODO: forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m#print(batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mlatent_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mrecon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Hanfeng/TUM/ML3D/ML3Dfinal_2021WS/Networks/mesh2mesh.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# TODO: Layers 2 and 3: 64->128, 128->1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# This is the symmetric max operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    292\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 294\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    295\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'experiment_name': 'pcd_stage1',\n",
    "    'device': 'cuda:0',                   # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': False,                   # True since we're doing overfitting\n",
    "    'batch_size': 1,\n",
    "    'resume_ckpt_en': '/home/wuha/Hanfeng/TUM/ML3D/ML3Dfinal_2021WS/models/runs/pcd_stage1/encoder_best.pth',\n",
    "    'resume_ckpt_de': '/home/wuha/Hanfeng/TUM/ML3D/ML3Dfinal_2021WS/models/runs/pcd_stage1/decoder_best.pth',\n",
    "    #'resume_ckpt_en': None,\n",
    "    #'resume_ckpt_de': None,\n",
    "    'learning_rate': 0.0001,\n",
    "    'max_epochs': 1000,\n",
    "    'print_every_n': 100,\n",
    "    'validate_every_n': 100,\n",
    "}\n",
    "train_mesh2mesh.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FoldingNetDec:\n\tMissing key(s) in state_dict: \"conv.weight\", \"conv.bias\", \"fold1.conv1.weight\", \"fold1.conv1.bias\", \"fold1.conv2.weight\", \"fold1.conv2.bias\", \"fold1.conv3.weight\", \"fold1.conv3.bias\", \"fold2.conv1.weight\", \"fold2.conv1.bias\", \"fold2.conv2.weight\", \"fold2.conv2.bias\", \"fold2.conv3.weight\", \"fold2.conv3.bias\". \n\tUnexpected key(s) in state_dict: \"fc.0.weight\", \"fc.0.bias\", \"fc.2.weight\", \"fc.2.bias\", \"fc.4.weight\", \"fc.4.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fb6685c34928>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFoldingNetDec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./models/runs/{config[\"experiment_name\"]}/decoder_best.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpcd_stage1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FoldingNetDec:\n\tMissing key(s) in state_dict: \"conv.weight\", \"conv.bias\", \"fold1.conv1.weight\", \"fold1.conv1.bias\", \"fold1.conv2.weight\", \"fold1.conv2.bias\", \"fold1.conv3.weight\", \"fold1.conv3.bias\", \"fold2.conv1.weight\", \"fold2.conv1.bias\", \"fold2.conv2.weight\", \"fold2.conv2.bias\", \"fold2.conv3.weight\", \"fold2.conv3.bias\". \n\tUnexpected key(s) in state_dict: \"fc.0.weight\", \"fc.0.bias\", \"fc.2.weight\", \"fc.2.bias\", \"fc.4.weight\", \"fc.4.bias\". "
     ]
    }
   ],
   "source": [
    "encoder = PointNetEncoder(numpoints=40000)\n",
    "encoder.load_state_dict(torch.load(f'./models/runs/{config[\"experiment_name\"]}/encoder_best.pth'))\n",
    "encoder.eval()\n",
    "decoder = FoldingNetDec(200,200)\n",
    "decoder.load_state_dict(torch.load(f'./models/runs/{config[\"experiment_name\"]}/decoder_best.pth'))\n",
    "decoder.eval()\n",
    "val_dataset = pcd_stage1(split='val')\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,     # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "        batch_size=1,   # The size of batches is defined here\n",
    "        shuffle=False,   # During validation, shuffling is not necessary anymore\n",
    "        num_workers=4,   # Data is usually loaded in parallel by num_workers\n",
    "        pin_memory=True  # This is an implementation detail to speed up data uploading to the GPU\n",
    "    )\n",
    "x = 1\n",
    "for batch in val_dataloader:\n",
    "    input = batch.numpy()\n",
    "    batch = batch.permute(0,2,1)\n",
    "    recon = decoder(encoder(batch))\n",
    "    out = recon.permute(0,2,1).detach().numpy()\n",
    "\n",
    "    print(input.shape)\n",
    "    print(out.shape)\n",
    "\n",
    "    \n",
    "    export_pointcloud_to_obj(f'./input_{x}.obj', input[0])\n",
    "    export_pointcloud_to_obj(f'./output_{x}.obj', out[0])\n",
    "\n",
    "\n",
    "    x +=1\n",
    "    if x==10: break\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4000, 3)\n",
      "(1, 4000, 3)\n",
      "tensor(0.8896, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 3, 4000])\n",
      "torch.Size([1, 4000, 3])\n",
      "(1, 4000, 3)\n",
      "(1, 4000, 3)\n",
      "tensor(0.8429, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 3, 4000])\n",
      "torch.Size([1, 4000, 3])\n",
      "(1, 4000, 3)\n",
      "(1, 4000, 3)\n",
      "tensor(0.6607, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 3, 4000])\n",
      "torch.Size([1, 4000, 3])\n",
      "(1, 4000, 3)\n",
      "(1, 4000, 3)\n",
      "tensor(1.4037, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 3, 4000])\n",
      "torch.Size([1, 4000, 3])\n",
      "(1, 4000, 3)\n",
      "(1, 4000, 3)\n",
      "tensor(1.7110, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 3, 4000])\n",
      "torch.Size([1, 4000, 3])\n",
      "(1, 4000, 3)\n",
      "(1, 4000, 3)\n",
      "tensor(1.4772, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 3, 4000])\n",
      "torch.Size([1, 4000, 3])\n",
      "(1, 4000, 3)\n",
      "(1, 4000, 3)\n",
      "tensor(0.5348, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 3, 4000])\n",
      "torch.Size([1, 4000, 3])\n",
      "(1, 4000, 3)\n",
      "(1, 4000, 3)\n",
      "tensor(0.9369, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 3, 4000])\n",
      "torch.Size([1, 4000, 3])\n",
      "(1, 4000, 3)\n",
      "(1, 4000, 3)\n",
      "tensor(0.6032, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 3, 4000])\n",
      "torch.Size([1, 4000, 3])\n"
     ]
    }
   ],
   "source": [
    "loss_criterion = ChamferDistance()\n",
    "\n",
    "encoder = PointNetEncoder(numpoints=4000)\n",
    "encoder.load_state_dict(torch.load(f'./models/runs/{config[\"experiment_name\"]}/encoder_best.pth'))\n",
    "encoder.eval()\n",
    "decoder = PointNetDecoder(numpoints=4000)\n",
    "decoder.load_state_dict(torch.load(f'./models/runs/{config[\"experiment_name\"]}/decoder_best.pth'))\n",
    "decoder.eval()\n",
    "val_dataset = pcd_stage1(split='val')\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,     # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "        batch_size=1,   # The size of batches is defined here\n",
    "        shuffle=False,   # During validation, shuffling is not necessary anymore\n",
    "        num_workers=4,   # Data is usually loaded in parallel by num_workers\n",
    "        pin_memory=True  # This is an implementation detail to speed up data uploading to the GPU\n",
    "    )  \n",
    "x=1     \n",
    "for batch in val_dataloader:\n",
    "    input = batch.numpy()\n",
    "    batch = batch.permute(0,2,1)\n",
    "    recon = decoder(encoder(batch))\n",
    "    out = recon.permute(0,2,1).detach().numpy()\n",
    "\n",
    "    print(input.shape)\n",
    "    print(out.shape)\n",
    "    print(loss_criterion(recon.permute(0,2,1), batch.permute(0,2,1)))\n",
    "    print(recon.shape)\n",
    "    print(batch.permute(0,2,1).shape)\n",
    "\n",
    "    \n",
    "    export_pointcloud_to_obj(f'./input_{x}.obj', input[0])\n",
    "    export_pointcloud_to_obj(f'./output_{x}.obj', out[0])\n",
    "\n",
    "\n",
    "    x +=1\n",
    "    if x==10: break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PointNetDecoder:\n\tsize mismatch for fc.4.weight: copying a param with shape torch.Size([120000, 1024]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for fc.4.bias: copying a param with shape torch.Size([120000]) from checkpoint, the shape in current model is torch.Size([3072]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a5b47e4e39d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPointNetDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./models/runs/{config[\"experiment_name\"]}/decoder_best.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpcd_stage1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'overfit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for PointNetDecoder:\n\tsize mismatch for fc.4.weight: copying a param with shape torch.Size([120000, 1024]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for fc.4.bias: copying a param with shape torch.Size([120000]) from checkpoint, the shape in current model is torch.Size([3072])."
     ]
    }
   ],
   "source": [
    "loss_criterion = torch.nn.MSELoss()\n",
    "\n",
    "encoder = PointNetEncoder(return_point_features=True, numpoints=40000)\n",
    "encoder.load_state_dict(torch.load(f'./models/runs/{config[\"experiment_name\"]}/encoder_best.pth'))\n",
    "encoder.eval()\n",
    "decoder = PointNetDecoder()\n",
    "decoder.load_state_dict(torch.load(f'./models/runs/{config[\"experiment_name\"]}/decoder_best.pth'))\n",
    "decoder.eval()\n",
    "val_dataset = pcd_stage1(split='overfit')\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,     # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "        batch_size=1,   # The size of batches is defined here\n",
    "        shuffle=False,   # During validation, shuffling is not necessary anymore\n",
    "        num_workers=4,   # Data is usually loaded in parallel by num_workers\n",
    "        pin_memory=True  # This is an implementation detail to speed up data uploading to the GPU\n",
    "    )  \n",
    "x=1     \n",
    "for batch in val_dataloader:\n",
    "    input = batch.numpy()\n",
    "    batch = batch.permute(0,2,1)\n",
    "    recon = decoder(encoder(batch))\n",
    "    out = recon.detach().numpy()\n",
    "\n",
    "    print(input.shape)\n",
    "    print(out.shape)\n",
    "    print(loss_criterion(recon, batch.permute(0,2,1)))\n",
    "    print(recon.shape)\n",
    "    print(batch.permute(0,2,1).shape)\n",
    "\n",
    "    \n",
    "    export_pointcloud_to_obj(f'./input_{x}.obj', input[0])\n",
    "    export_pointcloud_to_obj(f'./output_{x}.obj', out[0])\n",
    "\n",
    "\n",
    "    x +=1\n",
    "    if x==10: break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### stage 2 training\n",
    "\n",
    "config = {\n",
    "    'experiment_name': 'pcd_stage2',\n",
    "    'device': 'cuda:0',                   # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': False,                   # True since we're doing overfitting\n",
    "    'batch_size': 1,\n",
    "    'resume_ckpt_en': '/home/wuha/Hanfeng/TUM/ML3D/ML3Dfinal_2021WS/models/runs/pcd_stage2/encoder_best.pth',\n",
    "    #'resume_ckpt_en': None,\n",
    "    'encoder_pretrained': '/home/wuha/Hanfeng/TUM/ML3D/ML3Dfinal_2021WS/models/runs/pcd_stage1/encoder_best.pth', \n",
    "    'learning_rate': 0.0001,\n",
    "    'max_epochs': 300,\n",
    "    'print_every_n': 100,\n",
    "    'validate_every_n': 1000,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "[000/00099] train_loss: 0.0013866251\n",
      "[000/00199] train_loss: 0.0005798664\n",
      "[000/00299] train_loss: 0.0005497261\n",
      "[000/00399] train_loss: 0.0005865927\n",
      "[000/00499] train_loss: 0.0006226039\n",
      "[000/00599] train_loss: 0.0005177707\n",
      "[000/00699] train_loss: 0.0005058221\n",
      "[000/00799] train_loss: 0.0005430110\n",
      "[000/00899] train_loss: 0.0004930555\n",
      "[000/00999] train_loss: 0.0004593548\n",
      "[000/00999] val_loss: 0.0004580859\n",
      "[000/01099] train_loss: 0.0004883460\n",
      "[000/01199] train_loss: 0.0004735059\n",
      "[000/01299] train_loss: 0.0004305126\n",
      "[000/01399] train_loss: 0.0004026025\n",
      "[000/01499] train_loss: 0.0004288288\n",
      "[000/01599] train_loss: 0.0004276766\n",
      "[000/01699] train_loss: 0.0003645228\n",
      "[000/01799] train_loss: 0.0003398186\n",
      "[000/01899] train_loss: 0.0003673212\n",
      "[000/01999] train_loss: 0.0003674010\n",
      "[000/01999] val_loss: 0.0003338145\n",
      "[000/02099] train_loss: 0.0003216727\n",
      "[000/02199] train_loss: 0.0003686877\n",
      "[000/02299] train_loss: 0.0003300356\n",
      "[000/02399] train_loss: 0.0003108314\n",
      "[000/02499] train_loss: 0.0003244685\n",
      "[000/02599] train_loss: 0.0003169087\n",
      "[000/02699] train_loss: 0.0003404591\n",
      "[000/02799] train_loss: 0.0003050317\n",
      "[000/02899] train_loss: 0.0003099478\n",
      "[000/02999] train_loss: 0.0002915873\n",
      "[000/02999] val_loss: 0.0002523376\n",
      "[000/03099] train_loss: 0.0002684604\n",
      "[000/03199] train_loss: 0.0002676486\n",
      "[000/03299] train_loss: 0.0002376076\n",
      "[000/03399] train_loss: 0.0002441583\n",
      "[000/03499] train_loss: 0.0002333112\n",
      "[000/03599] train_loss: 0.0002304414\n",
      "[000/03699] train_loss: 0.0002236569\n",
      "[000/03799] train_loss: 0.0002328629\n",
      "[000/03899] train_loss: 0.0002098537\n",
      "[000/03999] train_loss: 0.0002216222\n",
      "[000/03999] val_loss: 0.0002227100\n",
      "[000/04099] train_loss: 0.0001970221\n",
      "[000/04199] train_loss: 0.0001937168\n",
      "[000/04299] train_loss: 0.0002016746\n",
      "[000/04399] train_loss: 0.0002109460\n",
      "[000/04499] train_loss: 0.0002118542\n",
      "[000/04599] train_loss: 0.0002011938\n",
      "[000/04699] train_loss: 0.0001995044\n",
      "[000/04799] train_loss: 0.0002231818\n",
      "[000/04899] train_loss: 0.0001875881\n",
      "[000/04999] train_loss: 0.0001975774\n",
      "[000/04999] val_loss: 0.0001879036\n",
      "[000/05099] train_loss: 0.0002034266\n",
      "[000/05199] train_loss: 0.0001944780\n",
      "[000/05299] train_loss: 0.0001808805\n",
      "[000/05399] train_loss: 0.0002170138\n",
      "[000/05499] train_loss: 0.0001659154\n",
      "[000/05599] train_loss: 0.0001995286\n",
      "[000/05699] train_loss: 0.0001907854\n",
      "[000/05799] train_loss: 0.0001875370\n",
      "[000/05899] train_loss: 0.0001802973\n",
      "[000/05999] train_loss: 0.0001876548\n",
      "[000/05999] val_loss: 0.0001796679\n",
      "[000/06099] train_loss: 0.0001788189\n",
      "[000/06199] train_loss: 0.0001855739\n",
      "[000/06299] train_loss: 0.0001787623\n",
      "[000/06399] train_loss: 0.0001629369\n",
      "[000/06499] train_loss: 0.0001601321\n",
      "[000/06599] train_loss: 0.0001669479\n",
      "[000/06699] train_loss: 0.0001813619\n",
      "[000/06799] train_loss: 0.0001932680\n",
      "[000/06899] train_loss: 0.0001895022\n",
      "[000/06999] train_loss: 0.0001738675\n",
      "[000/06999] val_loss: 0.0001790356\n",
      "[000/07099] train_loss: 0.0001606221\n",
      "[000/07199] train_loss: 0.0001785694\n",
      "[000/07299] train_loss: 0.0001847926\n",
      "[000/07399] train_loss: 0.0001776820\n",
      "[000/07499] train_loss: 0.0001768404\n",
      "[000/07599] train_loss: 0.0001908491\n",
      "[000/07699] train_loss: 0.0001622601\n",
      "[000/07799] train_loss: 0.0001645993\n",
      "[000/07899] train_loss: 0.0001749907\n",
      "[000/07999] train_loss: 0.0001578624\n",
      "[000/07999] val_loss: 0.0001694853\n",
      "[000/08099] train_loss: 0.0001749653\n",
      "[000/08199] train_loss: 0.0001576739\n",
      "[000/08299] train_loss: 0.0001636687\n",
      "[000/08399] train_loss: 0.0001658597\n",
      "[000/08499] train_loss: 0.0001508641\n",
      "[000/08599] train_loss: 0.0001857403\n",
      "[000/08699] train_loss: 0.0001629289\n",
      "[000/08799] train_loss: 0.0001662738\n",
      "[000/08899] train_loss: 0.0001478511\n",
      "[000/08999] train_loss: 0.0001544081\n",
      "[000/08999] val_loss: 0.0001681248\n",
      "[000/09099] train_loss: 0.0001636183\n",
      "[000/09199] train_loss: 0.0001719691\n",
      "[000/09299] train_loss: 0.0002056634\n",
      "[000/09399] train_loss: 0.0001807426\n",
      "[000/09499] train_loss: 0.0001576052\n",
      "[000/09599] train_loss: 0.0001589732\n",
      "[000/09699] train_loss: 0.0001721143\n",
      "[000/09799] train_loss: 0.0001488088\n",
      "[000/09899] train_loss: 0.0001527740\n",
      "[000/09999] train_loss: 0.0001445449\n",
      "[000/09999] val_loss: 0.0001486826\n",
      "[000/10099] train_loss: 0.0001416085\n",
      "[000/10199] train_loss: 0.0001609186\n",
      "[000/10299] train_loss: 0.0001598331\n",
      "[000/10399] train_loss: 0.0001395294\n",
      "[000/10499] train_loss: 0.0001503199\n",
      "[000/10599] train_loss: 0.0001624403\n",
      "[000/10699] train_loss: 0.0001425028\n",
      "[000/10799] train_loss: 0.0001539653\n",
      "[000/10899] train_loss: 0.0001493423\n",
      "[000/10999] train_loss: 0.0001422358\n",
      "[000/10999] val_loss: 0.0001432440\n",
      "[000/11099] train_loss: 0.0001643762\n",
      "[000/11199] train_loss: 0.0001454760\n",
      "[000/11299] train_loss: 0.0001436376\n",
      "[000/11399] train_loss: 0.0001662147\n",
      "[000/11499] train_loss: 0.0001403452\n",
      "[000/11599] train_loss: 0.0001309295\n",
      "[000/11699] train_loss: 0.0001512549\n",
      "[000/11799] train_loss: 0.0001337824\n",
      "[000/11899] train_loss: 0.0001346518\n",
      "[000/11999] train_loss: 0.0001437987\n",
      "[000/11999] val_loss: 0.0001402642\n",
      "[000/12099] train_loss: 0.0001223930\n",
      "[000/12199] train_loss: 0.0001335697\n",
      "[000/12299] train_loss: 0.0001508122\n",
      "[000/12399] train_loss: 0.0001452087\n",
      "[000/12499] train_loss: 0.0001463487\n",
      "[000/12599] train_loss: 0.0001316474\n",
      "[000/12699] train_loss: 0.0001395493\n",
      "[000/12799] train_loss: 0.0001343327\n",
      "[000/12899] train_loss: 0.0001150274\n",
      "[000/12999] train_loss: 0.0001428427\n",
      "[000/12999] val_loss: 0.0001311299\n",
      "[000/13099] train_loss: 0.0001373514\n",
      "[000/13199] train_loss: 0.0001307743\n",
      "[000/13299] train_loss: 0.0001288256\n",
      "[000/13399] train_loss: 0.0001353114\n",
      "[000/13499] train_loss: 0.0001499132\n",
      "[000/13599] train_loss: 0.0001421475\n",
      "[000/13699] train_loss: 0.0001198586\n",
      "[000/13799] train_loss: 0.0001279851\n",
      "[000/13899] train_loss: 0.0001417371\n",
      "[000/13999] train_loss: 0.0001320879\n",
      "[000/13999] val_loss: 0.0001346719\n",
      "[000/14099] train_loss: 0.0001450578\n",
      "[000/14199] train_loss: 0.0001301663\n",
      "[000/14299] train_loss: 0.0001295594\n",
      "[000/14399] train_loss: 0.0001463831\n",
      "[000/14499] train_loss: 0.0001200800\n",
      "[000/14599] train_loss: 0.0001355261\n",
      "[000/14699] train_loss: 0.0001151119\n",
      "[000/14799] train_loss: 0.0001248368\n",
      "[000/14899] train_loss: 0.0001320162\n",
      "[000/14999] train_loss: 0.0001295758\n",
      "[000/14999] val_loss: 0.0001269272\n",
      "[000/15099] train_loss: 0.0001459871\n",
      "[000/15199] train_loss: 0.0001261504\n",
      "[000/15299] train_loss: 0.0001176812\n",
      "[000/15399] train_loss: 0.0001168217\n",
      "[000/15499] train_loss: 0.0001262128\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-02b814863ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_mesh2mesh_stage2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Hanfeng/TUM/ML3D/ML3Dfinal_2021WS/Networks/train_mesh2mesh_stage2.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_pretrained\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Hanfeng/TUM/ML3D/ML3Dfinal_2021WS/Networks/train_mesh2mesh_stage2.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(encoder_pretrained, encoder, trainloader, valloader, device, config)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# TODO: forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m#print(batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mlatent_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mlatent_vector_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Hanfeng/TUM/ML3D/ML3Dfinal_2021WS/Networks/mesh2mesh.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mnum_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0minput_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_transform_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Hanfeng/TUM/ML3D/ML3Dfinal_2021WS/Networks/mesh2mesh.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinearlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Adding the identity to constrain the feature transformation matrix to be close to orthogonal matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Networks import train_mesh2mesh_stage2\n",
    "\n",
    "\n",
    "train_mesh2mesh_stage2.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6320915c84db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mrecon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "encoder = PointNetEncoder(numpoints=1000)\n",
    "encoder.load_state_dict(torch.load(f'./models/runs/pcd_stage2/encoder_stage2_best.pth'))\n",
    "encoder.eval()\n",
    "decoder = PointNetDecoder(numpoints=4000)\n",
    "decoder.load_state_dict(torch.load(f'./models/runs/pcd_stage1/decoder_best.pth'))\n",
    "decoder.eval()\n",
    "val_dataset = pcd_stage2(split='val')\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,     # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "        batch_size=1,   # The size of batches is defined here\n",
    "        shuffle=False,   # During validation, shuffling is not necessary anymore\n",
    "        num_workers=4,   # Data is usually loaded in parallel by num_workers\n",
    "        pin_memory=True  # This is an implementation detail to speed up data uploading to the GPU\n",
    "    )  \n",
    "x=1     \n",
    "for batch in val_dataloader:\n",
    "    gt = batch['full'].numpy()\n",
    "    input = batch['partial'].permute(0,2,1)\n",
    "    print(gt.shape)\n",
    "    print(input.shape)\n",
    "    recon = decoder(encoder(input))\n",
    "    out = recon.detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(out.shape)\n",
    "\n",
    "    \n",
    "    export_pointcloud_to_obj(f'./full_{x}.obj', gt[0])\n",
    "    export_pointcloud_to_obj(f'./partial_{x}.obj', out[0])\n",
    "\n",
    "\n",
    "    x +=1\n",
    "    if x==10: break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc0947d0fe176f08f121a45e9c7608968179b427c711a6bc177fb4cee838f9d6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

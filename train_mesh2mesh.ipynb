{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from Networks.mesh2mesh import *\n",
    "from Networks.rgbd2mesh import RGBD2Mesh\n",
    "import trimesh\n",
    "from Networks.obj2pointcloud import *\n",
    "from Networks.pointclouddataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####1 get data for stage one autoencoder training\n",
    "\n",
    "train_dataset = pcd_stage1(split='train')\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,   # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "        batch_size=1,   # The size of batches is defined here\n",
    "        shuffle=True,    # Shuffling the order of samples is useful during training to prevent that the network learns to depend on the order of the input data\n",
    "        num_workers=4,   # Data is usually loaded in parallel by num_workers\n",
    "        pin_memory=True  # This is an implementation detail to speed up data uploading to the GPU\n",
    "    )\n",
    "val_dataset = pcd_stage1(split='val')\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,     # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "        batch_size=1,   # The size of batches is defined here\n",
    "        shuffle=False,   # During validation, shuffling is not necessary anymore\n",
    "        num_workers=4,   # Data is usually loaded in parallel by num_workers\n",
    "        pin_memory=True  # This is an implementation detail to speed up data uploading to the GPU\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'experiment_name': 'pcd_stage1_overfit',\n",
    "    'device': 'cuda:0',                   # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': True,                   # True since we're doing overfitting\n",
    "    'batch_size': 1,\n",
    "    'resume_ckpt_en': None,\n",
    "    'resume_ckpt_de': None,\n",
    "    'learning_rate': 0.001,\n",
    "    'max_epochs': 300,\n",
    "    'print_every_n': 10,\n",
    "    'validate_every_n': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "[000/00009] train_loss: 288.740\n",
      "[000/00009] val_loss: 212.146\n",
      "[001/00009] train_loss: 337.432\n",
      "[001/00009] val_loss: 204.462\n",
      "[002/00009] train_loss: 227.578\n",
      "[002/00009] val_loss: 217.426\n",
      "[003/00009] train_loss: 219.915\n",
      "[003/00009] val_loss: 188.284\n",
      "[004/00009] train_loss: 187.207\n",
      "[004/00009] val_loss: 156.776\n",
      "[005/00009] train_loss: 190.598\n",
      "[005/00009] val_loss: 157.789\n",
      "[006/00009] train_loss: 168.000\n",
      "[006/00009] val_loss: 140.319\n",
      "[007/00009] train_loss: 149.344\n",
      "[007/00009] val_loss: 148.574\n",
      "[008/00009] train_loss: 175.154\n",
      "[008/00009] val_loss: 131.206\n",
      "[009/00009] train_loss: 139.257\n",
      "[009/00009] val_loss: 195.801\n",
      "[010/00009] train_loss: 206.207\n",
      "[010/00009] val_loss: 194.420\n",
      "[011/00009] train_loss: 180.496\n",
      "[011/00009] val_loss: 147.374\n",
      "[012/00009] train_loss: 126.813\n",
      "[012/00009] val_loss: 110.614\n",
      "[013/00009] train_loss: 108.884\n",
      "[013/00009] val_loss: 70.886\n",
      "[014/00009] train_loss: 61.532\n",
      "[014/00009] val_loss: 36.940\n",
      "[015/00009] train_loss: 28.789\n",
      "[015/00009] val_loss: 28.064\n",
      "[016/00009] train_loss: 35.176\n",
      "[016/00009] val_loss: 73.746\n",
      "[017/00009] train_loss: 235.580\n",
      "[017/00009] val_loss: 88.268\n",
      "[018/00009] train_loss: 93.032\n",
      "[018/00009] val_loss: 57.170\n",
      "[019/00009] train_loss: 93.355\n",
      "[019/00009] val_loss: 34.537\n",
      "[020/00009] train_loss: 132.995\n",
      "[020/00009] val_loss: 93.517\n",
      "[021/00009] train_loss: 92.641\n",
      "[021/00009] val_loss: 74.979\n",
      "[022/00009] train_loss: 137.382\n",
      "[022/00009] val_loss: 63.290\n",
      "[023/00009] train_loss: 117.053\n",
      "[023/00009] val_loss: 86.421\n",
      "[024/00009] train_loss: 107.418\n",
      "[024/00009] val_loss: 150.978\n",
      "[025/00009] train_loss: 138.343\n",
      "[025/00009] val_loss: 92.860\n",
      "[026/00009] train_loss: 53.368\n",
      "[026/00009] val_loss: 24.443\n",
      "[027/00009] train_loss: 30.586\n",
      "[027/00009] val_loss: 31.756\n",
      "[028/00009] train_loss: 30.821\n",
      "[028/00009] val_loss: 13.598\n",
      "[029/00009] train_loss: 18.783\n",
      "[029/00009] val_loss: 10.216\n",
      "[030/00009] train_loss: 11.213\n",
      "[030/00009] val_loss: 12.104\n",
      "[031/00009] train_loss: 10.431\n",
      "[031/00009] val_loss: 12.798\n",
      "[032/00009] train_loss: 22.279\n",
      "[032/00009] val_loss: 41.513\n",
      "[033/00009] train_loss: 66.944\n",
      "[033/00009] val_loss: 21.597\n",
      "[034/00009] train_loss: 54.205\n",
      "[034/00009] val_loss: 225.366\n",
      "[035/00009] train_loss: 228.621\n",
      "[035/00009] val_loss: 190.889\n",
      "[036/00009] train_loss: 216.025\n",
      "[036/00009] val_loss: 181.165\n",
      "[037/00009] train_loss: 181.627\n",
      "[037/00009] val_loss: 153.745\n",
      "[038/00009] train_loss: 244.150\n",
      "[038/00009] val_loss: 149.523\n",
      "[039/00009] train_loss: 193.260\n",
      "[039/00009] val_loss: 160.595\n",
      "[040/00009] train_loss: 163.795\n",
      "[040/00009] val_loss: 146.828\n",
      "[041/00009] train_loss: 176.142\n",
      "[041/00009] val_loss: 154.558\n",
      "[042/00009] train_loss: 192.783\n",
      "[042/00009] val_loss: 136.264\n",
      "[043/00009] train_loss: 151.731\n",
      "[043/00009] val_loss: 135.719\n",
      "[044/00009] train_loss: 142.158\n",
      "[044/00009] val_loss: 135.390\n",
      "[045/00009] train_loss: 143.623\n",
      "[045/00009] val_loss: 135.489\n",
      "[046/00009] train_loss: 141.777\n",
      "[046/00009] val_loss: 134.516\n",
      "[047/00009] train_loss: 139.687\n",
      "[047/00009] val_loss: 134.481\n",
      "[048/00009] train_loss: 142.308\n",
      "[048/00009] val_loss: 133.148\n",
      "[049/00009] train_loss: 137.993\n",
      "[049/00009] val_loss: 134.488\n",
      "[050/00009] train_loss: 143.825\n",
      "[050/00009] val_loss: 133.854\n",
      "[051/00009] train_loss: 144.675\n",
      "[051/00009] val_loss: 132.891\n",
      "[052/00009] train_loss: 146.826\n",
      "[052/00009] val_loss: 132.722\n",
      "[053/00009] train_loss: 140.993\n",
      "[053/00009] val_loss: 134.479\n",
      "[054/00009] train_loss: 139.199\n",
      "[054/00009] val_loss: 132.026\n",
      "[055/00009] train_loss: 138.487\n",
      "[055/00009] val_loss: 131.462\n",
      "[056/00009] train_loss: 137.656\n",
      "[056/00009] val_loss: 133.505\n",
      "[057/00009] train_loss: 147.825\n",
      "[057/00009] val_loss: 136.950\n",
      "[058/00009] train_loss: 148.901\n",
      "[058/00009] val_loss: 129.658\n",
      "[059/00009] train_loss: 135.802\n",
      "[059/00009] val_loss: 115.767\n",
      "[060/00009] train_loss: 138.922\n",
      "[060/00009] val_loss: 101.868\n",
      "[061/00009] train_loss: 118.544\n",
      "[061/00009] val_loss: 133.275\n",
      "[062/00009] train_loss: 184.888\n",
      "[062/00009] val_loss: 139.338\n",
      "[063/00009] train_loss: 181.687\n",
      "[063/00009] val_loss: 147.178\n",
      "[064/00009] train_loss: 152.375\n",
      "[064/00009] val_loss: 140.459\n",
      "[065/00009] train_loss: 148.252\n",
      "[065/00009] val_loss: 140.828\n",
      "[066/00009] train_loss: 141.684\n",
      "[066/00009] val_loss: 137.925\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5d5fbe509837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_mesh2mesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Hanfeng/TUM/ML3D/ML3Dfinal_2021WS/Networks/train_mesh2mesh.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Hanfeng/TUM/ML3D/ML3Dfinal_2021WS/Networks/train_mesh2mesh.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, trainloader, valloader, device, config)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0;31m# move batch to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0;31m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                     \u001b[0;31m# wrong, we set a timeout and if the workers fail to join,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                     \u001b[0;31m# they are killed in the `finally` block.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m                     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMP_STATUS_CHECK_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                     \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_join_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Networks import train_mesh2mesh\n",
    "\n",
    "\n",
    "train_mesh2mesh.main(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n"
     ]
    }
   ],
   "source": [
    "encoder = PointNetEncoder(numpoints=40000)\n",
    "encoder.load_state_dict(torch.load(f'./models/runs/{config[\"experiment_name\"]}/encoder_best.pth'))\n",
    "encoder.eval()\n",
    "decoder = PointNetDecoder(numpoints=40000)\n",
    "decoder.load_state_dict(torch.load(f'./models/runs/{config[\"experiment_name\"]}/decoder_best.pth'))\n",
    "decoder.eval()\n",
    "x = 1\n",
    "for batch in val_dataloader:\n",
    "    input = batch.numpy()\n",
    "    batch = batch.permute(0,2,1)\n",
    "    recon = decoder(encoder(batch))\n",
    "    out = recon.permute(0,2,1).detach().numpy()\n",
    "\n",
    "    print(input.shape)\n",
    "    print(out.shape)\n",
    "\n",
    "    \n",
    "    export_pointcloud_to_obj(f'./input_{x}.obj', input[0])\n",
    "    export_pointcloud_to_obj(f'./output_{x}.obj', out[0])\n",
    "\n",
    "\n",
    "    x +=1\n",
    "    if x==10: break\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n",
      "(1, 40000, 3)\n"
     ]
    }
   ],
   "source": [
    "encoder = PointNetEncoder(numpoints=40000)\n",
    "encoder.load_state_dict(torch.load(f'./models/runs/{config[\"experiment_name\"]}/encoder_best.pth'))\n",
    "encoder.eval()\n",
    "decoder = PointNetDecoder(numpoints=40000)\n",
    "decoder.load_state_dict(torch.load(f'./models/runs/{config[\"experiment_name\"]}/decoder_best.pth'))\n",
    "decoder.eval()\n",
    "val_dataset = pcd_stage1(split='overfit')\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,     # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "        batch_size=1,   # The size of batches is defined here\n",
    "        shuffle=False,   # During validation, shuffling is not necessary anymore\n",
    "        num_workers=4,   # Data is usually loaded in parallel by num_workers\n",
    "        pin_memory=True  # This is an implementation detail to speed up data uploading to the GPU\n",
    "    )   \n",
    "x=1    \n",
    "for batch in val_dataloader:\n",
    "    input = batch.numpy()\n",
    "    batch = batch.permute(0,2,1)\n",
    "    recon = decoder(encoder(batch))\n",
    "    out = recon.permute(0,2,1).detach().numpy()\n",
    "\n",
    "    print(input.shape)\n",
    "    print(out.shape)\n",
    "\n",
    "    \n",
    "    export_pointcloud_to_obj(f'./input_{x}.obj', input[0])\n",
    "    export_pointcloud_to_obj(f'./output_{x}.obj', out[0])\n",
    "\n",
    "\n",
    "    x +=1\n",
    "    if x==10: break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc0947d0fe176f08f121a45e9c7608968179b427c711a6bc177fb4cee838f9d6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
